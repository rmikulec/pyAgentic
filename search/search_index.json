{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"PyAgentic Documentation","text":"<p>Build sophisticated AI agents with declarative Python syntax. PyAgentic provides a type-safe, extensible framework for creating LLM agents with persistent context, powerful tools, and seamless integration with multiple LLM providers including OpenAI, Anthropic, and others.</p>"},{"location":"#quick-start","title":"Quick Start","text":"<p>New to PyAgentic? Start here to build your first agent in minutes:</p> <ul> <li> <p>Getting Started Guide</p> <p>Complete tutorial building a research assistant agent from scratch. Learn core concepts through practical examples.</p> <p> Start building</p> </li> </ul>"},{"location":"#core-documentation","title":"Core Documentation","text":"<p>Dive deeper into PyAgentic's powerful features:</p> <ul> <li> <p> Tools</p> <p>Give agents capabilities with the @tool decorator, parameter validation, and dynamic constraints.</p> <p> Learn about tools</p> </li> <li> <p> State Management</p> <p>Persistent, type-safe state fields with Pydantic models, computed fields, and access control.</p> <p> Learn about states</p> </li> <li> <p> Phases</p> <p>Structure agent workflows with finite state machines, phase-based tool filtering, and conditional transitions.</p> <p> Learn about phases</p> </li> <li> <p> Policies</p> <p>React to state changes with validation, history tracking, persistence, and custom behaviors.</p> <p> Learn about policies</p> </li> <li> <p> Agent Responses</p> <p>Understanding structured response objects with tool execution details and type safety.</p> <p> Learn about responses</p> </li> <li> <p> Execution Modes</p> <p>Three ways to run agents: simple calls, run(), and step() for streaming responses.</p> <p> Learn about execution modes</p> </li> <li> <p> Structured Outputs</p> <p>Using Pydantic models to enforce structured output schemas for your agents.</p> <p> Learn about structured outputs</p> </li> <li> <p> Agent Linking</p> <p>Build complex multi-agent workflows where agents call other agents as specialized tools.</p> <p> Explore linking</p> </li> <li> <p> Inheritance &amp; Extensions</p> <p>Create agent hierarchies and add cross-cutting capabilities with extensions.</p> <p> Build hierarchies</p> </li> <li> <p>:material-search: Observability</p> <p>Observe and trace all steps and interactions of an agent.</p> <p> Trace behavior</p> </li> </ul> <ul> <li>GitHub: rmikulec/pyagentic - Source code, issues, and contributions</li> <li>Installation: <code>pip install pyagentic-core</code></li> <li>Python Support: 3.13+</li> </ul>"},{"location":"agent-linking/","title":"Agent Linking","text":"<p>Agent linking allows you to build multi-agent systems where agents can call other agents as specialized tools. This enables complex workflows where different agents handle their areas of expertise while a coordinator orchestrates the overall process.</p>"},{"location":"agent-linking/#how-agent-linking-works","title":"How Agent Linking Works","text":"<p>When you declare an agent as an attribute of another agent class, PyAgentic automatically makes it available as a tool. The linked agent appears in the parent's toolset with its <code>__description__</code> as the tool description. When the LLM decides to use that \"tool,\" PyAgentic seamlessly calls the linked agent and integrates its response.</p> <p>This happens at the class definition level - each agent knows about its linked agents before any instances are created, ensuring type safety and predictable behavior.</p>"},{"location":"agent-linking/#basic-linking","title":"Basic Linking","text":"<p>The simplest way to link agents is by declaring them as typed attributes in your agent class. You can use either the <code>Link[T]</code> descriptor or direct type annotation:</p> <pre><code>from pyagentic import BaseAgent, Link, tool\n\nclass DatabaseAgent(BaseAgent):\n    __system_message__ = \"I query databases\"\n    __description__ = \"Retrieves and analyzes data from databases\"\n\n    @tool(\"Execute SQL query\")\n    def query(self, sql: str) -&gt; str: ...\n\nclass ReportAgent(BaseAgent):\n    __system_message__ = \"I generate business reports\"\n\n    # Using Link[T] (recommended for advanced features)\n    database: Link[DatabaseAgent]\n\n    # OR direct annotation (backward compatible)\n    # database: DatabaseAgent\n\n# The report agent can now automatically call the database agent\nresponse = await report_agent(\"Create a sales report for Q4\")\n</code></pre> <p>When the report agent runs, the LLM sees the database agent as an available tool in its toolset. If the LLM determines it needs database information to complete the task, it will automatically call the database agent. PyAgentic handles all the communication, context passing, and response integration behind the scenes.</p> <p>Both <code>Link[DatabaseAgent]</code> and direct <code>DatabaseAgent</code> annotations work identically for basic linking. The <code>Link[T]</code> syntax becomes powerful when combined with <code>spec.AgentLink()</code> for advanced configuration (covered below).</p>"},{"location":"agent-linking/#multiple-linked-agents","title":"Multiple Linked Agents","text":"<p>Real-world applications often require coordination between multiple specialized agents. You can link as many agents as needed to create sophisticated workflows where each agent contributes its expertise:</p> <pre><code>class EmailAgent(BaseAgent):\n    __system_message__ = \"I send emails\"\n    __description__ = \"Sends and manages email communications\"\n\nclass CalendarAgent(BaseAgent):\n    __system_message__ = \"I manage calendars\"\n    __description__ = \"Schedules meetings and manages calendar events\"\n\nclass AssistantAgent(BaseAgent):\n    __system_message__ = \"I help with daily tasks\"\n\n    email: EmailAgent\n    calendar: CalendarAgent\n\nresponse = await assistant.run(\"Schedule a meeting with John and send him the details\")\n</code></pre> <p>With multiple linked agents, the coordinator can intelligently decide which agents to call and in what order. In this example, the assistant might first call the calendar agent to schedule the meeting, then use that information to call the email agent to send the details. The LLM automatically determines the optimal workflow based on the task requirements.</p>"},{"location":"agent-linking/#advanced-link-configuration-with-specagentlink","title":"Advanced Link Configuration with <code>spec.AgentLink()</code>","text":"<p>Just like <code>State</code> fields can be configured with <code>spec.State()</code>, linked agents can be configured with <code>spec.AgentLink()</code> for advanced features like defaults, factories, and conditional linking. This follows the same descriptor pattern used throughout PyAgentic.</p>"},{"location":"agent-linking/#default-agent-instances","title":"Default Agent Instances","text":"<p>Provide a default agent instance that will be used if none is provided during initialization:</p> <pre><code>from pyagentic import BaseAgent, Link, spec\n\nclass AnalysisAgent(BaseAgent):\n    __system_message__ = \"I analyze data\"\n    __description__ = \"Performs data analysis\"\n\n# Create a pre-configured analyzer\ndefault_analyzer = AnalysisAgent(model=\"gpt-4\", api_key=\"sk-...\")\n\nclass ReportAgent(BaseAgent):\n    __system_message__ = \"I generate reports\"\n\n    # Will use default_analyzer if no analyzer is provided\n    analyzer: Link[AnalysisAgent] = spec.AgentLink(default=default_analyzer)\n\n# Can use the default\nreport_agent = ReportAgent(model=\"gpt-4\", api_key=\"sk-...\")\n# Or provide a custom analyzer\ncustom_analyzer = AnalysisAgent(model=\"claude-3\", api_key=\"sk-...\")\nreport_agent = ReportAgent(\n    model=\"gpt-4\",\n    api_key=\"sk-...\",\n    analyzer=custom_analyzer\n)\n</code></pre>"},{"location":"agent-linking/#default-factory-for-dynamic-creation","title":"Default Factory for Dynamic Creation","text":"<p>Use <code>default_factory</code> to create agent instances on-demand, similar to how <code>spec.State()</code> works:</p> <pre><code>class SearchAgent(BaseAgent):\n    __system_message__ = \"I search databases\"\n    __description__ = \"Database search specialist\"\n\ndef create_searcher():\n    \"\"\"Factory function to create search agents\"\"\"\n    return SearchAgent(\n        model=\"gpt-4-turbo\",\n        api_key=os.getenv(\"OPENAI_API_KEY\"),\n        max_iterations=5\n    )\n\nclass DataAgent(BaseAgent):\n    __system_message__ = \"I manage data operations\"\n\n    # Automatically creates a searcher if not provided\n    searcher: Link[SearchAgent] = spec.AgentLink(default_factory=create_searcher)\n\n# Searcher is automatically created\ndata_agent = DataAgent(model=\"gpt-4\", api_key=\"sk-...\")\n# data_agent.searcher is now a SearchAgent instance\n</code></pre> <p>This is particularly useful when: - Agent configuration depends on environment variables or runtime context - You want to avoid creating expensive agent instances until they're needed - Different instances of the parent agent should have independent child agents</p>"},{"location":"agent-linking/#conditional-linking","title":"Conditional Linking","text":"<p>Link agents conditionally based on runtime state, enabling dynamic agent composition:</p> <pre><code>from pyagentic import State\n\nclass ExpertAgent(BaseAgent):\n    __system_message__ = \"I provide expert analysis\"\n    __description__ = \"Expert consultant for complex problems\"\n\nclass SmartAgent(BaseAgent):\n    __system_message__ = \"I handle tasks with optional expert help\"\n\n    # State field to control expert availability\n    needs_expert: State[bool] = spec.State(default=False)\n    complexity_level: State[int] = spec.State(default=1)\n\n    # Expert is only available when needed\n    expert: Link[ExpertAgent] = spec.AgentLink(\n        condition=lambda self: self.needs_expert\n    )\n\n    # Or use more complex conditions\n    advanced_expert: Link[ExpertAgent] = spec.AgentLink(\n        condition=lambda self: self.complexity_level &gt; 7\n    )\n\n    @tool(\"Mark task as complex\")\n    def mark_complex(self) -&gt; str:\n        self.needs_expert = True\n        return \"Expert help is now available\"\n</code></pre>"},{"location":"agent-linking/#how-condition-works","title":"How <code>condition</code> Works","text":"<p>The <code>condition</code> parameter accepts a callable (typically a lambda function) that receives the agent instance (<code>self</code>) and returns a boolean:</p> <ul> <li>Evaluation Time: Conditions are evaluated each time the tool schema is generated, which happens before every agent interaction</li> <li>Access to State: The condition function has full access to the agent's state and methods via <code>self</code></li> <li>Dynamic Agent Composition: Only linked agents whose conditions evaluate to <code>True</code> appear as available tools in the parent agent's toolset</li> </ul> <p>This enables sophisticated agent workflows where the available linked agents adapt based on the current state and requirements.</p>"},{"location":"agent-linking/#custom-agent-parameters","title":"Custom Agent Parameters","text":"<p>By default, when a linked agent is called, it receives the full user input as a single string. However, you can customize this behavior to create more sophisticated interactions by implementing custom <code>__call__</code> methods and using Pydantic models to define structured input parameters.</p>"},{"location":"agent-linking/#basic-custom-call","title":"Basic Custom call","text":"<p>Overriding the <code>__call__</code> method gives you complete control over how your linked agent processes input. This allows you to define specific parameters that the parent agent can pass:</p> <pre><code>class AnalysisAgent(BaseAgent):\n    __system_message__ = \"I analyze data\"\n    __description__ = \"Performs statistical analysis on datasets\"\n\n    async def __call__(self, data: str, analysis_type: str = \"basic\") -&gt; str: ...\n\nclass ReportAgent(BaseAgent):\n    __system_message__ = \"I generate reports\"\n    analyzer: AnalysisAgent\n\n# The LLM can now call the analyzer with specific parameters\nresponse = await report_agent(\"Create a detailed analysis report\")\n</code></pre> <p>With this setup, the parent agent's LLM can call the analysis agent with specific parameters like <code>analysis_type=\"advanced\"</code>, giving it precise control over the linked agent's behavior.</p>"},{"location":"agent-linking/#using-pydantic-models-for-structured-input","title":"Using Pydantic Models for Structured Input","text":"<p>For more complex scenarios with multiple parameters, validation, and documentation, use Pydantic <code>BaseModel</code> classes. These provide type safety, validation, and automatic schema generation:</p> <pre><code>from pydantic import BaseModel, Field\n\nclass SearchParams(BaseModel):\n    query: str = Field(..., description=\"The search query to execute\")\n    max_results: int = Field(default=10, description=\"Maximum number of results to return\")\n    include_metadata: bool = Field(default=True, description=\"Whether to include metadata in results\")\n\nclass SearchAgent(BaseAgent):\n    __system_message__ = \"I search databases\"\n    __description__ = \"Searches databases with advanced filtering\"\n\n    async def __call__(self, params: SearchParams) -&gt; str:\n        # Access validated parameters\n        results = self.search_db(params.query, params.max_results)\n        return f\"Found {len(results)} results for '{params.query}'\"\n\nclass DataAgent(BaseAgent):\n    __system_message__ = \"I manage data operations\"\n    searcher: SearchAgent\n\n# The LLM can now call the searcher with structured parameters\nresult = await data_agent(\"Find customer records for 'John Smith'\")\n</code></pre> <p>When using Pydantic <code>BaseModel</code> classes, PyAgentic automatically generates the proper OpenAI tool schema, complete with parameter types, defaults, descriptions, and validation rules. This makes the linked agent's interface clear to the calling LLM and ensures type safety throughout the system.</p>"},{"location":"execution-modes/","title":"Execution Modes","text":"<p>PyAgentic provides three different ways to execute your agents, each suited for different use cases. Understanding these modes helps you choose the right execution pattern for your application.</p>"},{"location":"execution-modes/#overview","title":"Overview","text":"Mode Method Returns Use Case Call <code>agent(...)</code> <code>AgentResponse</code> Customizable interface, used when linking agents Run <code>agent.run(\"message\")</code> <code>AgentResponse</code> Direct execution with message string Step <code>agent.step(\"message\")</code> <code>AsyncGenerator</code> Streaming responses, real-time updates"},{"location":"execution-modes/#call-agent","title":"Call: <code>agent(...)</code>","text":"<p>The <code>__call__</code> method provides a customizable interface for your agent. By default, it accepts a single <code>user_input</code> string and forwards it to <code>run()</code>, but you can override it to accept any typed parameters you need.</p>"},{"location":"execution-modes/#default-behavior","title":"Default Behavior","text":"<pre><code>agent = ResearchAgent(\n    model=\"openai::gpt-4o\",\n    api_key=API_KEY\n)\n\n# Call the agent directly with a message\nresponse = await agent(\"Find papers on AI and climate change\")\nprint(response.final_output)\n</code></pre>"},{"location":"execution-modes/#customizing-__call__-for-structured-input","title":"Customizing <code>__call__</code> for Structured Input","text":"<p>The real power of <code>__call__</code> is that you can override it to accept typed parameters that match your agent's purpose. These parameters automatically become tool parameters when the agent is used as a linked agent:</p> <pre><code>from typing import Optional\n\nclass CoursePlannerAgent(BaseAgent):\n    __system_message__ = \"You design course curricula\"\n    __description__ = \"Creates structured course plans based on learning goals\"\n    __response_format__ = CoursePlan\n\n    async def __call__(\n        self,\n        goal: str,\n        experience: str,\n        context: Optional[str] = None\n    ) -&gt; CoursePlan:\n        \"\"\"\n        Generate a course plan based on structured inputs.\n\n        Args:\n            goal: The student's learning objective\n            experience: Description of their current skill level\n            context: Optional additional context or preferences\n        \"\"\"\n        # Build a structured prompt from the parameters\n        prompt_parts = [\n            f\"Goal: {goal}\",\n            f\"Experience: {experience}\",\n        ]\n        if context:\n            prompt_parts.append(f\"Additional Context: {context}\")\n\n        user_input = \"\\n\".join(prompt_parts)\n        return await self.run(input_=user_input).final_output\n\n# Now you can call it with structured parameters\nplanner = CoursePlannerAgent(model=\"openai::gpt-4o\", api_key=API_KEY)\ncourse = await planner(\n    goal=\"Learn machine learning\",\n    experience=\"Beginner programmer with Python knowledge\",\n    context=\"Prefer hands-on projects\"\n)\n</code></pre>"},{"location":"execution-modes/#why-this-matters-for-agent-linking","title":"Why This Matters for Agent Linking","text":"<p>When you link an agent to another agent, PyAgentic extracts the parameters from the <code>__call__</code> signature and uses them as tool parameters. This means the LLM will see your structured parameters instead of just a generic \"user_input\" string:</p> <pre><code>class AssistantAgent(BaseAgent):\n    __system_message__ = \"You help students with learning plans\"\n\n    # Link the course planner\n    planner: CoursePlannerAgent\n\n# When the LLM wants to use the planner, it sees:\n# Tool: planner(goal: str, experience: str, context: Optional[str])\n# Instead of: planner(user_input: str)\n\nassistant = AssistantAgent(\n    model=\"openai::gpt-4o\",\n    api_key=API_KEY,\n    planner=planner\n)\n\n# The assistant can intelligently call the planner with structured data\nresponse = await assistant(\"Help me learn ML - I'm a beginner with Python\")\n# The LLM will call: planner(goal=\"machine learning\", experience=\"beginner with Python\", context=None)\n</code></pre>"},{"location":"execution-modes/#when-to-use-custom-__call__","title":"When to Use Custom <code>__call__</code>","text":"<ul> <li>When your agent has a specific interface contract (like <code>goal</code> and <code>experience</code>)</li> <li>When you're building agents that will be linked to other agents</li> <li>When you want to enforce a structured input schema</li> <li>When you need to transform input parameters before processing</li> </ul>"},{"location":"execution-modes/#when-to-use-default-__call__","title":"When to Use Default <code>__call__</code>","text":"<ul> <li>For simple conversational agents</li> <li>When you don't need structured parameters</li> <li>For quick prototypes</li> <li>When the agent won't be used as a linked agent</li> </ul>"},{"location":"execution-modes/#run-agentrunmessage","title":"Run: <code>agent.run(\"message\")</code>","text":"<p>The <code>run()</code> method is the direct execution method that always takes a single message string. It's what <code>__call__</code> uses by default, and it's the low-level execution interface.</p> <pre><code># Direct execution with a message\nresponse = await agent.run(\"What's the weather?\")\n</code></pre>"},{"location":"execution-modes/#when-to-use","title":"When to Use","text":"<ul> <li>When you need to explicitly pass a formatted message string</li> <li>In internal methods where you've already formatted the input</li> <li>When bypassing a custom <code>__call__</code> implementation</li> <li>For consistency in code that always uses explicit method calls</li> </ul>"},{"location":"execution-modes/#step-agentstepmessage","title":"Step: <code>agent.step(\"message\")</code>","text":"<p>The most powerful execution mode, <code>step()</code> returns an async generator that yields responses as they happen. This enables real-time streaming and fine-grained control over the agent's execution.</p> <pre><code>async for response in agent.step(\"Research AI and climate change\"):\n    if isinstance(response, LLMResponse):\n        print(f\"LLM thinking: {response.text}\")\n    elif isinstance(response, ToolResponse):\n        print(f\"Tool '{response.tool_name}' called with {response.raw_kwargs}\")\n        print(f\"Result: {response.output}\")\n    elif isinstance(response, AgentResponse):\n        print(f\"Final answer: {response.final_output}\")\n</code></pre>"},{"location":"execution-modes/#when-to-use_1","title":"When to Use","text":"<ul> <li>Building interactive UIs that show real-time progress</li> <li>Streaming responses to users as the agent works</li> <li>Debugging complex multi-step agent workflows</li> <li>Implementing custom retry logic or intervention</li> <li>Monitoring tool execution in real-time</li> </ul>"},{"location":"execution-modes/#what-you-get","title":"What You Get","text":"<p>The generator yields three types of responses in sequence:</p>"},{"location":"execution-modes/#1-llmresponse-each-llm-inference","title":"1. <code>LLMResponse</code> - Each LLM Inference","text":"<p>Yielded each time the LLM is called (can happen multiple times per run):</p> <pre><code>LLMResponse(\n    text=\"I'll search for papers on that topic\",\n    tool_calls=[...],  # Tool calls the LLM wants to make\n    parsed=None,       # Structured output (if using response_format)\n    usage=UsageInfo(...)  # Token usage stats\n)\n</code></pre>"},{"location":"execution-modes/#2-toolresponse-each-tool-call","title":"2. <code>ToolResponse</code> - Each Tool Call","text":"<p>Yielded for every tool that gets executed:</p> <pre><code>ToolResponse(\n    output=\"Found 5 papers...\",  # The tool's return value\n    call_depth=0,                # How deep in the tool loop\n    raw_kwargs='{\"query\": \"AI climate\"}',  # Original JSON args\n    # Plus all the tool's typed parameters...\n)\n</code></pre>"},{"location":"execution-modes/#3-agentresponse-final-result","title":"3. <code>AgentResponse</code> - Final Result","text":"<p>Yielded once at the very end with the complete execution summary:</p> <pre><code>AgentResponse(\n    final_output=\"Here's what I found...\",\n    state=&lt;agent state&gt;,\n    tool_responses=[...],  # All tools that were called\n    provider_info=&lt;provider info&gt;\n)\n</code></pre>"},{"location":"execution-modes/#response-flow-example","title":"Response Flow Example","text":"<p>Here's what the response stream looks like for a typical agent run:</p> <pre><code>async for response in agent.step(\"Find and analyze papers on AI\"):\n    # First: LLM decides to call search tool\n    # \u2192 LLMResponse(tool_calls=[ToolCall(name=\"search\", ...)])\n\n    # Second: Search tool executes\n    # \u2192 ToolResponse(output=\"Found 5 papers...\")\n\n    # Third: LLM decides to call read_paper tool\n    # \u2192 LLMResponse(tool_calls=[ToolCall(name=\"read_paper\", ...)])\n\n    # Fourth: Read tool executes\n    # \u2192 ToolResponse(output=\"Paper content...\")\n\n    # Fifth: LLM provides final analysis\n    # \u2192 LLMResponse(text=\"Based on these papers...\")\n\n    # Finally: Complete response\n    # \u2192 AgentResponse(final_output=\"Based on these papers...\", ...)\n</code></pre>"},{"location":"getting-started/","title":"Getting Started with PyAgentic","text":"<p>PyAgentic is a declarative framework for building AI agents with support for multiple LLM providers including OpenAI, Anthropic, and others. This guide will walk you through building a research assistant agent step by step, introducing each core concept along the way.</p>"},{"location":"getting-started/#installation","title":"Installation","text":"<p>First, install PyAgentic:</p> <pre><code>pip install pyagentic-core\n</code></pre> <p>You'll also need an API key from your chosen LLM provider (OpenAI, Anthropic, etc.) for this tutorial.</p>"},{"location":"getting-started/#why-pyagentic","title":"Why PyAgentic?","text":"<p>Imagine you're a researcher who needs to organize papers, extract key insights, and generate summaries. You want an AI assistant that can:</p> <ul> <li>Remember what papers you've added to your collection</li> <li>Extract and summarize key findings from papers</li> <li>Answer questions about your research collection</li> <li>Maintain context across conversations</li> </ul> <p>This is exactly the kind of stateful, tool-equipped agent that PyAgentic makes easy to build.</p>"},{"location":"getting-started/#choosing-your-llm-provider","title":"Choosing Your LLM Provider","text":"<p>PyAgentic supports multiple LLM providers out of the box. You can configure your agent to use any supported provider:</p>"},{"location":"getting-started/#supported-providers","title":"Supported Providers","text":"<ul> <li>OpenAI: GPT-4, GPT-3.5, and other OpenAI models</li> <li>Anthropic: Claude models with full tool calling support</li> <li>Mock: For testing and development without API costs</li> </ul>"},{"location":"getting-started/#provider-configuration-methods","title":"Provider Configuration Methods","text":"<p>You can configure providers in two ways:</p> <p>Model String Format <pre><code>agent = MyAgent(\n    model=\"&lt;provider&gt;::&lt;model_name&gt;\",\n    api_key=\"your_api_key\"\n)\n\nopenai_agent = MyAgent(\n    model=\"openai::gpt-5\",\n    api_key=\"your_api_key\"\n)\n\nanthropic_agent = MyAgent(\n    model=\"anthropic::claude-opus-4-1-20250805\",\n    api_key=\"your_api_key\"\n)\n</code></pre></p> <p>Provider Instance <pre><code>from pyagentic.llm import OpenAIProvider, AnthropicProvider\n\n# OpenAI\nagent = MyAgent(\n    provider=OpenAIProvider(\n        model=\"gpt-5\",\n        api_key=\"your_openai_key\",\n        max_retries=10,\n        timeout=5\n    )\n)\n\n# Anthropic\nagent = MyAgent(\n    provider=AnthropicProvider(\n        model=\"claude-opus-4-1-20250805\",\n        api_key=\"your_anthropic_key\",\n        base_url=\"https://my-deployment.com/models\"\n    )\n)\n</code></pre></p> <p>The provider instance method gives you more control over client configuration, allowing you to pass additional parameters like <code>base_url</code>, <code>timeout</code>, <code>max_retries</code>, etc.</p>"},{"location":"getting-started/#step-1-your-first-agent","title":"Step 1: Your First Agent","text":"<p>Let's start by creating a simple research assistant agent:</p> <pre><code>from pyagentic import BaseAgent\n\nclass ResearchAgent(BaseAgent):\n    \"\"\"An AI assistant for managing and analyzing research papers.\"\"\"\n\n    __system_message__ = \"\"\"\n    You are a research assistant that helps organize and analyze academic papers.\n    You maintain a collection of research papers and can answer questions about them.\n    You are knowledgeable, precise, and helpful in academic contexts.\n    \"\"\"\n</code></pre> <p>This creates a basic conversational agent, but it can't do much beyond chat. Let's add some memory and capabilities.</p>"},{"location":"getting-started/#step-2-adding-state-with-state-fields","title":"Step 2: Adding State with State Fields","text":"<p>Real research assistants need to remember things! Let's add some persistent state to track the papers in our collection:</p> <pre><code>from pyagentic import BaseAgent, State, spec\nfrom typing import List, Dict\nfrom collections import defaultdict\n\nfrom arxiv import Result as Paper\n\nclass ResearchAgent(BaseAgent):\n    \"\"\"An AI assistant for managing and analyzing research papers.\"\"\"\n\n    __system_message__ = \"\"\"\n    You are a research assistant that helps organize and analyze academic papers.\n    You have full access to the Arxiv\n\n    Available topics: {available_topics}\n\n    Use your tools to help users manage and analyze their research collection.\n    Feel free to use many tools at once\n    \"\"\"\n\n    __input_template__ = \"\"\"\n    Current Topic: {current_topic}\n\n    User Message: {user_message}\n    \"\"\"\n\n    papers: State[Dict[str, List[Paper]]] = spec.State(default_factory=lambda: defaultdict(list))\n    current_topic: State[str] = spec.State(default=\"General Research\")\n</code></pre> <p>Now our agent has memory! The <code>papers</code> dict and <code>current_topic</code> string persist between conversations. Notice how we reference <code>{available_topics}</code> in the system message - we'll make that work next using Pydantic computed fields.</p>"},{"location":"getting-started/#step-3-adding-tools-for-actions","title":"Step 3: Adding Tools for Actions","text":"<p>Let's give our agent the ability to actually search and papers by adding tools:</p> <pre><code>@tool(\"Search the Arxiv for relevant papers\")\ndef search(\n    self,\n    terms: list[str] = spec.Param(required=True, description=\"Terms you think are relevant to the user's query. Be creative\")\n) -&gt; str:\n    print(f\"Searching terms: {terms}\")\n    found = []\n    for term in terms:\n        results = search_arxiv(term)\n        found.extend(results)\n    return json.dumps(found, indent=2)\n\n@tool(\"Add a new paper to the research collection\")\ndef add_paper(\n    self,\n    paper_id: str = spec.Param(required=True, description=\"ID of the paper from search results\"),\n    topic: str = spec.Param(\n        required=False,\n        description=\"Research topic/area\",\n    )\n) -&gt; str:\n    print(f\"Adding {paper_id} to {topic}\")\n    paper = get_paper(paper_id)\n    self.state.papers[topic].append(paper)\n    return f\"Added paper '{paper.title}' by {paper.authors} to your collection under topic '{topic}'.\"\n</code></pre> <p>Now our agent can perform actions! The <code>@tool</code> decorator exposes methods to the AI, and <code>spec.Param()</code> helps define parameter requirements and descriptions.</p> <p>A problem may arise here, asking the LLM to generate raw paper ids may lead to hallucination...</p>"},{"location":"getting-started/#step-4-pydantic-computed-fields-for-dynamic-values","title":"Step 4: Pydantic Computed Fields for Dynamic Values","text":"<p>This can be solved by passing over values to the param, ensuring the LLM will only pick from that list.</p> <p>To do so, we need to create a Pydantic model with computed fields and use <code>ref</code> to reference them.</p> <p>Pydantic's <code>@computed_field</code> decorator works like Python <code>@property</code> - each time it's accessed, it's recalculated. Let's create a state model with computed fields:</p> <pre><code>from pydantic import BaseModel, computed_field\n\nclass ResearchState(BaseModel):\n    papers: Dict[str, List[Paper]] = defaultdict(list)\n    current_topic: str = \"General Research\"\n\n    @computed_field\n    @property\n    def available_topics(self) -&gt; List[str]:\n        \"\"\"Extract unique topics from paper summaries and titles\"\"\"\n        return list(self.papers.keys())\n\n    @computed_field\n    @property\n    def paper_ids(self) -&gt; List[str]:\n        \"\"\"Get list of all paper titles for reference\"\"\"\n        return [paper.get_short_id() for paper in self.papers.get(self.current_topic, [])]\n\nclass ResearchAgent(BaseAgent):\n    # ... system message ...\n\n    state: State[ResearchState] = spec.State(default_factory=ResearchState)\n\n    @tool(\"Add a new paper to the research collection\")\n    def add_paper(\n        self,\n        paper_id: str = spec.Param(\n            required=True,\n            description=\"ID of the paper from search results\",\n            values=ref.state.paper_ids  # Reference computed field!\n        ),\n        topic: str = spec.Param(\n            required=False,\n            description=\"Research topic/area\",\n            values=ref.state.available_topics  # Dynamic options!\n        )\n    ) -&gt; str:\n        print(f\"Adding {paper_id} to {topic}\")\n        paper = get_paper(paper_id)\n        self.state.papers[topic].append(paper)\n        return f\"Added paper '{paper.title}' by {paper.authors} to your collection under topic '{topic}'.\"\n</code></pre> <p>This will ensure that the LLM chooses specific values when calling the tool. The <code>ref.state.available_topics</code> creates a reference that's resolved at runtime.</p>"},{"location":"getting-started/#step-5-complete-agent-with-ref","title":"Step 5: Complete Agent with ref","text":"<p>Let's put it all together while adding a couple more features to make it more complete, like:     - Setting the focus     - Read a paper</p> <pre><code>from pyagentic import BaseAgent, State, spec, tool, ref\nfrom pydantic import BaseModel, computed_field\nfrom typing import List, Dict\nfrom collections import defaultdict\n\nfrom utils import read_paper, get_paper, search_arxiv\nfrom arxiv import Result as Paper\n\nclass ResearchState(BaseModel):\n    papers: Dict[str, List[Paper]] = defaultdict(list)\n    current_topic: str = \"General Research\"\n\n    @computed_field\n    @property\n    def available_topics(self) -&gt; List[str]:\n        \"\"\"Extract unique topics from paper summaries and titles\"\"\"\n        return list(self.papers.keys())\n\n    @computed_field\n    @property\n    def paper_titles(self) -&gt; List[str]:\n        \"\"\"Get list of all paper titles for reference\"\"\"\n        return [paper.title for paper in self.papers.get(self.current_topic, [])]\n\n    @computed_field\n    @property\n    def paper_ids(self) -&gt; List[str]:\n        \"\"\"Get list of all paper IDs for reference\"\"\"\n        return [paper.get_short_id() for paper in self.papers.get(self.current_topic, [])]\n\nclass ResearchAgent(BaseAgent):\n    \"\"\"An AI assistant for managing and analyzing research papers.\"\"\"\n\n    __system_message__ = \"\"\"\n    You are a research assistant that helps organize and analyze academic papers.\n    You have full access to the Arxiv\n\n    Available topics: {available_topics}\n\n    Use your tools to help users manage and analyze their research collection.\n    Feel free to use many tools at once\n    \"\"\"\n\n    __input_template__ = \"\"\"\n    Current Topic: {current_topic}\n\n    User Message: {user_message}\n    \"\"\"\n\n    state: State[ResearchState] = spec.State(default_factory=ResearchState)\n\n    @tool(\"Search the Arxiv for relevant papers\")\n    def search(\n        self,\n        terms: list[str] = spec.Param(required=True, description=\"Terms you think are relevant to the user's query. Be creative\")\n    ) -&gt; str:\n        print(f\"Searching terms: {terms}\")\n        found = []\n        for term in terms:\n            results = search_arxiv(term)\n            found.extend(results)\n        return json.dumps(found, indent=2)\n\n    @tool(\"Add a new paper to the research collection\")\n    def add_paper(\n        self,\n        paper_id: str = spec.Param(\n            required=True,\n            description=\"ID of the paper from search results\",\n            values=ref.paper_ids\n        ),\n        topic: str = spec.Param(\n            required=False,\n            description=\"Research topic/area\",\n            values=ref.available_topics  # Dynamic options!\n        )\n    ) -&gt; str:\n        print(f\"Adding {paper_id} to {topic}\")\n        paper = get_paper(paper_id)\n        self.papers[topic].append(paper)\n        return f\"Added paper '{paper.title}' by {paper.authors} to your collection under topic '{topic}'.\"\n\n    @tool(\"Read the entire content of a paper\")\n    def read_paper(\n        self,\n        title: str = spec.Param(\n            required=True,\n            description=\"Exact title of the paper to get details for\",\n            values=ref.paper_titles  # Only allow existing paper titles!\n        )\n    ) -&gt; str:\n        print(f\"Reading {title}\")\n        current_topic = self.current_topic\n        for paper in self.papers[current_topic]:\n            if title in paper.title:\n                return read_paper(paper)\n        return f\"Paper '{title}' not found in collection.\"\n\n    @tool(\"Update research focus topic, call this whenever you feel the subject has changed. Always call this before other tools if the subject has changed\")\n    def set_focus_topic(\n        self,\n        topic: str = spec.Param(\n            required=True,\n            description=\"New research focus topic\",\n        )\n    ) -&gt; str:\n        print(f\"New focus: {topic}\")\n        self.current_topic = topic\n        return f\"Research focus updated to: {topic}\"\n</code></pre> <p>Now our tools are much smarter! The <code>ref</code> system creates dynamic constraints: - When adding papers, the <code>topic</code> parameter will only suggest topics that already exist in our collection - When getting paper details, the agent can only choose from actual paper titles - The available options update automatically as we add more papers</p>"},{"location":"getting-started/#step-6-lets-run-it","title":"Step 6: Let's run it!","text":"<p>First, we have to create our agent.</p> <pre><code># Option 1: Using model string format\nagent = ResearchAgent(\n    model=\"openai::gpt-4o\",\n    api_key=API_KEY\n)\n\n# Option 2: Using a provider instance\nfrom pyagentic.llm import OpenAIProvider\n\nagent = ResearchAgent(\n    provider=OpenAIProvider(\n        model=\"gpt-4o\",\n        api_key=API_KEY\n    )\n)\n</code></pre> <p>Now lets run a couple messages through to see if it is working?</p> Set FocusFind PapersAdd PapersAnalyze <pre><code>await agent('''\nIm trying to find a link between ai usage and climate change\n''')\n</code></pre> <pre><code>New focus: AI and Climate Change\n</code></pre> <p>Let's explore research papers linking AI usage and climate change. I'll look for recent studies on this topic. Please hold on for a moment.Here are some research areas and findings regarding the connection between AI usage and climate change:</p> <ol> <li> <p>AI in Climate Modeling: AI helps improve climate models by enhancing predictions of weather patterns, temperature changes, and extreme events like hurricanes. Machine learning algorithms can analyze vast datasets to improve climate forecasts.</p> </li> <li> <p>Monitoring and Reducing Emissions: AI aids in monitoring industrial emissions and optimizing energy consumption in various sectors, potentially reducing overall carbon footprints. Smart grids and AI-enhanced energy management systems help in efficient resource usage.</p> </li> <li> <p>Environmental Data Analysis:</p> </li> <li> <p>AI processes environmental data from satellites and sensors to monitor deforestation, glacial melting, and other climate-related changes. This helps in providing timely insights for environmental protection efforts.</p> </li> <li> <p>Sustainable Practices: Machine learning supports the development of sustainable agricultural practices by analyzing crop yield data and predicting suitable planting strategies, reducing waste and resource usage.</p> </li> <li> <p>AI's Carbon Footprint: Training AI models is energy-intensive, contributing to carbon emissions. Research is exploring more efficient algorithms and hardware to mitigate these effects.</p> </li> </ol> <p>Would you like to dive deeper into any specific area or look for more detailed research papers?</p> <pre><code>response = await agent('''\nYa! Find some papers around AI's Carbon Footprint\n''')\n</code></pre> <pre><code>Searching terms: ['AI carbon footprint', 'energy consumption AI', 'AI environmental impact']\n</code></pre> <p>Here are some papers related to AI's carbon footprint:</p> <ol> <li> <p>Integrating AI's Carbon Footprint into Risk Management Frameworks: Strategies and Tools for Sustainable Compliance in Banking Sector Author: Nataliya Tkachenko This paper explores integrating AI\u2019s carbon footprint into risk management in the banking sector, highlighting advancements like energy-efficient models and green cloud computing. Read more</p> </li> <li> <p>Carbon-Aware End-to-End Data Movement Authors: Jacob Goldverg, Hasibul Jamil, Elvis Rodriguez, Tevfik Kosar Investigates carbon emissions from data movement in cloud computing and proposes optimization strategies for reducing energy consumption. Read more</p> </li> <li> <p>Making AI Less \"Thirsty\": Uncovering and Addressing the Secret Water Footprint of AI Models Authors: Pengfei Li, Jianyi Yang, Mohammad A. Islam, Shaolei Ren Tackles AI's overlooked water consumption, highlighting the necessity to address both water and carbon footprints for sustainable AI. Read more</p> </li> <li> <p>Towards Environmentally Equitable AI via Geographical Load Balancing Authors: Pengfei Li, Jianyi Yang, Adam Wierman, Shaolei Ren Proposes equity-aware geographical load balancing to address regional disparities in AI's environmental impact. Read more</p> </li> <li> <p>CAFE: Carbon-Aware Federated Learning in Geographically Distributed Data Centers Authors: Jieming Bian, Lei Wang, Shaolei Ren, Jie Xu Introduces a framework for carbon-aware federated learning to optimize training across distributed data centers while considering carbon intensity. Read more</p> </li> </ol> <p>If you want to explore any specific paper in detail, let me know!</p> <pre><code>response = await agent('''\nAdd the papers that you think are the most relevant to linking AI and carbon\n''')\n</code></pre> <pre><code>Adding 2410.01818v1 to AI and Climate Change\nAdding 2406.09650v1 to AI and Climate Change\nAdding 2304.03271v5 to AI and Climate Change\nAdding 2407.05176v1 to AI and Climate Change\n</code></pre> <p>I've added the most relevant papers connecting AI and carbon emissions to your collection. If you need further assistance or wish to explore more papers, feel free to ask!</p> <pre><code>response = await agent('''\nAnalyze these papers and tell me what you learned with citiations\n''')\n</code></pre> <pre><code>Reading Integrating AI's Carbon Footprint into Risk Management Frameworks: Strategies and Tools for Sustainable Compliance in Banking Sector\nReading Carbon-Aware End-to-End Data Movement\nReading Making AI Less \"Thirsty\": Uncovering and Addressing the Secret Water Footprint of AI Models\nReading Towards Socially and Environmentally Responsible AI\n</code></pre> <p>Here's a summary and analysis of the selected papers linking AI and carbon:</p> <ol> <li>Integrating AI's Carbon Footprint into Risk Management Frameworks (Tkachenko, 2024)</li> </ol> <p>Overview: This paper discusses how AI's carbon footprint can be integrated into the banking sector's risk management frameworks (RMFs). It highlights the regulatory requirements driving financial institutions to consider environmental impacts within AI governance. Key Insights: AI models in banking require significant energy, contributing to carbon emissions. Efficient AI models and green cloud computing practices are recommended strategies to mitigate these impacts. Importance: Integrating AI's carbon footprint into RMFs can help banks comply with sustainability regulations and demonstrate environmental responsibility.</p> <ol> <li>Carbon-Aware End-to-End Data Movement (Goldverg et al., 2024)</li> </ol> <p>Overview: This study focuses on measuring and optimizing the carbon footprint of data movement across networks, a significant contributor to AI-related carbon emissions. Key Insights: The paper introduces carbon-aware scheduling strategies that optimize data transfer times and routes to reduce carbon emissions. It highlights the need for detailed monitoring of network paths and end systems. Importance: Addressing the carbon footprint in data movement is crucial for reducing the total carbon emissions associated with AI workloads.</p> <ol> <li>Making AI Less \"Thirsty\" (Li et al., 2025)</li> </ol> <p>Overview: This paper uncovers the water footprint of AI models, emphasizing that AI's environmental impact extends beyond carbon emissions to significant water consumption, particularly in data center cooling. Key Insights: The water consumption associated with AI could become a major ecological challenge. The study presents methodologies to estimate and reduce AI's water footprint. Importance: Highlighting AI's water usage as a crucial aspect of its environmental footprint encourages more holistic sustainability strategies.</p> <ol> <li>Towards Socially and Environmentally Responsible AI (Li et al., 2024)</li> </ol> <p>Overview: The paper proposes equitable geographical load balancing (GLB) to address AI's social and environmental inequalities, ensuring fair distribution of AI's benefits and burdens across regions. Key Insights: The disparities in AI's resource allocation can lead to environmental and social inequity. Implementing equity-aware GLB can balance AI's negative impacts more fairly across regions. Importance: By promoting social and environmental equity, this approach aims to foster responsible AI deployment.</p> <p>If you want further analysis or details on specific papers, feel free to let me know!</p>"},{"location":"getting-started/#conclusion","title":"Conclusion","text":"<p>The research underscores the multifaceted environmental impacts of AI, including carbon and water footprints, and stresses the importance of equitable resource distribution. The integration of these concerns into frameworks such as RMFs in banking and carbon-aware scheduling in data movement are vital steps towards sustainable AI practices.</p>"},{"location":"getting-started/#what-makes-this-powerful","title":"What Makes This Powerful","text":"<p>Our research assistant demonstrates all of PyAgentic's key strengths:</p> <ol> <li>Declarative Design: We define what the agent should do, not how</li> <li>Persistent State: The agent remembers papers across conversations via State fields</li> <li>Dynamic Intelligence: Tools adapt their constraints based on current data using <code>ref</code></li> <li>Type Safety: All parameters are properly typed and validated</li> <li>Pydantic Integration: Leverage Pydantic's computed fields for reactive state</li> <li>Natural Evolution: Easy to add new capabilities without breaking existing functionality</li> </ol>"},{"location":"getting-started/#controlling-tool-usage-with-max_call_depth","title":"Controlling Tool Usage with max_call_depth","text":"<p>By default, PyAgentic agents can only call tools once per conversation turn, then must provide a final response. This prevents endless tool-calling loops but might limit complex workflows. You can control this behavior with the <code>max_call_depth</code> parameter:</p> <pre><code># Allow multiple rounds of tool calling\nagent = ResearchAgent(\n    model=\"openai::gpt-4o\",\n    api_key=API_KEY,\n    max_call_depth=3  # Allow up to 3 rounds of tool calls\n)\n</code></pre>"},{"location":"getting-started/#how-max_call_depth-works","title":"How max_call_depth Works","text":"<ul> <li>Depth 0: Agent can call tools, then must respond</li> <li>Depth 1 (default): After tools execute, agent can call more tools or respond  </li> <li>Depth 2+: Agent can continue calling tools in multiple rounds</li> </ul> <p>Each \"depth\" represents a full round of tool calling. Within each round, the agent can make multiple parallel tool calls, but after each round completes, it decides whether to call more tools or give a final answer.</p>"},{"location":"getting-started/#when-to-increase-max_call_depth","title":"When to Increase max_call_depth","text":"<p>Use higher depths (2-4) when your agent needs to: - Search for information, then analyze what it found - Read multiple files and synthesize information - Perform multi-step research or analysis - Chain tool outputs together</p> <p>Keep default (1) when your agent: - Has simple, single-purpose tools - Should respond quickly without complex workflows - Might get stuck in tool-calling loops</p>"},{"location":"getting-started/#example-research-agent-with-multiple-depths","title":"Example: Research Agent with Multiple Depths","text":"<pre><code>With max_call_depth=1 (default):\nUser: \"Research AI and climate change\" \n  \u2192 Agent calls search() \u2192 Responds with results\n\nWith max_call_depth=3:\nUser: \"Research AI and climate change\"\n  \u2192 Depth 0: Agent calls search()  \n  \u2192 Depth 1: Agent calls add_paper() for multiple papers\n  \u2192 Depth 2: Agent calls read_paper() to analyze content\n  \u2192 Final response with comprehensive analysis\n</code></pre> <p>This allows your agent to perform sophisticated multi-step workflows while preventing infinite loops.</p>"},{"location":"getting-started/#key-concepts-summary","title":"Key Concepts Summary","text":"<ul> <li><code>BaseAgent</code>: Base class that handles LLM provider integration and orchestration</li> <li><code>State[T]</code>: Persistent state fields that survive between conversations, typed with Pydantic models</li> <li><code>spec.State()</code>: Factory for creating state fields with defaults and configuration</li> <li><code>@tool</code>: Decorator that exposes methods as callable functions to the AI</li> <li><code>spec.Param()</code>: Metadata for tool parameters (descriptions, requirements, defaults, values)</li> <li><code>@computed_field</code>: Pydantic decorator for dynamic properties that recalculate on each access</li> <li><code>ref</code>: Reference system that links tool parameters to live state data for smart constraints</li> <li><code>max_call_depth</code>: Controls how many rounds of tool calling are allowed per turn</li> </ul>"},{"location":"getting-started/#next-steps","title":"Next Steps","text":"<p>Now you're ready to build sophisticated AI agents! Try:</p> <ul> <li>Adding more complex tools (file I/O, API calls, data analysis)</li> <li>Creating multi-agent systems that collaborate</li> <li>Building domain-specific agents for your use cases</li> <li>Exploring advanced context patterns and validation</li> </ul> <p>The declarative nature of PyAgentic makes it easy to iterate and extend your agents as your needs grow.</p>"},{"location":"inheritance/","title":"Agent Inheritance","text":"<p>PyAgentic supports standard Python inheritance, allowing you to build agent hierarchies that share tools, context, and functionality. You can also use extensions to add cross-cutting capabilities to multiple agents without deep inheritance chains.</p>"},{"location":"inheritance/#how-inheritance-works","title":"How Inheritance Works","text":"<p>Agent inheritance follows Python's standard rules with some PyAgentic-specific behaviors. When you inherit from an agent, you get all its tools, context items, and linked agents. However, each agent must define its own system message to maintain clear identity and purpose.</p> <p>PyAgentic builds the complete agent schema at class definition time, combining inherited elements with new ones to create a fully-typed, predictable agent interface.</p>"},{"location":"inheritance/#inheritance-rules","title":"Inheritance Rules","text":"<p>PyAgentic follows specific rules about what gets inherited and what must be redefined:</p>"},{"location":"inheritance/#what-gets-inherited","title":"What Gets Inherited \u2705","text":"<ul> <li>Tools - All <code>@tool</code> methods are inherited and can be overridden</li> <li>State Fields - <code>State</code> fields inherit with their defaults and types</li> <li>Linked Agents - Agent references are inherited, child classes can add more</li> <li>Properties - Dynamic properties are inherited and overridable</li> </ul>"},{"location":"inheritance/#what-must-be-redefined","title":"What Must Be Redefined \u274c","text":"<ul> <li>System Messages - Each agent must define its own <code>__system_message__</code> to maintain clear identity</li> <li>Input Templates - <code>__input_template__</code> is not inherited, allowing agent-specific formatting</li> </ul> <p>This design ensures that while agents can share functionality, each maintains its own distinct purpose and behavior.</p>"},{"location":"inheritance/#basic-inheritance","title":"Basic Inheritance","text":"<p>Extend agents using normal Python inheritance to build specialized capabilities on top of base functionality:</p> <pre><code>class BaseAssistantAgent(BaseAgent):\n    __system_message__ = \"I am a helpful AI assistant\"\n\n    user_name: State[str] = spec.State(default=\"User\")\n    session_id: State[str] = spec.State(default=\"\")\n    conversation_context: State[str] = spec.State(default=\"\")\n\n    @tool(\"Get current timestamp\")\n    def get_timestamp(self) -&gt; str: ...\n\n    @tool(\"Read a file in the current directory\")\n    def count_words(self, file_name: str) -&gt; int: ...\n\n    @tool(\"Update conversation context\")\n    def update_context(self, new_context: str) -&gt; str: ...\n\nclass CodeAssistantAgent(BaseAssistantAgent):\n    __system_message__ = \"I help with programming tasks and code review\"\n\n    # Inherit user_name, session_id, conversation_context, and basic tools\n    # Add coding-specific state\n    preferred_language: State[str] = spec.State(default=\"python\")\n    current_project: State[str] = spec.State(default=\"\")\n    debug_mode: State[bool] = spec.State(default=False)\n\n    @tool(\"Format code snippet\")\n    def format_code(self, code: str, language: str = None) -&gt; str: ...\n\n    @tool(\"Generate code documentation\")\n    def document_code(self, code: str) -&gt; str: ...\n</code></pre> <p>The <code>CodeAssistantAgent</code> inherits all the basic functionality from <code>BaseAssistantAgent</code> (user tracking, session management, conversation context) while adding its own specialized tools for code formatting and documentation. This creates a clean hierarchy where common assistant behaviors are shared but specific domains add their own capabilities.</p> <p>Inheritance also works with tool overriding to enhance parent functionality:</p> <pre><code>class AdvancedCodeAssistantAgent(CodeAssistantAgent):\n    __system_message__ = \"I provide advanced programming assistance with security analysis\"\n\n    # Override parent tool with enhanced functionality\n    @tool(\"Format and validate code snippet\")\n    def format_code(self, code: str, language: str = None, formatting_style: str = None) -&gt; str: ...\n</code></pre>"},{"location":"inheritance/#agent-extensions","title":"Agent Extensions","text":"<p>Extensions allow you to add cross-cutting functionality to multiple agents without creating deep inheritance hierarchies. They're perfect for capabilities like logging, authentication, or caching that many different agents might need.</p>"},{"location":"inheritance/#creating-extensions","title":"Creating Extensions","text":"<p>Extensions inherit from <code>AgentExtension</code> and can include tools, context items, and computed context:</p> <pre><code>class FileOperationsExtension(AgentExtension):\n    base_directory: State[str] = spec.State(default=\"./workspace\")\n\n    @tool(\"Read file contents\")\n    def read_file(self, filename: str) -&gt; str: ...\n\n    @tool(\"Write content to file\")\n    def write_file(self, filename: str, content: str) -&gt; str: ...\n\nclass WebSearchExtension(AgentExtension):\n    max_results: State[int] = spec.State(default=5)\n\n    @tool(\"Search the web for information\")\n    def web_search(self, query: str) -&gt; str: ...\n\n    @tool(\"Get webpage content\")\n    def get_webpage(self, url: str) -&gt; str: ...\n</code></pre>"},{"location":"inheritance/#using-extensions","title":"Using Extensions","text":"<p>Simply include extensions in your agent's inheritance list:</p> <pre><code>class ResearchAgent(BaseAgent, FileOperationsExtension, WebSearchExtension):\n    __system_message__ = \"I help with research by searching the web and managing files\"\n\n    research_topic: State[str] = spec.State(default=\"\")\n\n    @tool(\"Conduct comprehensive research\")\n    def research_topic(self, topic: str) -&gt; str: ...\n</code></pre> <p>The agent automatically gets all tools and context from both extensions, creating a powerful composition pattern.</p>"},{"location":"inheritance/#method-resolution-order-mro","title":"Method Resolution Order (MRO)","text":"<p>When using multiple extensions or inheritance, Python's Method Resolution Order (MRO) determines which implementation is used when there are conflicts. PyAgentic follows Python's C3 linearization:</p> <pre><code>class MemoryExtension(AgentExtension):\n    @tool(\"Remember information\")\n    def remember(self, info: str) -&gt; str: ...\n\nclass ConversationExtension(AgentExtension):\n    @tool(\"Remember information\")\n    def remember(self, info: str) -&gt; str: ...\n\nclass ChatbotAgent(BaseAgent, MemoryExtension, ConversationExtension):\n    __system_message__ = \"I am a conversational AI\"\n\n# MRO: ChatbotAgent -&gt; MemoryExtension -&gt; ConversationExtension -&gt; BaseAgent\n# The MemoryExtension.remember() method will be used\n</code></pre> <p>You can check the MRO with <code>ChatbotAgent.__mro__</code> to understand the resolution order. Extensions listed first in the inheritance list take precedence.</p>"},{"location":"observability/","title":"Observability","text":"<p>PyAgentic provides built-in observability through tracing, allowing you to monitor and understand how your agents work. This guide covers the basics of tracing and how to set up different tracers.</p>"},{"location":"observability/#what-are-traces","title":"What are Traces?","text":"<p>Traces help you observe the execution flow of your agents by recording what happens during agent runs. A trace represents a complete execution path, made up of individual spans that capture specific operations.</p> <p>Think of a trace like a detailed log of everything your agent does: - When it starts thinking about a problem - When it calls tools or external services - When it makes inference calls to language models - When it finishes a task</p>"},{"location":"observability/#span-types","title":"Span Types","text":"<p>PyAgentic supports four types of spans to categorize different operations:</p> <ul> <li>Agent spans (<code>SpanKind.AGENT</code>): Track high-level agent operations and workflows</li> <li>Tool spans (<code>SpanKind.TOOL</code>): Monitor tool executions and external API calls</li> <li>Inference spans (<code>SpanKind.INFERENCE</code>): Capture language model interactions and generations</li> <li>Step spans (<code>SpanKind.STEP</code>): Record individual steps within larger operations</li> </ul> <p>Each span captures timing information, attributes, and can include events for detailed logging.</p>"},{"location":"observability/#available-tracers","title":"Available Tracers","text":"<p>PyAgentic includes two built-in tracers:</p>"},{"location":"observability/#basictracer","title":"BasicTracer","text":"<p>An in-memory tracer that stores traces locally in Python dictionaries. Perfect for development, testing, and simple use cases.</p> <p>The BasicTracer is the simplest way to get started with tracing. It stores all trace data in memory and provides export functionality.</p> <pre><code>from pyagentic import BaseAgent\n\nclass YourAgent(BaseAgent):\n    __system_message__ = \"Your agent description\"\n    # ... your agent implementation ...\n\n# Create an agent - The BasicTracer is the default tracer of any declared agent\nagent = YourAgent(\n    model=\"openai::gpt-4o\",\n    api_key=MY_API_KEY,\n)\n\n# Run your agent\nresult = await agent(\"Your task here\")\n</code></pre>"},{"location":"observability/#basictracer-features","title":"BasicTracer Features","text":"<ul> <li>In-memory storage: All data stored locally, no external dependencies</li> <li>Export functionality: Get trace data as JSON for analysis or debugging</li> <li>Thread-safe: Safe to use with concurrent operations</li> <li>Reset option: Clear traces after export to manage memory usage</li> </ul> <pre><code># Export a specific trace and clear it from memory\ntrace_data = tracer.export_trace(trace_id, reset=True)\n\n# Clear all stored traces\ntracer.clear()\n</code></pre>"},{"location":"observability/#langfusetracer","title":"LangfuseTracer","text":"<p>Integrates with Langfuse for production-grade observability with advanced analytics, dashboards, and collaboration features.</p> <p>The LangfuseTracer provides enterprise-grade observability by forwarding traces to Langfuse.</p>"},{"location":"observability/#setup","title":"Setup","text":"<p>First, install the Langfuse SDK:</p> <pre><code>pip install langfuse\n</code></pre> <p>Configure your Langfuse connection using environment variables:</p> <pre><code>export LANGFUSE_SECRET_KEY=\"your-secret-key\"\nexport LANGFUSE_PUBLIC_KEY=\"your-public-key\"\nexport LANGFUSE_HOST=\"https://cloud.langfuse.com\"  # or your self-hosted instance\n</code></pre>"},{"location":"observability/#usage","title":"Usage","text":"<pre><code>from pyagentic import BaseAgent\nfrom pyagentic.tracing import LangfuseTracer\n\nclass YourAgent(BaseAgent):\n    __system_message__ = \"Your agent description\"\n    # ... your agent implementation ...\n\n# Create an agent with the tracer\nagent = YourAgent(\n    model=\"openai::gpt-4o\",\n    api_key=MY_API_KEY,\n    tracer=LangfuseTracer()\n)\n\n# Run your agent - traces will be sent to Langfuse\nresult = await agent(\"Your task here\")\n</code></pre>"},{"location":"observability/#langfusetracer-features","title":"LangfuseTracer Features","text":"<ul> <li>Real-time streaming: Traces sent to Langfuse as they happen</li> <li>Rich UI: View traces in the Langfuse dashboard with advanced filtering and analytics</li> <li>Cost tracking: Automatic LLM usage and cost monitoring</li> <li>Collaboration: Share traces with team members</li> <li>Production-ready: Built for high-volume production workloads</li> </ul>"},{"location":"observability/#choosing-a-tracer","title":"Choosing a Tracer","text":"<p>Use BasicTracer when: - Developing and testing agents locally - Simple debugging scenarios - No external dependencies desired - Working with sensitive data that must stay local</p> <p>Use LangfuseTracer when: - Running agents in production - Need advanced analytics and monitoring - Want to share traces with team members - Require cost tracking and optimization insights - Building user-facing applications</p>"},{"location":"phases/","title":"Phases","text":"<p>Phases are a finite state machine (FSM) system that allows agents to progress through different operational states. This powerful feature enables you to create agents with structured workflows, conditional tool availability, and context-aware behavior based on the current execution phase.</p>"},{"location":"phases/#overview","title":"Overview","text":"<p>Phases allow you to:</p> <ul> <li>Structure agent workflows into distinct operational stages</li> <li>Control tool availability based on the current phase</li> <li>Customize prompts dynamically using phase-aware templates</li> <li>Define state transitions with custom condition functions</li> <li>Build complex multi-stage agents with clear progression logic</li> </ul>"},{"location":"phases/#basic-usage","title":"Basic Usage","text":"<p>Define phases on your agent class using the <code>phases</code> class variable:</p> <pre><code>from pyagentic import BaseAgent, tool, spec\n\nclass ResearchAgent(BaseAgent):\n    __system_message__ = \"\"\"\n    You are a research agent.\n    Current phase: {{ phase }}\n    {% if phase == \"planning\" %}\n    Focus on creating a research plan.\n    {% elif phase == \"research\" %}\n    Execute the research plan and gather data.\n    {% elif phase == \"analysis\" %}\n    Analyze the gathered data and form conclusions.\n    {% endif %}\n    \"\"\"\n\n    research_plan: spec.State[str] = spec.State(default=\"\")\n    data: spec.State[list[str]] = spec.State(default_factory=list)\n\n    # Define phase transitions: (from_state, to_state, condition_function)\n    phases = [\n        (\"planning\", \"research\", lambda self: bool(self.state.research_plan)),\n        (\"research\", \"analysis\", lambda self: len(self.state.data) &gt;= 3),\n    ]\n\n    @tool(\"Create a research plan\", phases=[\"planning\"])\n    def create_plan(self, topic: str, approach: str) -&gt; str:\n        self.research_plan = f\"Research {topic} using {approach}\"\n        return f\"Plan created: {self.research_plan}\"\n\n    @tool(\"Gather research data\", phases=[\"research\"])\n    def gather_data(self, query: str) -&gt; str:\n        # Simulate data gathering\n        result = f\"Data for: {query}\"\n        self.data.append(result)\n        return result\n\n    @tool(\"Analyze data\", phases=[\"analysis\"])\n    def analyze(self) -&gt; str:\n        return f\"Analysis of {len(self.data)} data points\"\n</code></pre>"},{"location":"phases/#phase-definition","title":"Phase Definition","text":"<p>Phases are defined as a list of tuples with three elements:</p> <pre><code>phases = [\n    (source_state, destination_state, condition_function),\n    # ...\n]\n</code></pre> <ul> <li>source_state (<code>str</code>): The current phase name</li> <li>destination_state (<code>str</code>): The target phase name</li> <li>condition_function (<code>Callable</code>): A function that receives the agent instance and returns <code>True</code> when the transition should occur</li> </ul>"},{"location":"phases/#condition-functions","title":"Condition Functions","text":"<p>Condition functions determine when a phase transition should happen. They receive the agent instance (<code>self</code>) and have access to all state and properties:</p> <pre><code># Transition when a specific state field is populated\n(\"planning\", \"execution\", lambda self: bool(self.state.plan))\n\n# Transition based on multiple conditions\n(\"gathering\", \"analysis\", lambda self: len(self.state.items) &gt; 5 and self.state.quality_check)\n\n# Transition based on complex logic\n(\"draft\", \"review\", lambda self: self._is_complete())\n</code></pre>"},{"location":"phases/#phase-aware-tools","title":"Phase-Aware Tools","text":"<p>Tools can be restricted to specific phases using the <code>phases</code> parameter in the <code>@tool</code> decorator:</p> <pre><code>@tool(\"Tool only available in planning phase\", phases=[\"planning\"])\ndef planning_tool(self) -&gt; str:\n    return \"This only works during planning\"\n\n@tool(\"Tool available in multiple phases\", phases=[\"research\", \"analysis\"])\ndef multi_phase_tool(self) -&gt; str:\n    return \"Available in research and analysis\"\n\n@tool(\"Tool available in all phases\")  # No phases parameter\ndef universal_tool(self) -&gt; str:\n    return \"Always available\"\n</code></pre> <p>When an agent is in a specific phase, only tools that: 1. Specify that phase in their <code>phases</code> list, OR 2. Don't specify any phases (available in all phases)</p> <p>will be exposed to the LLM.</p>"},{"location":"phases/#phases-with-linked-agents","title":"Phases with Linked Agents","text":"<p>Linked agents can be restricted to specific phases using the <code>phases</code> parameter in <code>spec.AgentLink()</code>, similar to how tools can be phase-restricted. This allows you to compose multi-agent systems where different agents are available at different stages of the workflow:</p> <pre><code>from pyagentic import BaseAgent, tool, spec, Link\n\nclass PlannerAgent(BaseAgent):\n    __system_message__ = \"I create detailed plans\"\n    __description__ = \"Planning specialist for strategy development\"\n\nclass ExecutorAgent(BaseAgent):\n    __system_message__ = \"I execute plans\"\n    __description__ = \"Execution specialist for implementing plans\"\n\nclass ReviewerAgent(BaseAgent):\n    __system_message__ = \"I review completed work\"\n    __description__ = \"Quality assurance and review specialist\"\n\nclass ProjectAgent(BaseAgent):\n    __system_message__ = \"\"\"\n    You manage projects through phases: {{ phase }}\n    \"\"\"\n\n    plan: spec.State[str] = spec.State(default=\"\")\n    execution_complete: spec.State[bool] = spec.State(default=False)\n\n    # Define phase transitions\n    phases = [\n        (\"planning\", \"execution\", lambda self: bool(self.plan)),\n        (\"execution\", \"review\", lambda self: self.execution_complete),\n    ]\n\n    # Each linked agent is only available during specific phases\n    planner: Link[PlannerAgent] = spec.AgentLink(phases=[\"planning\"])\n    executor: Link[ExecutorAgent] = spec.AgentLink(phases=[\"execution\"])\n    reviewer: Link[ReviewerAgent] = spec.AgentLink(phases=[\"review\"])\n\n    @tool(\"Save the project plan\", phases=[\"planning\"])\n    def save_plan(self, plan_text: str) -&gt; str:\n        self.plan = plan_text\n        return \"Plan saved\"\n\n    @tool(\"Mark execution complete\", phases=[\"execution\"])\n    def complete_execution(self) -&gt; str:\n        self.execution_complete = True\n        return \"Execution marked complete\"\n</code></pre> <p>When using phase-restricted linked agents: - Linked agents only appear as available tools during their specified phases - Omitting the <code>phases</code> parameter makes the agent available in all phases - Multiple phases can be specified: <code>phases=[\"planning\", \"review\"]</code> - Phase restrictions work alongside the <code>condition</code> parameter for fine-grained control</p> <p>For more details on linked agents, see the Agent Linking documentation.</p>"},{"location":"phases/#accessing-current-phase","title":"Accessing Current Phase","text":"<p>You can access the current phase in several ways:</p>"},{"location":"phases/#in-system-messages","title":"In System Messages","text":"<p>Use the <code>{{ phase }}</code> variable in your system message template:</p> <pre><code>__system_message__ = \"\"\"\nYou are in the {{ phase }} phase.\n{% if phase == \"planning\" %}\nCreate a detailed plan.\n{% elif phase == \"execution\" %}\nExecute the plan step by step.\n{% endif %}\n\"\"\"\n</code></pre>"},{"location":"phases/#in-input-templates","title":"In Input Templates","text":"<p>The phase is also available in input templates:</p> <pre><code>__input_template__ = \"\"\"\nUser request: {{ user_message }}\nCurrent phase: {{ phase }}\n\"\"\"\n</code></pre>"},{"location":"phases/#in-code","title":"In Code","text":"<p>Access the phase directly from the agent state:</p> <pre><code>current_phase = self.state.phase\n# or\ncurrent_phase = agent.state.phase\n</code></pre>"},{"location":"phases/#phase-lifecycle","title":"Phase Lifecycle","text":""},{"location":"phases/#initialization","title":"Initialization","text":"<p>When an agent with phases is initialized:</p> <ol> <li>The phase machine is built from the <code>phases</code> list</li> <li>States are extracted automatically from the tuples</li> <li>The initial state is set to the first source state in the list</li> <li>Transition triggers are created for each phase pair</li> </ol>"},{"location":"phases/#state-transitions","title":"State Transitions","text":"<p>Phase transitions are evaluated automatically:</p> <ul> <li>After LLM inference: Following each call to the LLM</li> <li>After tool execution: After each tool completes</li> <li>After agent calls: When linked agents finish execution</li> </ul> <p>The transition evaluation checks each condition function in order and triggers the first transition whose condition returns <code>True</code>.</p>"},{"location":"policies/","title":"Policies","text":"<p>Policies are powerful hooks that react to state changes in your agents. They let you validate data, track history, persist changes, trigger side effects, and implement reactive behaviors\u2014without cluttering your tool implementations.</p>"},{"location":"policies/#why-use-policies","title":"Why Use Policies?","text":"<p>Without policies, each tool that mutates state must repeat validation, logging, persistence, and other cross-cutting concerns. Policies centralize those behaviors and reduce the need for hand-written Getter/Setter tools.</p> <p>Without policies \u2014 repetitive and error-prone <pre><code>class TextAdventureAgent(BaseAgent):\n    combat_score: State[int] = spec.State(default=0)      # valid 0..100\n    puzzle_score: State[int] = spec.State(default=0)      # valid -20..500\n    streak: State[int] = spec.State(default=0)\n\n    @tool(\"Award combat points for defeating an enemy\")\n    def defeat_enemy(self, enemy: str, points: int = 10):\n        ...\n        new_score = self.combat_score + points + (2 if self.streak &gt;= 3 else 0)\n        if not isinstance(new_score, int):\n            raise ValueError(\"Combat Score must be an integer\")\n        if not (0 &lt;= new_score &lt;= 100):\n            raise ValueError(\"Combat Score must be between 0 and 100\")\n\n        self.combat_score = new_score\n        self.streak += 1\n\n    @tool(\"Award puzzle points for solving a riddle\")\n    def solve_puzzle(self, puzzle: str, points: int = 25):\n        ...\n        new_score = self.puzzle_score + points\n        if not isinstance(new_score, int):\n            raise ValueError(\"Puzzle Score must be an integer\")\n        if not (-20 &lt;= new_score &lt;= 500):\n            raise ValueError(\"Puzzle Score must be between -20 and 500\")\n\n        self.puzzle_score = new_score\n        # streak doesn\u2019t change here\n    ...\n</code></pre></p> <p>With policies \u2014 clean and declarative</p> <p>Instead of repeating this logic, declare policies on the <code>score</code> state and use it naturally in any tool. Validation and side effects are always enforced.</p> <p>The user could use the <code>BoundValuePolicy</code> <pre><code>from pyagentic.policies.core import BoundValuePolicy\n\nclass TextAdventureAgent(BaseAgent):\n    combat_score: State[int] = spec.State(\n        default=0,\n        policies=[\n            BoundValuePolicy(min_val=0, max_val=100),\n        ],\n    )\n\n    puzzle_score: State[int] = spec.State(\n        default=0,\n        policies=[\n            BoundValuePolicy(min_val=-20, max_val=500),\n        ],\n    )\n\n    streak: State[int] = spec.State(default=0)\n\n    @tool(\"Award combat points for defeating an enemy\")\n    def defeat_enemy(self, enemy: str, points: int = 10):\n        ...\n        # Intent only; bounds enforced by the BoundValuePolicy\n        bonus = 2 if self.streak &gt;= 3 else 0\n        self.combat_score = self.combat_score + points + bonus\n        self.streak = self.streak + 1\n\n    @tool(\"Award puzzle points for solving a riddle\")\n    def solve_puzzle(self, puzzle: str, points: int = 25):\n        ...\n        # Intent only; bounds enforced by the BoundValuePolicy\n        self.puzzle_score = self.puzzle_score + points\n</code></pre></p> <p>For Background Jobs</p> <p>Policies can also be used to trigger background jobs whenever a field is modified. Take for example an <code>JournalAgent</code>, which writes journal entries based on the conversation with the user. This Agent may have a <code>Journal</code>, complete with <code>entries</code> and a <code>summary</code></p> <pre><code>class Journal(BaseModel):\n    \"\"\"A journal with entries and a running summary.\"\"\"\n    entries: list[str] = []\n    summary: str = \"\"\n</code></pre> <p>The JournalAgent may then take this further by using a <code>SummarizePolicy</code> to auto summarize the entries without needing explicit calling by the user.</p> <pre><code>class JournalAgent(BaseAgent):\n    \"\"\"Agent that manages a journal and keeps it summarized.\"\"\"\n    journal: State[Journal] = spec.State(\n        default_factory=Journal,\n        policies=[\n            SummaryPolicy(\n                to_summarize='entries',\n                summary_field=\"summary\",\n            )\n        ]\n    )\n\n    @tool(\"Add a new journal entry\")\n    def add_entry(self, text: str):\n        \"\"\"\n        Add a new entry to the journal.\n        The SummaryPolicy automatically updates the summary afterward.\n        \"\"\"\n        self.journal.entries.append(text)\n        return f\"Added entry: {text[:40]}...\"\n    ...\n</code></pre> <p>This would make sure that the summary attached to the journal is always up-to-date with the entries. No matter if the agent adds, removes, or modifies them. </p>"},{"location":"policies/#how-policies-work","title":"How Policies Work","text":"<p>Policies implement the <code>Policy[T]</code> protocol and define handlers for state events.</p>"},{"location":"policies/#event-types","title":"Event Types","text":"<p><code>GetEvent</code> \u2014 triggered when state is read</p> <pre><code>@dataclass\nclass GetEvent:\n    name: str           # Field name being accessed\n    value: Any          # Current value\n    timestamp: datetime # When the access occurred\n</code></pre> <p><code>SetEvent</code> \u2014 triggered when state is written</p> <pre><code>@dataclass\nclass SetEvent:\n    name: str           # Field name being modified\n    previous: Any       # Value before change\n    value: Any          # New value being set\n    timestamp: datetime # When the change occurred\n</code></pre>"},{"location":"policies/#handler-semantics","title":"Handler Semantics","text":"<ul> <li> <p>Synchronous (<code>on_get</code>, <code>on_set</code>)</p> </li> <li> <p>Run before the value is returned/stored and block the operation.</p> </li> <li>May transform the value by returning a replacement.</li> <li>May validate by raising an exception, which aborts the operation.</li> <li> <p>Ordering: policies run in the order they\u2019re declared; the first exception aborts, and later handlers do not run.</p> </li> <li> <p>Background (<code>background_get</code>, <code>background_set</code>)</p> </li> <li> <p>Run after sync handlers complete and must not mutate stored state.</p> </li> <li>Intended for side effects only: logging, metrics, notifications, persistence.</li> <li>Failures should be handled internally (e.g., retries/backoff); they cannot prevent an already-completed operation.</li> </ul>"},{"location":"policies/#execution-flow","title":"Execution Flow","text":"<pre><code>flowchart TD\n    Start[State Access/Modification] --&gt; Type{Access Type?}\n\n    Type --&gt;|GET| GetRetrieve[1. Retrieve stored value]\n    Type --&gt;|SET| SetGetPrev[1. Get previous value]\n\n    GetRetrieve --&gt; GetSync[2. Run on_get for each policy&lt;br/&gt;\u23f1\ufe0f BLOCKS until complete]\n    SetGetPrev --&gt; SetSync[2. Run on_set for each policy&lt;br/&gt;\u23f1\ufe0f BLOCKS until complete]\n\n    GetSync --&gt; GetTransform{Any handler&lt;br/&gt;returned new value?}\n    SetSync --&gt; SetValidate{Any handler&lt;br/&gt;raised error?}\n\n    SetValidate --&gt;|Yes| SetError[\u274c Raise error&lt;br/&gt;State unchanged]\n    SetValidate --&gt;|No| SetTransform{Any handler&lt;br/&gt;returned new value?}\n\n    GetTransform --&gt;|Yes| GetNewVal[Use transformed value]\n    GetTransform --&gt;|No| GetOldVal[Use original value]\n    SetTransform --&gt;|Yes| SetNewVal[3. Store new value]\n    SetTransform --&gt;|No| SetOldVal[3. Store value as-is]\n\n    GetNewVal --&gt; GetBg[4. Launch background_get tasks&lt;br/&gt;\ud83d\udd04 Side effects only]\n    GetOldVal --&gt; GetBg\n    SetNewVal --&gt; SetBg[4. Launch background_set tasks&lt;br/&gt;\ud83d\udd04 Side effects only]\n    SetOldVal --&gt; SetBg\n\n    GetBg --&gt; GetReturn[5. Return value to caller]\n    SetBg --&gt; SetReturn[5. Return success]\n\n    GetReturn --&gt; End[\u2713 Complete]\n    SetReturn --&gt; End\n    SetError --&gt; End\n\n    style GetSync fill:#e1f5ff\n    style SetSync fill:#ffe1e1\n    style GetBg fill:#d4edda\n    style SetBg fill:#d4edda\n    style SetError fill:#ffcccc\n</code></pre>"},{"location":"policies/#combining-multiple-policies","title":"Combining Multiple Policies","text":"<p>Policies compose into a pipeline. Order matters.</p> <pre><code>class RangeValidationPolicy(Policy[int]):\n    def __init__(self, min_val: int, max_val: int):\n        self.min_val, self.max_val = min_val, max_val\n\n    def on_set(self, event: SetEvent, value: int) -&gt; Optional[int]:\n        if not self.min_val &lt;= value &lt;= self.max_val:\n            raise ValueError(f\"Value must be between {self.min_val} and {self.max_val}\")\n        return None\n\nclass HistoryTrackingPolicy(Policy[int]):\n    def __init__(self, max_length=100):\n        self.max_length = max_length\n        self.history: list[dict] = []\n\n    def on_set(self, event: SetEvent, value: int) -&gt; Optional[int]:\n        self.history.append({\n            \"old\": event.previous,\n            \"new\": value,\n            \"timestamp\": event.timestamp.isoformat()\n        })\n        if len(self.history) &gt; self.max_length:\n            self.history.pop(0)\n        return None\n\nclass SQLPersistencePolicy(Policy[int]):\n    async def background_set(self, event: SetEvent, value: int) -&gt; None:\n        await sql.sync_to_db({\"field\": event.name, \"value\": value, \"ts\": event.timestamp})\n\nclass Agent(BaseAgent):\n    score: State[int] = spec.State(\n        default=0,\n        policies=[\n            RangeValidationPolicy(0, 100),  # validate first\n            HistoryTrackingPolicy(50),      # track second\n            SQLPersistencePolicy(),         # persist last (background)\n        ],\n    )\n</code></pre>"},{"location":"policies/#invalid-value-example-sequence","title":"Invalid Value Example (sequence)","text":"<pre><code>sequenceDiagram\n    participant LLM\n    participant Agent as Agent (@tool)\n    participant State as AgentState\n    participant Policy as RangeValidationPolicy\n\n    Note over LLM,Policy: \u274c Attempt with invalid value\n\n    LLM-&gt;&gt;Agent: update_score(150)\n    Agent-&gt;&gt;State: Set score to 150\n    State-&gt;&gt;Policy: on_set(event, 150)\n    Policy--xState: raise ValueError(\"Value must be between 0 and 100\")\n    State--xAgent: Error\n    Agent--xLLM: Tool error\n\n    Note over LLM,Policy: \u2705 Retry with valid value\n\n    LLM-&gt;&gt;Agent: update_score(100)\n    Agent-&gt;&gt;State: Set score to 100\n    State-&gt;&gt;Policy: on_set(event, 100)\n    Policy--&gt;&gt;State: return None (keep)\n    State--&gt;&gt;Agent: \u2713 Success\n    Agent--&gt;&gt;LLM: \"Score updated to 100\"\n</code></pre> <p>Key insights</p> <ul> <li>Writing <code>self.score = v</code> creates a <code>SetEvent(previous, value)</code>.</li> <li>A policy exception aborts the write; the LLM sees a tool error and can retry.</li> <li>Background handlers cannot undo or change the committed value.</li> </ul>"},{"location":"policies/#creating-custom-policies","title":"Creating Custom Policies","text":"<p>Implement only what you need.</p>"},{"location":"policies/#example-1-validation","title":"Example 1: Validation","text":"<pre><code>class NonEmptyPolicy(Policy[str]):\n    def on_set(self, event: SetEvent, value: str) -&gt; Optional[str]:\n        if not value.strip():\n            raise ValueError(\"Value cannot be empty\")\n        return None\n</code></pre>"},{"location":"policies/#example-2-transformation","title":"Example 2: Transformation","text":"<pre><code>class TrimAndLowerPolicy(Policy[str]):\n    def on_set(self, event: SetEvent, value: str) -&gt; Optional[str]:\n        return value.strip().lower()\n</code></pre>"},{"location":"policies/#example-3-async-persistence-non-blocking","title":"Example 3: Async Persistence (non-blocking)","text":"<pre><code>import json, asyncio\nfrom pathlib import Path\n\nclass JSONPersistencePolicy(Policy[Any]):\n    def __init__(self, filepath: str):\n        self.filepath = Path(filepath)\n\n    async def background_set(self, event: SetEvent, value: Any) -&gt; None:\n        record = {\n            \"timestamp\": event.timestamp.isoformat(),\n            \"field\": event.name,\n            \"value\": value,\n        }\n\n        def write_json():\n            existing = []\n            if self.filepath.exists():\n                existing = json.loads(self.filepath.read_text())\n            existing.append(record)\n            self.filepath.write_text(json.dumps(existing, indent=2))\n\n        await asyncio.to_thread(write_json)\n</code></pre>"},{"location":"policies/#access-control-autogenerated-tools","title":"Access Control &amp; Autogenerated Tools","text":"<p>When <code>access=\"write\"</code> is set, a setter tool named <code>set_&lt;field&gt;</code> is autogenerated. For example:</p> <ul> <li><code>score: State[int] = spec.State(..., access=\"write\")</code> \u2192 <code>set_score(new_score: int)</code></li> <li>Tool errors propagate policy exceptions to the LLM.</li> <li>You can layer RBAC/role checks via a policy:</li> </ul> <pre><code>class RoleGatePolicy(Policy[Any]):\n    def __init__(self, allowed_roles: set[str]):\n        self.allowed_roles = allowed_roles\n\n    def on_set(self, event: SetEvent, value: Any) -&gt; Optional[Any]:\n        if current_role() not in self.allowed_roles:\n            raise PermissionError(\"Not authorized to modify this field\")\n        return None\n</code></pre>"},{"location":"policies/#concurrency-ordering-and-safety","title":"Concurrency, Ordering, and Safety","text":"<ul> <li>Ordering: Sync handlers run in declaration order; first exception aborts the operation.</li> <li>Atomicity: A successful write commits exactly once. Background effects may be retried but cannot change the committed value.</li> <li>Reentrancy: Policy handlers must not synchronously write to the same state they observe (avoid recursion). If needed, perform follow-up writes through separate, explicit application logic.</li> <li>Concurrency: If your runtime allows concurrent writes, the default is last-writer-wins. To enforce stronger guarantees, implement a CAS-style policy:</li> </ul> <pre><code>class CompareAndSetPolicy(Policy[Any]):\n    def __init__(self, expected_getter):\n        self.expected_getter = expected_getter  # app-provided function\n\n    def on_set(self, event: SetEvent, value: Any) -&gt; Optional[Any]:\n        expected = self.expected_getter(event.name)\n        if event.previous != expected:\n            raise RuntimeError(\"Concurrent update detected\")\n        return None\n</code></pre> <ul> <li>Timeouts: Keep sync handlers fast. If a handler may block, move it to <code>background_*</code> or enforce a per-policy timeout in your framework settings.</li> </ul>"},{"location":"policies/#best-practices","title":"Best Practices","text":"<ol> <li>Keep policies focused \u2014 one responsibility per policy.</li> <li>Validate first, transform second, side effects last.</li> <li>Use background handlers for I/O \u2014 never mutate state there.</li> <li>Handle background errors \u2014 retries/backoff and metrics.</li> <li>Avoid recursive writes \u2014 no in-handler writes to the same field.</li> <li>Make policies reusable \u2014 accept parameters in <code>__init__</code>.</li> <li>Observe and test \u2014 add counters/latency metrics and unit tests for each policy.</li> </ol>"},{"location":"policies/#end-to-end-minimal-example","title":"End-to-End Minimal Example","text":"<pre><code>class GameAgent(BaseAgent):\n    score: State[int] = spec.State(\n        default=0,\n        access=\"write\",\n        policies=[\n            RangeValidationPolicy(0, 100),\n            HistoryTrackingPolicy(max_length=10),\n            JSONPersistencePolicy(\"scores_history.json\"),\n        ],\n    )\n\n    @tool(\"Update the player's score\")\n    def update_score(self, value: int) -&gt; str:\n        self.score = value\n        return f\"Score is now {self.score}\"\n</code></pre> <p>Behavior</p> <ul> <li><code>update_score(150)</code> \u2192 tool error: <code>Value must be between 0 and 100</code></li> <li><code>update_score(100)</code> \u2192 success; history appended; JSON file updated asynchronously</li> </ul>"},{"location":"policies/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about State Management to see how policies integrate with state lifecycles.</li> <li>Explore Structured Outputs for validating agent responses.</li> <li>See Agent Linking to coordinate policies across multiple agents.</li> </ul>"},{"location":"responses/","title":"Agent Responses","text":"<p>PyAgentic agents return structured response objects that contain both the natural language output and detailed information about what happened during execution. This makes it easy to build applications that need both human-readable responses and programmatic access to execution details.</p>"},{"location":"responses/#response-structure","title":"Response Structure","text":"<p>Every agent response is a Pydantic model with a predictable structure:</p> <ul> <li><code>final_output: str</code> - The natural language response from the LLM</li> <li><code>tool_responses: List[ToolResponse]</code> - Details of any tools called (if agent has tools)</li> <li><code>agent_responses: List[AgentResponse]</code> - Responses from linked agents (if agent has linked agents)</li> </ul> <p>The response model is predetermined when the agent class is defined. Each agent automatically gets its own response class that knows exactly what tools and linked agents it can use. This means you get full type safety and IDE autocompletion before you ever run the agent.</p>"},{"location":"responses/#basic-response","title":"Basic Response","text":"<p>Every agent response includes a <code>final_output</code> field containing the LLM's natural language response:</p> <pre><code>response = await agent(\"Hello\")\nresponse.final_output  # \"Hi there! How can I help?\"\n</code></pre> <p>Since responses are Pydantic models, you can serialize them to JSON, validate them, and integrate them seamlessly with FastAPI or other frameworks.</p>"},{"location":"responses/#tool-responses","title":"Tool Responses","text":"<p>When agents use tools, the response automatically includes structured information about each tool call. All tool parameters become accessible as typed fields on the response:</p> <pre><code>class EmailAgent(BaseAgent):\n    @tool(\"Send email\")\n    def send_email(self, to: str, urgent: bool = False) -&gt; str: ...\n\nresponse = await agent(\"Send urgent email to john about moving to our next apartment\")\n</code></pre> <pre><code>{\n  \"final_output\": \"I've sent the email to John. Let me know if there's anything else you need!\",\n  \"tool_responses\": [\n    {\n      \"raw_kwargs\": \"{\\\"to\\\":\\\"john@example.com\\\",\\\"message\\\":\\\"Subject: Moving Forward with the Next Apartment\\\\n\\\\nHi John,\\\\n\\\\nI hope this message finds you well. I wanted to discuss our plans for moving to the next apartment. Please let me know when would be a good time for us to chat or meet to go over the specifics.\\\\n\\\\nLooking forward to hearing from you soon.\\\\n\\\\nBest,\\\\n[Your Name]\\\",\\\"urgent\\\":false}\",\n      \"call_depth\": 0,\n      \"output\": \"Email sent\",\n      \"to\": \"john@example.com\",\n      \"message\": \"Subject: Moving Forward with the Next Apartment\\n\\nHi John,\\n\\nI hope this message finds you well. I wanted to discuss our plans for moving to the next apartment. Please let me know when would be a good time for us to chat or meet to go over the specifics.\\n\\nLooking forward to hearing from you soon.\\n\\nBest,\\n[Your Name]\",\n      \"urgent\": false\n    }\n  ]\n}\n</code></pre> <p>This gives you both the conversational response and programmatic access to exactly what the agent did.</p>"},{"location":"responses/#multiple-tools","title":"Multiple Tools","text":"<p>PyAgentic automatically generates response schemas that can handle any combination of tools your agent might use. The response type is created at class definition time and includes proper typing for all possible tool combinations:</p> <pre><code>class CustomerAgent(BaseAgent):\n    @tool(\"Get customer\")\n    def get_customer(self, email: str): ...\n\n    @tool(\"Update status\")\n    def update_status(self, id: int, status: str): ...\n\n# Response automatically includes fields for whichever tools were called\n</code></pre> <p>You can access any tool's parameters through the <code>tool_responses</code> list, with full type safety and IDE autocompletion.</p>"},{"location":"responses/#linked-agents","title":"Linked Agents","text":"<p>When agents call other agents, their complete responses are nested within the parent response. This creates a tree structure that captures the full execution flow:</p> <pre><code>class ReportAgent(BaseAgent):\n    database: DatabaseAgent\n\n    @tool(\"Create chart\")\n    def make_chart(self, type: str): ...\n\nresponse = await agent(\"Create sales chart\")\nresponse.final_output                    # Main agent response\nresponse.tool_responses[0].type          # \"sales\"\nresponse.agent_responses[0].final_output # Database agent response\n</code></pre> <p>This nested structure lets you trace exactly what each agent did and access the results of any sub-agent calls. The parent agent's response includes both its own tool calls and the complete responses from any linked agents it used.</p>"},{"location":"states/","title":"State Management","text":"<p>PyAgentic's state system provides persistent, type-safe data storage for agents. States are fields that maintain their values across multiple conversations, allowing agents to build context, remember user preferences, and track complex workflows over time.</p>"},{"location":"states/#why-use-states","title":"Why Use States?","text":"<p>Without state, agents are stateless - they start fresh with each interaction and can't remember anything from previous conversations. States solve this by:</p> <ul> <li>Persisting Data: Values survive across multiple agent calls</li> <li>Type Safety: Full Pydantic validation and type checking</li> <li>Dynamic Behavior: Computed fields that update automatically</li> <li>Smart References: Link tool parameters to live state values</li> <li>Access Control: Control how the LLM can interact with state</li> </ul>"},{"location":"states/#basic-state-fields","title":"Basic State Fields","text":"<p>The simplest way to add state is using <code>State[T]</code> with <code>spec.State()</code>:</p> <pre><code>from pyagentic import BaseAgent, State, spec\n\nclass ChatAgent(BaseAgent):\n    __system_message__ = \"I'm a helpful assistant that remembers our conversations\"\n\n    user_name: State[str] = spec.State(default=\"User\")\n    message_count: State[int] = spec.State(default=0)\n    conversation_topic: State[str] = spec.State(default=\"general\")\n</code></pre> <p>Each state field is: - Typed: The <code>State[T]</code> annotation ensures type safety - Persistent: Values are maintained between agent calls - Accessible: Reference directly via <code>self.field_name</code> in tools</p>"},{"location":"states/#accessing-state-in-tools","title":"Accessing State in Tools","text":"<p>Access state fields directly on <code>self</code> - the framework handles state management automatically:</p> <pre><code>class ChatAgent(BaseAgent):\n    __system_message__ = \"I'm a helpful assistant\"\n\n    message_count: State[int] = spec.State(default=0)\n\n    @tool(\"Record a new message\")\n    def record_message(self, content: str) -&gt; str:\n        self.message_count += 1\n        return f\"Message {self.message_count} recorded: {content}\"\n</code></pre>"},{"location":"states/#state-configuration-options","title":"State Configuration Options","text":"<p><code>spec.State()</code> accepts several configuration options:</p> <pre><code>class ConfiguredAgent(BaseAgent):\n    # Simple default value\n    username: State[str] = spec.State(default=\"anonymous\")\n\n    # Default factory for mutable defaults\n    tags: State[list[str]] = spec.State(default_factory=list)\n\n    # Description (used in system messages and auto-generated tools)\n    bio: State[str] = spec.State(\n        default=\"\",\n        description=\"User biography and preferences\"\n    )\n\n    # Access control (covered below)\n    api_key: State[str] = spec.State(\n        default=\"\",\n        access=\"write\"  # LLM can only write, not read\n    )\n</code></pre>"},{"location":"states/#pydantic-models-as-state","title":"Pydantic Models as State","text":"<p>For complex state with multiple related fields and computed values, use Pydantic models:</p> <pre><code>from pydantic import BaseModel, computed_field\nfrom pyagentic import BaseAgent, State, spec\n\nclass UserProfile(BaseModel):\n    name: str = \"Guest\"\n    email: str = \"\"\n    preferences: dict = {}\n    login_count: int = 0\n\n    @computed_field\n    @property\n    def is_registered(self) -&gt; bool:\n        \"\"\"Computed field automatically updates based on other fields\"\"\"\n        return bool(self.email)\n\n    @computed_field\n    @property\n    def greeting(self) -&gt; str:\n        \"\"\"Dynamic greeting based on login count\"\"\"\n        if self.login_count == 0:\n            return f\"Welcome, {self.name}!\"\n        return f\"Welcome back, {self.name}! Visit #{self.login_count}\"\n\nclass UserAgent(BaseAgent):\n    __system_message__ = \"I manage user profiles. Greeting: {profile.greeting}\"\n\n    profile: State[UserProfile] = spec.State(default_factory=UserProfile)\n\n    @tool(\"Update user email\")\n    def set_email(self, email: str) -&gt; str:\n        self.profile.email = email\n        # is_registered automatically updates!\n        return f\"Email set. Registered: {self.profile.is_registered}\"\n</code></pre>"},{"location":"states/#benefits-of-pydantic-models","title":"Benefits of Pydantic Models","text":"<ol> <li>Computed Fields: Use <code>@computed_field</code> for values derived from other state</li> <li>Validation: Pydantic validates all field types and constraints</li> <li>Nested Structure: Organize related data logically</li> <li>Serialization: Easy JSON export/import of state</li> <li>IDE Support: Full autocomplete for all fields</li> </ol>"},{"location":"states/#referencing-state-with-ref","title":"Referencing State with <code>ref</code>","text":"<p>The <code>ref</code> system creates dynamic links between tool parameters and state values:</p> <pre><code>from pyagentic import ref\n\nclass TopicState(BaseModel):\n    available_topics: list[str] = [\"general\", \"tech\", \"science\"]\n    current_topic: str = \"general\"\n\n    @computed_field\n    @property\n    def topic_count(self) -&gt; int:\n        return len(self.available_topics)\n\nclass TopicAgent(BaseAgent):\n    __system_message__ = \"I manage topics. Current: {current_topic}\"\n\n    topics: State[TopicState] = spec.State(default_factory=TopicState)\n\n    @tool(\"Switch to a different topic\")\n    def switch_topic(\n        self,\n        topic: str = spec.Param(\n            description=\"Topic to switch to\",\n            values=ref.available_topics  # LLM can only pick from this list!\n        )\n    ) -&gt; str:\n        self.current_topic = topic\n        return f\"Switched to {topic}\"\n</code></pre>"},{"location":"states/#how-ref-works","title":"How <code>ref</code> Works","text":"<ul> <li>Direct References: <code>ref.available_topics</code> creates a reference to state fields</li> <li>Runtime Resolution: Values are resolved when the tool schema is generated</li> <li>Always Current: References always point to the latest state values</li> <li>Type Safe: Full typing support through the reference chain</li> </ul>"},{"location":"states/#using-state-in-system-messages","title":"Using State in System Messages","text":"<p>You can also reference state in system messages using template syntax:</p> <pre><code>class Agent(BaseAgent):\n    __system_message__ = \"\"\"\n    Current topic: {current_topic}\n    Available topics: {available_topics}\n    Total topics: {topic_count}\n    \"\"\"\n\n    topics: State[TopicState] = spec.State(default_factory=TopicState)\n</code></pre> <p>When using a Pydantic model for state, the model's fields (including computed fields) are directly accessible in templates without needing to prefix them with the state field name.</p>"},{"location":"states/#state-access-control","title":"State Access Control","text":"<p>Control how the LLM can interact with state using the <code>access</code> parameter:</p> <pre><code>class SecureAgent(BaseAgent):\n    __system_message__ = \"I'm a secure agent with controlled state access\"\n\n    # Default: LLM can see value but not modify it\n    user_id: State[str] = spec.State(\n        default=\"\",\n        access=\"read\"\n    )\n\n    # LLM can modify but not see the value\n    api_key: State[str] = spec.State(\n        default=\"\",\n        access=\"write\",\n        set_description=\"Store the user's API key securely\"\n    )\n\n    # LLM can both read and write\n    preferences: State[dict] = spec.State(\n        default_factory=dict,\n        access=\"readwrite\",\n        get_description=\"Get user preferences\",\n        set_description=\"Update user preferences\"\n    )\n\n    # LLM cannot interact with this at all\n    internal_cache: State[dict] = spec.State(\n        default_factory=dict,\n        access=\"hidden\"\n    )\n</code></pre>"},{"location":"states/#access-levels","title":"Access Levels","text":"Access LLM Can Read LLM Can Write Auto-Generated Tools <code>\"read\"</code> (default) \u2705 Yes \u274c No Getter only <code>\"write\"</code> \u274c No \u2705 Yes Setter only <code>\"readwrite\"</code> \u2705 Yes \u2705 Yes Getter + Setter <code>\"hidden\"</code> \u274c No \u274c No None"},{"location":"states/#auto-generated-state-tools","title":"Auto-Generated State Tools","text":"<p>PyAgentic automatically generates tools for state access based on the <code>access</code> level:</p> <pre><code>class DataAgent(BaseAgent):\n    __system_message__ = \"I manage data\"\n\n    current_data: State[str] = spec.State(\n        default=\"\",\n        access=\"readwrite\",\n        get_description=\"Retrieve the current stored data\",\n        set_description=\"Update the stored data with new content\"\n    )\n</code></pre> <p>This automatically creates two tools: 1. <code>get_current_data()</code> - Returns the current value 2. <code>set_current_data(value: str)</code> - Updates the value</p> <p>The LLM can call these tools just like your custom <code>@tool</code> methods.</p>"},{"location":"states/#state-in-system-messages-and-templates","title":"State in System Messages and Templates","text":"<p>Reference state fields in templates directly by their field names:</p> <pre><code>class ResearchAgent(BaseAgent):\n    __system_message__ = \"\"\"\n    You are a research assistant.\n    Current focus: {current_topic}\n    Papers collected: {paper_count}\n    \"\"\"\n\n    __input_template__ = \"\"\"\n    Research Topic: {current_topic}\n    User Message: {user_message}\n    \"\"\"\n\n    research: State[ResearchState] = spec.State(default_factory=ResearchState)\n</code></pre> <p>Templates support: - Direct field access: <code>{current_topic}</code> - Computed fields: <code>{topic_count}</code> - All fields from your state model are automatically available</p>"},{"location":"states/#state-policies","title":"State Policies","text":"<p>States can have policies attached that react to state changes, validate values, persist data, and more. Policies provide powerful hooks for implementing cross-cutting concerns without cluttering your tool implementations.</p> <p>Quick preview:</p> <pre><code># Define custom policies\nclass ScoreValidationPolicy:\n    def on_set(self, event, value):\n        if not 0 &lt;= value &lt;= 100:\n            raise ValueError(\"Score must be between 0 and 100\")\n        return None\n\n    async def background_set(self, event, value):\n        return None\n\n    def on_get(self, event, value):\n        return None\n\n    async def background_get(self, event, value):\n        return None\n\nclass ChangeHistoryPolicy:\n    def __init__(self, max_length=100):\n        self.max_length = max_length\n        self.history = []\n\n    def on_set(self, event, value):\n        self.history.append({\n            \"old\": event.previous,\n            \"new\": value,\n            \"timestamp\": event.timestamp\n        })\n        if len(self.history) &gt; self.max_length:\n            self.history.pop(0)\n        return None\n\n    # ... other methods\n\n# Use them\nclass TrackedAgent(BaseAgent):\n    __system_message__ = \"I track changes to my state\"\n\n    score: State[int] = spec.State(\n        default=0,\n        policies=[\n            ScoreValidationPolicy(),\n            ChangeHistoryPolicy(max_length=50)\n        ]\n    )\n</code></pre> <p>Policies execute in order when state changes: 1. ScoreValidationPolicy - Ensures score is between 0-100 (raises error if not) 2. ChangeHistoryPolicy - Records the change in an in-memory history</p> <p>See the Policies documentation for: - Complete guide to the Policy protocol - 7+ patterns for building policies (validation, transformation, history, persistence, etc.) - Async vs sync handlers with execution flow diagrams - Best practices and common use cases</p>"},{"location":"states/#best-practices","title":"Best Practices","text":""},{"location":"states/#1-use-pydantic-models-for-complex-state","title":"1. Use Pydantic Models for Complex State","text":"<p>Instead of many individual state fields:</p> <pre><code># \u274c Not ideal - many scattered fields\nclass Agent(BaseAgent):\n    user_name: State[str] = spec.State(default=\"\")\n    user_email: State[str] = spec.State(default=\"\")\n    user_age: State[int] = spec.State(default=0)\n    user_prefs: State[dict] = spec.State(default_factory=dict)\n</code></pre> <p>Group related data into models:</p> <pre><code># \u2705 Better - organized and type-safe\nclass UserData(BaseModel):\n    name: str = \"\"\n    email: str = \"\"\n    age: int = 0\n    preferences: dict = {}\n\nclass Agent(BaseAgent):\n    user: State[UserData] = spec.State(default_factory=UserData)\n</code></pre>"},{"location":"states/#2-leverage-computed-fields","title":"2. Leverage Computed Fields","text":"<p>Use <code>@computed_field</code> for derived values instead of manually updating them:</p> <pre><code>class TaskState(BaseModel):\n    total_tasks: int = 0\n    completed_tasks: int = 0\n\n    @computed_field\n    @property\n    def completion_percentage(self) -&gt; float:\n        \"\"\"Automatically stays in sync\"\"\"\n        if self.total_tasks == 0:\n            return 0.0\n        return (self.completed_tasks / self.total_tasks) * 100\n</code></pre>"},{"location":"states/#3-use-ref-for-dynamic-constraints","title":"3. Use <code>ref</code> for Dynamic Constraints","text":"<p>Prevent hallucination by constraining parameters to valid state values:</p> <pre><code>@tool(\"Select a file\")\ndef select_file(\n    self,\n    filename: str = spec.Param(\n        description=\"File to select\",\n        values=ref.files.available_files  # Only allow existing files!\n    )\n) -&gt; str:\n    ...\n</code></pre>"},{"location":"states/#4-choose-appropriate-access-levels","title":"4. Choose Appropriate Access Levels","text":"<ul> <li>Use <code>\"read\"</code> for data the LLM needs to see but shouldn't modify</li> <li>Use <code>\"write\"</code> for sensitive data the LLM should store but not read</li> <li>Use <code>\"hidden\"</code> for internal state the LLM shouldn't know about</li> <li>Use <code>\"readwrite\"</code> sparingly, only when the LLM truly needs both</li> </ul>"},{"location":"states/#5-provide-clear-descriptions","title":"5. Provide Clear Descriptions","text":"<p>Help the LLM understand your state:</p> <pre><code>conversation_history: State[list[str]] = spec.State(\n    default_factory=list,\n    description=\"Complete history of user messages in this session\",\n    access=\"read\"\n)\n</code></pre>"},{"location":"states/#common-patterns","title":"Common Patterns","text":""},{"location":"states/#accumulator-pattern","title":"Accumulator Pattern","text":"<p>Build up data over multiple interactions:</p> <pre><code>class ResearchAgent(BaseAgent):\n    papers: State[list[dict]] = spec.State(default_factory=list)\n\n    @tool(\"Add paper to collection\")\n    def add_paper(self, title: str, authors: str) -&gt; str:\n        self.papers.append({\"title\": title, \"authors\": authors})\n        return f\"Added paper. Total: {len(self.papers)}\"\n</code></pre>"},{"location":"states/#state-machine-pattern","title":"State Machine Pattern","text":"<p>Track agent state through a workflow:</p> <pre><code>class WorkflowState(BaseModel):\n    stage: str = \"initial\"\n    data: dict = {}\n\n    @computed_field\n    @property\n    def valid_next_stages(self) -&gt; list[str]:\n        stages = {\n            \"initial\": [\"gathering\"],\n            \"gathering\": [\"processing\"],\n            \"processing\": [\"complete\"],\n            \"complete\": []\n        }\n        return stages.get(self.stage, [])\n\nclass WorkflowAgent(BaseAgent):\n    workflow: State[WorkflowState] = spec.State(default_factory=WorkflowState)\n\n    @tool(\"Advance to next stage\")\n    def advance(\n        self,\n        stage: str = spec.Param(values=ref.valid_next_stages)\n    ) -&gt; str:\n        self.stage = stage\n        return f\"Advanced to {stage}\"\n</code></pre>"},{"location":"states/#configuration-pattern","title":"Configuration Pattern","text":"<p>Store user preferences and settings:</p> <pre><code>class Settings(BaseModel):\n    language: str = \"en\"\n    theme: str = \"light\"\n    notifications: bool = True\n\n    @computed_field\n    @property\n    def formatted_display(self) -&gt; str:\n        return f\"{self.language.upper()} | {self.theme} theme | {'\ud83d\udd14' if self.notifications else '\ud83d\udd15'}\"\n\nclass Agent(BaseAgent):\n    __system_message__ = \"Settings: {settings.formatted_display}\"\n\n    settings: State[Settings] = spec.State(\n        default_factory=Settings,\n        access=\"readwrite\"\n    )\n</code></pre>"},{"location":"states/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about Policies for advanced state management</li> <li>Explore Agent Linking to share state between agents</li> <li>See Structured Outputs for validating agent responses</li> </ul>"},{"location":"structured-output/","title":"Structured Outputs","text":"<p>PyAgentic can automatically structure the final output of an agent into a Pydantic model. This is useful when you need the agent's response to follow a specific schema, making it easy to validate and use in downstream applications.</p>"},{"location":"structured-output/#defining-a-response-model","title":"Defining a Response Model","text":"<p>To specify a structured output, define a Pydantic model and assign it to the <code>__response_format__</code> attribute of your agent.</p> <pre><code>from pyagentic import BaseAgent, tool\nfrom pydantic import BaseModel\n\nclass UserInfo(BaseModel):\n    name: str\n    age: int\n    desc: str\n    city: str\n    state: str\n\nclass UserParsingAgent(BaseAgent):\n    __system_message__ = \"You are an AI that is an expert at parsing user information from any text\"\n    __response_format__ = UserInfo\n\n    @tool(\"Returns the city and state of a given zipcode\")\n    def zipcode_lookup(self, zipcode: str) -&gt; str:\n        ...\n</code></pre> <p>When you run this agent, the <code>final_output</code> of the response will be an instance of the <code>UserInfo</code> model, rather than a string.</p> <pre><code>await agent(\"Im John, im 28 and my postal code is 10012\")\n</code></pre> <pre><code>{\n  \"final_output\": {\n    \"name\": \"John\",\n    \"age\": 28,\n    \"desc\": \"Postal code was 10012\",\n    \"city\": \"NYC\",\n    \"state\": \"New York\"\n  },\n  \"provider_info\": {\n    \"name\": \"openai\",\n    \"model\": \"gpt-4o\",\n    \"attributes\": {}\n  },\n  \"tool_responses\": [\n    {\n      \"raw_kwargs\": \"{\\\"zipcode\\\":\\\"10012\\\"}\",\n      \"call_depth\": 0,\n      \"output\": \"NYC, New York\",\n      \"zipcode\": \"10012\"\n    }\n  ],\n  \"state\": {\n    \"instructions\": \"You are an AI that is an expert at parsing user information from any text\",\n    \"input_template\": null\n  }\n}\n</code></pre>"},{"location":"structured-output/#how-it-works","title":"How it Works","text":"<p>Under the hood, PyAgentic uses the <code>parse</code> capability with a given <code>__response_format__</code>, this takes advantage of the LLMs structured output feature (if supported). Pyagentic also automatically updates its own <code>__response_model__</code> to ensure that the agent's output is always expected.</p> <pre><code>{\n  \"$defs\": {\n    \"AgentState_UserParsingAgent_\": {\n      \"properties\": {\n        \"instructions\": {\n          \"title\": \"Instructions\",\n          \"type\": \"string\"\n        },\n        \"input_template\": {\n          \"anyOf\": [\n            {\n              \"type\": \"string\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Input Template\"\n        }\n      },\n      \"required\": [\n        \"instructions\"\n      ],\n      \"title\": \"AgentState[UserParsingAgent]\",\n      \"type\": \"object\"\n    },\n    \"ProviderInfo\": {\n      \"properties\": {\n        \"name\": {\n          \"title\": \"Name\",\n          \"type\": \"string\"\n        },\n        \"model\": {\n          \"title\": \"Model\",\n          \"type\": \"string\"\n        },\n        \"attributes\": {\n          \"additionalProperties\": true,\n          \"default\": null,\n          \"title\": \"Attributes\",\n          \"type\": \"object\"\n        }\n      },\n      \"required\": [\n        \"name\",\n        \"model\"\n      ],\n      \"title\": \"ProviderInfo\",\n      \"type\": \"object\"\n    },\n    \"ToolResponse_zipcode_lookup_\": {\n      \"properties\": {\n        \"raw_kwargs\": {\n          \"title\": \"Raw Kwargs\",\n          \"type\": \"string\"\n        },\n        \"call_depth\": {\n          \"title\": \"Call Depth\",\n          \"type\": \"integer\"\n        },\n        \"output\": {\n          \"title\": \"Output\"\n        },\n        \"zipcode\": {\n          \"default\": null,\n          \"title\": \"Zipcode\",\n          \"type\": \"string\"\n        }\n      },\n      \"required\": [\n        \"raw_kwargs\",\n        \"call_depth\",\n        \"output\"\n      ],\n      \"title\": \"ToolResponse[zipcode_lookup]\",\n      \"type\": \"object\"\n    },\n    \"UserInfo\": {\n      \"properties\": {\n        \"name\": {\n          \"title\": \"Name\",\n          \"type\": \"string\"\n        },\n        \"age\": {\n          \"title\": \"Age\",\n          \"type\": \"integer\"\n        },\n        \"desc\": {\n          \"title\": \"Desc\",\n          \"type\": \"string\"\n        },\n        \"city\": {\n          \"title\": \"City\",\n          \"type\": \"string\"\n        },\n        \"state\": {\n          \"title\": \"State\",\n          \"type\": \"string\"\n        }\n      },\n      \"required\": [\n        \"name\",\n        \"age\",\n        \"desc\",\n        \"city\",\n        \"state\"\n      ],\n      \"title\": \"UserInfo\",\n      \"type\": \"object\"\n    }\n  },\n  \"properties\": {\n    \"final_output\": {\n      \"$ref\": \"#/$defs/UserInfo\"\n    },\n    \"provider_info\": {\n      \"$ref\": \"#/$defs/ProviderInfo\"\n    },\n    \"tool_responses\": {\n      \"items\": {\n        \"$ref\": \"#/$defs/ToolResponse_zipcode_lookup_\"\n      },\n      \"title\": \"Tool Responses\",\n      \"type\": \"array\"\n    },\n    \"state\": {\n      \"$ref\": \"#/$defs/AgentState_UserParsingAgent_\"\n    }\n  },\n  \"required\": [\n    \"final_output\",\n    \"provider_info\",\n    \"tool_responses\",\n    \"state\"\n  ],\n  \"title\": \"UserParsingAgentResponse\",\n  \"type\": \"object\"\n}\n</code></pre> <p>This ensures that the agent's output is a valid JSON object that conforms to the specified Pydantic model, providing type safety and structured data you can rely on.</p>"},{"location":"tools/","title":"Tools","text":"<p>Tools are the primary way agents interact with the outside world and perform actions. By decorating methods with <code>@tool</code>, you give your agents capabilities like searching databases, calling APIs, processing files, or any other Python function you can write.</p>"},{"location":"tools/#why-use-tools","title":"Why Use Tools?","text":"<p>LLMs are excellent at reasoning and generating text, but they can't directly interact with external systems. Tools bridge this gap by:</p> <ul> <li>Extending Capabilities: Give agents access to APIs, databases, file systems, and more</li> <li>Type Safety: Full parameter validation and type checking via Pydantic</li> <li>Dynamic Constraints: Use <code>ref</code> to constrain parameters to valid state values</li> <li>Automatic Schema Generation: Tool definitions are automatically converted to LLM-compatible schemas</li> <li>Error Handling: Built-in error handling and result tracking</li> </ul>"},{"location":"tools/#basic-tool-declaration","title":"Basic Tool Declaration","text":"<p>The simplest tool is a method decorated with <code>@tool</code> that returns a string:</p> <pre><code>from pyagentic import BaseAgent, tool\n\nclass ResearchAgent(BaseAgent):\n    __system_message__ = \"I help with research tasks\"\n\n    @tool(\"Search for academic papers on a topic\")\n    def search_papers(self, query: str) -&gt; str:\n        # Your search logic here\n        results = search_database(query)\n        return f\"Found {len(results)} papers about '{query}'\"\n</code></pre> <p>Every tool must: - Have a <code>@tool</code> decorator with a description - Have type-annotated parameters - Return a <code>str</code> (the result passed back to the LLM)</p> <p>When the LLM decides to use this tool, PyAgentic will: 1. Extract the parameters from the LLM's tool call 2. Validate the parameter types 3. Execute your tool method 4. Return the string result to the LLM</p>"},{"location":"tools/#tool-parameters","title":"Tool Parameters","text":"<p>Tools can accept any number of typed parameters. PyAgentic automatically generates the proper schema for the LLM:</p> <pre><code>class DataAgent(BaseAgent):\n    __system_message__ = \"I analyze data\"\n\n    @tool(\"Query database with filters\")\n    def query_data(\n        self,\n        table: str,\n        limit: int,\n        filters: dict,\n        include_metadata: bool\n    ) -&gt; str:\n        results = db.query(table, limit=limit, filters=filters)\n        return f\"Retrieved {len(results)} records from {table}\"\n</code></pre>"},{"location":"tools/#supported-parameter-types","title":"Supported Parameter Types","text":"<p>PyAgentic supports a variety of parameter types:</p> Type Example Description <code>str</code> <code>query: str</code> String values <code>int</code> <code>count: int</code> Integer numbers <code>float</code> <code>threshold: float</code> Floating point numbers <code>bool</code> <code>include_all: bool</code> Boolean true/false <code>list[T]</code> <code>tags: list[str]</code> Lists of primitives <code>dict</code> <code>metadata: dict</code> Dictionary/object <code>BaseModel</code> <code>options: SearchOptions</code> Custom Pydantic model <code>list[BaseModel]</code> <code>items: list[Item]</code> List of custom models"},{"location":"tools/#parameter-configuration-with-specparam","title":"Parameter Configuration with <code>spec.Param</code>","text":"<p>Use <code>spec.Param()</code> to add descriptions, defaults, and constraints to parameters:</p> <pre><code>from pyagentic import spec\n\nclass FileAgent(BaseAgent):\n    __system_message__ = \"I manage files\"\n\n    @tool(\"Read a file from the system\")\n    def read_file(\n        self,\n        path: str = spec.Param(\n            description=\"Path to the file to read\",\n            required=True\n        ),\n        encoding: str = spec.Param(\n            description=\"Text encoding to use\",\n            default=\"utf-8\"\n        ),\n        max_lines: int = spec.Param(\n            description=\"Maximum number of lines to read\",\n            default=100\n        )\n    ) -&gt; str:\n        with open(path, encoding=encoding) as f:\n            lines = [f.readline() for _ in range(max_lines)]\n        return f\"Read {len(lines)} lines from {path}\"\n</code></pre>"},{"location":"tools/#specparam-options","title":"<code>spec.Param()</code> Options","text":"<pre><code>spec.Param(\n    description=\"Human-readable parameter description\",\n    required=True,           # Must be provided by LLM\n    default=\"value\",          # Default if not provided\n    default_factory=list,     # Factory function for mutable defaults\n    values=[\"opt1\", \"opt2\"]  # Constrain to specific values (enum)\n)\n</code></pre>"},{"location":"tools/#custom-parameter-models","title":"Custom Parameter Models","text":"<p>For complex structured input, use Pydantic <code>BaseModel</code> classes:</p> <pre><code>from pydantic import BaseModel, Field\n\nclass SearchOptions(BaseModel):\n    query: str = Field(..., description=\"Search query string\")\n    max_results: int = Field(default=10, description=\"Maximum results\")\n    filters: dict = Field(default_factory=dict, description=\"Additional filters\")\n    case_sensitive: bool = Field(default=False, description=\"Case sensitive search\")\n\nclass SearchAgent(BaseAgent):\n    __system_message__ = \"I search databases\"\n\n    @tool(\"Search with advanced options\")\n    def search(self, options: SearchOptions) -&gt; str:\n        # Access structured parameters\n        results = db.search(\n            options.query,\n            max_results=options.max_results,\n            filters=options.filters,\n            case_sensitive=options.case_sensitive\n        )\n        return f\"Found {len(results)} results\"\n</code></pre> <p>Benefits of custom parameter models: - Grouped Parameters: Organize related parameters logically - Validation: Pydantic validates all fields automatically - Reusability: Use the same model across multiple tools - Documentation: Field descriptions help the LLM understand parameters</p>"},{"location":"tools/#lists-of-custom-models","title":"Lists of Custom Models","text":"<p>Tools can accept lists of custom models for batch operations:</p> <pre><code>class Task(BaseModel):\n    title: str = Field(..., description=\"Task title\")\n    priority: int = Field(default=1, description=\"Priority level 1-5\")\n    tags: list[str] = Field(default_factory=list, description=\"Task tags\")\n\nclass TaskAgent(BaseAgent):\n    __system_message__ = \"I manage tasks\"\n\n    @tool(\"Create multiple tasks at once\")\n    def create_tasks(self, tasks: list[Task]) -&gt; str:\n        for task in tasks:\n            db.create(task.title, task.priority, task.tags)\n        return f\"Created {len(tasks)} tasks\"\n</code></pre>"},{"location":"tools/#dynamic-constraints-with-ref","title":"Dynamic Constraints with <code>ref</code>","text":"<p>The <code>ref</code> system allows you to constrain tool parameters to valid state values, preventing the LLM from hallucinating invalid options:</p> <pre><code>from pydantic import BaseModel, computed_field\nfrom pyagentic import State, ref, spec\n\nclass FileSystemState(BaseModel):\n    current_directory: str = \"/home\"\n    available_files: list[str] = []\n\n    @computed_field\n    @property\n    def file_names(self) -&gt; list[str]:\n        \"\"\"List of just the file names\"\"\"\n        return [f.split('/')[-1] for f in self.available_files]\n\nclass FileAgent(BaseAgent):\n    __system_message__ = \"I manage files in the current directory\"\n\n    filesystem: State[FileSystemState] = spec.State(default_factory=FileSystemState)\n\n    @tool(\"Open a file from the current directory\")\n    def open_file(\n        self,\n        filename: str = spec.Param(\n            description=\"File to open\",\n            values=ref.filesystem.file_names  # LLM can ONLY choose from this list!\n        )\n    ) -&gt; str:\n        return f\"Opened {filename}\"\n</code></pre>"},{"location":"tools/#how-ref-works","title":"How <code>ref</code> Works","text":"<p>When you use <code>ref.filesystem.file_names</code>: 1. Declaration Time: A <code>RefNode</code> is created storing the path <code>['filesystem', 'file_names']</code> 2. Instantiation Time: The tool definition stores this reference 3. Runtime: When generating the tool schema for the LLM:    - PyAgentic builds an agent reference dictionary from the current state    - The <code>RefNode</code> resolves by walking the path to get the actual value    - The resolved value is injected into the tool schema as the <code>enum</code> constraint</p> <p>This means the LLM always sees the current, up-to-date list of valid options, and it's impossible for it to hallucinate an invalid filename.</p>"},{"location":"tools/#common-ref-patterns","title":"Common <code>ref</code> Patterns","text":"<p>Constrain to state values: <pre><code>@tool(\"Select a dataset\")\ndef select(\n    self,\n    dataset: str = spec.Param(values=ref.datasets.available_names)\n) -&gt; str: ...\n</code></pre></p> <p>Use computed fields for dynamic lists: <pre><code>class ProjectState(BaseModel):\n    projects: list[dict] = []\n\n    @computed_field\n    @property\n    def active_project_ids(self) -&gt; list[str]:\n        return [p['id'] for p in self.projects if p['active']]\n\n@tool(\"Archive a project\")\ndef archive(\n    self,\n    project_id: str = spec.Param(values=ref.projects.active_project_ids)\n) -&gt; str: ...\n</code></pre></p> <p>Reference nested state: <pre><code>@tool(\"Set user preference\")\ndef set_preference(\n    self,\n    key: str = spec.Param(values=ref.config.user.valid_preference_keys)\n) -&gt; str: ...\n</code></pre></p>"},{"location":"tools/#accessing-agent-state-in-tools","title":"Accessing Agent State in Tools","text":"<p>Tools have full access to agent state via <code>self</code>:</p> <pre><code>class ResearchAgent(BaseAgent):\n    __system_message__ = \"I research papers\"\n\n    paper_count: State[int] = spec.State(default=0)\n    current_topic: State[str] = spec.State(default=\"general\")\n\n    @tool(\"Add a paper to the collection\")\n    def add_paper(self, title: str, authors: str) -&gt; str:\n        # Read state\n        topic = self.current_topic\n\n        # Modify state\n        self.paper_count += 1\n\n        # Use state in logic\n        db.save_paper(title, authors, topic)\n\n        return f\"Added paper #{self.paper_count} about {topic}\"\n</code></pre> <p>State modifications in tools persist across agent calls, enabling stateful workflows.</p>"},{"location":"tools/#async-tools","title":"Async Tools","text":"<p>Tools can be async functions for I/O operations:</p> <pre><code>class APIAgent(BaseAgent):\n    __system_message__ = \"I call external APIs\"\n\n    @tool(\"Fetch data from external API\")\n    async def fetch_data(self, endpoint: str) -&gt; str:\n        async with httpx.AsyncClient() as client:\n            response = await client.get(f\"https://api.example.com/{endpoint}\")\n            data = response.json()\n        return f\"Retrieved {len(data)} items from {endpoint}\"\n\n    @tool(\"Search the web\")\n    async def web_search(self, query: str, max_results: int = 5) -&gt; str:\n        results = await async_web_search(query, limit=max_results)\n        return f\"Found {len(results)} results for '{query}'\"\n</code></pre> <p>PyAgentic automatically detects and handles async tools, awaiting them during execution.</p>"},{"location":"tools/#conditional-tools","title":"Conditional Tools","text":"<p>Tools can be conditionally included based on state using the <code>condition</code> parameter:</p> <pre><code>class WorkflowAgent(BaseAgent):\n    __system_message__ = \"I manage workflows\"\n\n    workflow_stage: State[str] = spec.State(default=\"initial\")\n\n    @tool(\n        \"Start data processing\",\n        condition=lambda self: self.workflow_stage == \"ready\"\n    )\n    def start_processing(self) -&gt; str:\n        self.workflow_stage = \"processing\"\n        return \"Started processing\"\n\n    @tool(\n        \"Finalize results\",\n        condition=lambda self: self.workflow_stage == \"processing\"\n    )\n    def finalize(self) -&gt; str:\n        self.workflow_stage = \"complete\"\n        return \"Finalized results\"\n</code></pre>"},{"location":"tools/#how-condition-works","title":"How <code>condition</code> Works","text":"<p>The <code>condition</code> parameter accepts a callable (typically a lambda function) that receives the agent instance (<code>self</code>) and returns a boolean:</p> <ul> <li>Evaluation Time: Conditions are evaluated each time the tool schema is generated for the LLM, which happens before every agent interaction</li> <li>Access to State: The condition function has full access to the agent's state via <code>self</code>, allowing dynamic decisions based on current values</li> <li>Dynamic Toolset: Only tools whose conditions evaluate to <code>True</code> are included in the LLM's available toolset for that interaction</li> </ul> <p>This mechanism allows you to create state-machine-like workflows where available tools change as the agent progresses through different states.</p> <p>Tools can also be restricted to specific phases using the <code>phases</code> parameter for structured multi-stage workflows. See the phases documentation for more details.</p>"},{"location":"tools/#error-handling","title":"Error Handling","text":"<p>When tools raise exceptions, PyAgentic catches them and returns an error message to the LLM:</p> <pre><code>@tool(\"Divide two numbers\")\ndef divide(self, a: float, b: float) -&gt; str:\n    if b == 0:\n        raise ValueError(\"Cannot divide by zero\")\n    result = a / b\n    return f\"{a} / {b} = {result}\"\n</code></pre> <p>If the LLM calls this tool with <code>b=0</code>, PyAgentic will catch the exception and send a message like: <pre><code>Tool `divide` failed: Cannot divide by zero. Please kindly state to the user that it failed, provide state, and ask if they want to try again.\n</code></pre></p> <p>The LLM can then inform the user and potentially retry with different parameters.</p>"},{"location":"tools/#custom-error-handling","title":"Custom Error Handling","text":"<p>For more control, catch exceptions yourself:</p> <pre><code>@tool(\"Process data file\")\ndef process_file(self, path: str) -&gt; str:\n    try:\n        with open(path) as f:\n            data = json.load(f)\n        results = process_data(data)\n        return f\"Processed {len(results)} items from {path}\"\n    except FileNotFoundError:\n        return f\"Error: File '{path}' not found. Available files: {', '.join(self.available_files)}\"\n    except json.JSONDecodeError:\n        return f\"Error: File '{path}' is not valid JSON\"\n    except Exception as e:\n        return f\"Error processing file: {str(e)}\"\n</code></pre> <p>Returning error messages as strings allows the LLM to handle errors gracefully and provide helpful feedback to users.</p>"},{"location":"diagrams/source/","title":"Architecture Diagrams","text":"<p>This directory contains the source D2 files for PyAgentic's architecture diagrams.</p>"},{"location":"diagrams/source/#files","title":"Files","text":"<ul> <li><code>declaration.d2</code> - Shows the declaration phase where the metaclass processes agent class definitions</li> <li><code>instantiation.d2</code> - Shows the instantiation phase where agent instances are created</li> <li><code>runtime.d2</code> - Shows the runtime execution phase of the agentic loop</li> </ul>"},{"location":"diagrams/source/#building-diagrams","title":"Building Diagrams","text":"<p>The diagrams are automatically compiled to SVG when building or deploying the documentation:</p> <pre><code># Compile all diagrams\nuv run task compile-diagrams\n\n# Build docs (automatically compiles diagrams first)\nuv run task build-docs\n\n# Serve docs locally (automatically compiles diagrams first)\nuv run task serve-docs\n\n# Deploy docs (automatically compiles diagrams first)\nuv run task deploy-docs\n</code></pre>"},{"location":"diagrams/source/#layout-engine","title":"Layout Engine","text":"<p>The <code>.d2</code> files specify <code>tala</code> as the layout engine for optimal results, but the build process uses <code>elk</code> by default since <code>tala</code> requires a separate installation.</p> <p>To use <code>tala</code> for better layouts:</p> <ol> <li>Install tala: https://d2lang.com/tour/tala</li> <li>Compile manually without the <code>--layout</code> flag:    <pre><code>d2 declaration.d2 ../declaration.svg\nd2 instantiation.d2 ../instantiation.svg\nd2 runtime.d2 ../runtime.svg\n</code></pre></li> </ol>"},{"location":"diagrams/source/#editing-diagrams","title":"Editing Diagrams","text":"<ol> <li>Edit the <code>.d2</code> files in this directory</li> <li>Run <code>uv run task compile-diagrams</code> to regenerate the SVGs</li> <li>Preview by serving the docs: <code>uv run task serve-docs</code></li> </ol> <p>For D2 syntax and features, see: https://d2lang.com/tour/intro</p>"},{"location":"reference/architecture/","title":"Architecture","text":"<p>This page documents the internal architecture of PyAgentic, showing how agents are constructed from declaration through instantiation to runtime execution.</p>"},{"location":"reference/architecture/#overview","title":"Overview","text":"<p>PyAgentic's architecture is built around three distinct phases:</p> <ol> <li>Declaration Phase - User writes agent class code, metaclass processes it</li> <li>Instantiation Phase - Agent class is instantiated with dynamic state and initialization</li> <li>Runtime Phase - Agent executes, calling tools and linked agents in an agentic loop</li> </ol> <p>Each phase builds upon the previous one, transforming user-friendly declarations into sophisticated runtime behavior.</p>"},{"location":"reference/architecture/#declaration-phase","title":"Declaration Phase","text":"<p>The declaration phase occurs when you define an agent class. The <code>AgentMetaclass</code> intercepts the class definition and generates all the internal structures needed for the agent to function.</p> <p></p>"},{"location":"reference/architecture/#key-components","title":"Key Components","text":"<p>User Declarations: - BaseAgent - Your agent class inherits from this - System Message - The agent's core instructions - State Fields - <code>State[T]</code> annotations with optional <code>spec.State()</code> configuration - Linked Agents - <code>Link[AgentClass]</code> or direct type annotations with optional <code>spec.AgentLink()</code> configuration - Tools - Methods decorated with <code>@tool</code></p> <p>Metaclass Processing: 1. Extract Attributes - Pulls state, tools, and linked agents from the class 2. C3 Linearize - Resolves inheritance from parent classes and mixins 3. Validate Definitions - Ensures all definitions are valid 4. Generate Definitions - Creates internal definition objects:    - <code>_StateDefinition</code> - Pairs <code>State[T]</code> type with <code>StateInfo</code> descriptor (from <code>spec.State()</code>)    - <code>_ToolDefinition</code> - Schema and metadata for each tool    - <code>_LinkedAgentDefinition</code> - Pairs <code>Link[T]</code> type with <code>AgentInfo</code> descriptor (from <code>spec.AgentLink()</code>) 5. Build Init - Dynamically generates <code>__init__</code> signature and function 6. Build Response Model - Creates Pydantic response model from tool definitions</p> <p>Generated Class Structure: - <code>__tool_defs__</code> - Registry of all tool definitions - <code>__state_defs__</code> - Registry of all state definitions - <code>__linked_agents__</code> - Registry of all linked agent types - <code>__response_model__</code> - Pydantic model for agent responses - <code>__init__()</code> - Dynamically generated constructor</p>"},{"location":"reference/architecture/#supporting-utilities","title":"Supporting Utilities","text":"<p>The <code>spec</code> object provides configuration helpers using a descriptor pattern: - <code>spec.State()</code> - Returns <code>StateInfo</code> descriptor for state fields (default, default_factory, access control, policies) - <code>spec.Param()</code> - Returns <code>ParamInfo</code> descriptor for tool parameters (description, default, values) - <code>spec.AgentLink()</code> - Returns <code>AgentInfo</code> descriptor for linked agents (default, default_factory, condition)</p> <p>The <code>ref</code> object creates lazy references to state for use in tool parameters: - <code>ref.field.subfield</code> creates a <code>RefNode</code> that resolves at runtime - Used to constrain parameters to valid state values</p>"},{"location":"reference/architecture/#instantiation-phase","title":"Instantiation Phase","text":"<p>The instantiation phase occurs when you create an instance of your agent class (e.g., <code>agent = MyAgent(...)</code>). The dynamically generated <code>__init__</code> method creates the agent's runtime state and configuration.</p> <p></p>"},{"location":"reference/architecture/#initialization-flow","title":"Initialization Flow","text":"<ol> <li>Make State Model</li> <li>Creates a dynamic Pydantic model from <code>__state_defs__</code></li> <li>Each state field becomes a validated model field</li> <li> <p>Computed fields are included automatically</p> </li> <li> <p>Compile State Values</p> </li> <li>Processes initialization arguments</li> <li>Applies default values from <code>spec.State()</code></li> <li> <p>Type-checks all values</p> </li> <li> <p>Create State Instance</p> </li> <li>Instantiates the dynamic state model</li> <li>Stores as <code>agent.state</code></li> <li> <p>Includes system message and templates</p> </li> <li> <p>Set Linked Agents</p> </li> <li>Processes <code>AgentInfo</code> from <code>spec.AgentLink()</code> for each linked agent</li> <li>Applies <code>default</code> or calls <code>default_factory</code> if agent not provided</li> <li>Attaches agent instances to the parent</li> <li>Creates tool definitions from linked agents</li> <li> <p>Validates linked agent types</p> </li> <li> <p>Set Attributes</p> </li> <li>Attaches any additional instance attributes</li> <li> <p>Binds tools as instance methods</p> </li> <li> <p>Post Initialization (<code>__post_init__</code>)</p> </li> <li>Check LLM Provider - Validates model string or provider instance</li> <li>Setup Tracer - Initializes observability tracer (defaults to BasicTracer)</li> </ol>"},{"location":"reference/architecture/#instance-attributes","title":"Instance Attributes","text":"<p>After initialization, the agent instance has: - <code>state</code> - The <code>AgentState</code> instance with all state fields - Linked agents - References to other agent instances - <code>provider</code> - The configured LLM provider - <code>tracer</code> - The observability tracer - <code>model</code>, <code>api_key</code> - Provider configuration - <code>max_call_depth</code> - Maximum depth for the agentic loop</p>"},{"location":"reference/architecture/#runtime-phase","title":"Runtime Phase","text":"<p>The runtime phase occurs when you call <code>agent.run(input)</code> or <code>agent(input)</code>. The agent enters an agentic loop where it can call tools and linked agents multiple times before producing a final response.</p> <p></p>"},{"location":"reference/architecture/#execution-flow","title":"Execution Flow","text":"<ol> <li>Add User Message</li> <li>Input is added to <code>agent.state._messages</code></li> <li> <p>State is now primed for inference</p> </li> <li> <p>Get Tool Definitions</p> </li> <li>Collects all <code>@tool</code> methods from <code>__tool_defs__</code></li> <li>Generates tool definitions for linked agents via <code>agent.get_tool_definition()</code></li> <li> <p>Creates list of available tools for the LLM</p> </li> <li> <p>Process LLM Inference</p> </li> <li>Builds prompt with system message and user input</li> <li>Sends to provider with tool schemas</li> <li> <p>Returns LLM response (text and/or tool calls)</p> </li> <li> <p>Tool Call Routing</p> </li> <li>If no tool calls \u2192 Build final response</li> <li>If tool calls \u2192 Route to appropriate processor:</li> </ol> <p>Process Tool Call:    - Looks up tool in <code>__tool_defs__</code>    - Compiles arguments (resolves refs, validates types)    - Executes tool method    - Returns <code>ToolResponse</code> with result</p> <p>Process Agent Call:    - Looks up linked agent    - Calls <code>linked_agent.run()</code>    - Returns <code>AgentResponse</code> from linked agent</p> <ol> <li>Increment Depth</li> <li>Increases loop counter</li> <li>Checks against <code>max_call_depth</code></li> <li>If under limit \u2192 Loop back to inference</li> <li> <p>If at limit \u2192 Build final response</p> </li> <li> <p>Build Response</p> </li> <li>Combines final LLM output with all tool/agent responses</li> <li>Creates <code>AgentResponse</code> instance using <code>__response_model__</code></li> <li>Returns to caller</li> </ol>"},{"location":"reference/architecture/#response-object","title":"Response Object","text":"<p>The <code>AgentResponse</code> contains: - <code>final_output</code> - The LLM's final text response - <code>tool_responses</code> - List of <code>ToolResponse</code> objects (one per tool call) - <code>agent_responses</code> - List of nested <code>AgentResponse</code> objects (one per linked agent call) - <code>provider_info</code> - Metadata about the LLM provider and usage</p> <p>Each <code>ToolResponse</code> contains: - <code>output</code> - The string result from the tool - <code>call_depth</code> - Which loop iteration this was called in - <code>raw_kwargs</code> - Original arguments from the LLM - Compiled parameters specific to that tool</p>"},{"location":"reference/architecture/#key-design-patterns","title":"Key Design Patterns","text":""},{"location":"reference/architecture/#metaclass-based-construction","title":"Metaclass-Based Construction","text":"<p>Using a metaclass allows PyAgentic to inspect and transform agent classes at definition time, generating optimal runtime structures before any instances are created. This enables: - Compile-time validation of agent definitions - Pre-generated response models for type safety - Efficient tool schema generation - Inheritance and mixin support via C3 linearization</p>"},{"location":"reference/architecture/#dynamic-state-management","title":"Dynamic State Management","text":"<p>State is defined declaratively at the class level but instantiated dynamically per agent instance. This provides: - Type-safe state access via Pydantic - Computed fields that update automatically - Access control (read/write/hidden) - Serialization support</p>"},{"location":"reference/architecture/#reference-resolution","title":"Reference Resolution","text":"<p>The <code>ref</code> system creates lazy references at declaration time that resolve at runtime: 1. Declaration: <code>ref.field.subfield</code> creates <code>RefNode(['field', 'subfield'])</code> 2. Storage: <code>RefNode</code> stored in tool parameter definition 3. Runtime: When generating tool schema, <code>RefNode.resolve(agent_reference)</code> walks the path to get current value</p> <p>This keeps tool parameters synchronized with live state values.</p>"},{"location":"reference/architecture/#tool-as-universal-interface","title":"Tool as Universal Interface","text":"<p>Both custom <code>@tool</code> methods and linked agents use the same <code>_ToolDefinition</code> interface. This allows: - Uniform handling by the LLM - Consistent parameter validation - Seamless composition of agents</p>"},{"location":"reference/architecture/#source-diagrams","title":"Source Diagrams","text":"<p>These architecture diagrams were created using D2. The source <code>.d2</code> files are available in <code>docs/diagrams/source/</code>:</p> <ul> <li><code>docs/diagrams/source/declaration.d2</code> - Declaration phase diagram</li> <li><code>docs/diagrams/source/instantiation.d2</code> - Instantiation phase diagram</li> <li><code>docs/diagrams/source/runtime.d2</code> - Runtime phase diagram</li> </ul> <p>The diagrams are automatically compiled to SVG when building or deploying the documentation. To manually regenerate:</p> <pre><code># Compile all diagrams (uses elk layout engine)\nuv run task compile-diagrams\n\n# Or compile individually with elk layout\nd2 --layout elk docs/diagrams/source/declaration.d2 docs/diagrams/declaration.svg\nd2 --layout elk docs/diagrams/source/instantiation.d2 docs/diagrams/instantiation.svg\nd2 --layout elk docs/diagrams/source/runtime.d2 docs/diagrams/runtime.svg\n</code></pre> <p>Note: The <code>.d2</code> source files specify the <code>tala</code> layout engine, but the build process overrides this with <code>elk</code> since <code>tala</code> requires a separate installation. If you have <code>tala</code> installed locally, you can compile without the <code>--layout elk</code> flag for potentially better layouts.</p>"},{"location":"reference/architecture/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about the public API you should use</li> <li>Read the user guide for practical examples</li> <li>Explore state management for persistent agents</li> <li>See tools for extending agent capabilities</li> </ul>"},{"location":"reference/modules/","title":"API Reference","text":"<p>Complete API documentation for PyAgentic's public interfaces.</p>"},{"location":"reference/modules/#core-classes","title":"Core Classes","text":""},{"location":"reference/modules/#baseagent","title":"BaseAgent","text":"<p>Base agent class to be extended to define new LLM-powered agents.</p> Agent definition requires the use of special decorators and class attributes <ul> <li>@tool: Declares a method as a tool callable by the LLM</li> <li>system_message: Required class attribute defining the agent's system prompt</li> <li>description: Optional description used when agent is linked to another agent</li> <li>input_template: Optional template for formatting user input</li> <li>response_format: Optional Pydantic model for structured output</li> </ul> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>str</code> <p>Model used for inference in format <code>&lt;provider&gt;::&lt;model&gt;</code>. For example: <code>openai::gpt-4o</code>. Requires <code>api_key</code> to also be provided.</p> required <code>api_key</code> <code>str</code> <p>API key matching the model provider</p> required <code>provider</code> <code>LLMProvider</code> <p>Pre-configured provider instance. Overrides <code>model</code> and <code>api_key</code> if provided.</p> required <code>tracer</code> <code>AgentTracer</code> <p>Tracer instance for observability. Defaults to BasicTracer if not provided.</p> required <code>max_call_depth</code> <code>int</code> <p>Maximum number of tool calling loops per run. Defaults to 1.</p> required <p>Examples:</p> <p>With a model string: <pre><code>agent = MyAgent(\n    model=\"openai::gpt-4o\",\n    api_key=MY_API_KEY\n)\n</code></pre></p> <p>With a provider: <pre><code>from pyagentic.llm import OpenAIProvider\n\nagent = MyAgent(\n    provider=OpenAIProvider(\n        model=\"gpt-4o\",\n        api_key=MY_API_KEY,\n        base_url=\"http://localhost:8000\",\n        max_retries=5\n    )\n)\n</code></pre></p>"},{"location":"reference/modules/#pyagentic.BaseAgent.run","title":"<code>run(input_: str) -&gt; AgentResponse</code>  <code>async</code>","text":"<p>Executes the agent with a message string and returns the final result.</p> <p>This method consumes the entire step() generator and returns only the final AgentResponse. Use this when you don't need intermediate streaming responses and just want the final output.</p> <p>Parameters:</p> Name Type Description Default <code>input_</code> <code>str</code> <p>The user input/query for the agent to process</p> required <p>Returns:</p> Name Type Description <code>AgentResponse</code> <code>AgentResponse</code> <p>Structured response containing: - final_output: The final text or structured output from the LLM - state: Current agent state after execution - tool_responses: List of all tool calls and their outputs - agent_responses: List of linked agent calls (if any) - provider_info: Information about the LLM provider used</p> Example <pre><code>agent = MyAgent(model=\"openai::gpt-4o\", api_key=API_KEY)\nresponse = await agent.run(\"What's the weather in San Francisco?\")\nprint(response.final_output)  # LLM's final answer\nprint(response.tool_responses)  # Tools that were called\n</code></pre> Source code in <code>pyagentic/_base/_agent/_agent.py</code> <pre><code>async def run(self, input_: str) -&gt; AgentResponse:\n    \"\"\"\n    Executes the agent with a message string and returns the final result.\n\n    This method consumes the entire step() generator and returns only the final\n    AgentResponse. Use this when you don't need intermediate streaming responses\n    and just want the final output.\n\n    Args:\n        input_ (str): The user input/query for the agent to process\n\n    Returns:\n        AgentResponse: Structured response containing:\n            - final_output: The final text or structured output from the LLM\n            - state: Current agent state after execution\n            - tool_responses: List of all tool calls and their outputs\n            - agent_responses: List of linked agent calls (if any)\n            - provider_info: Information about the LLM provider used\n\n    Example:\n        ```python\n        agent = MyAgent(model=\"openai::gpt-4o\", api_key=API_KEY)\n        response = await agent.run(\"What's the weather in San Francisco?\")\n        print(response.final_output)  # LLM's final answer\n        print(response.tool_responses)  # Tools that were called\n        ```\n    \"\"\"\n    final_response = None\n    async for res in self.step(input_):\n        final_response = res\n    return final_response\n</code></pre>"},{"location":"reference/modules/#pyagentic.BaseAgent.get_tool_definition","title":"<code>get_tool_definition(name: str) -&gt; _ToolDefinition</code>  <code>classmethod</code>","text":"<p>Creates a tool definition for this agent class to be used as a linked agent.</p> <p>When an agent is linked to another agent, it appears as a tool that can be called by the LLM. This method generates the tool definition with the agent's description as the tool description and the agent's call signature as the tool parameters.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name to use for this agent when it appears as a tool</p> required <p>Returns:</p> Name Type Description <code>_ToolDefinition</code> <code>_ToolDefinition</code> <p>A tool definition that can be sent to the LLM</p> Source code in <code>pyagentic/_base/_agent/_agent.py</code> <pre><code>@classmethod\ndef get_tool_definition(cls, name: str) -&gt; _ToolDefinition:\n    \"\"\"\n    Creates a tool definition for this agent class to be used as a linked agent.\n\n    When an agent is linked to another agent, it appears as a tool that can be\n    called by the LLM. This method generates the tool definition with the agent's\n    __description__ as the tool description and the agent's __call__ signature\n    as the tool parameters.\n\n    Args:\n        name (str): The name to use for this agent when it appears as a tool\n\n    Returns:\n        _ToolDefinition: A tool definition that can be sent to the LLM\n    \"\"\"\n    desc = getattr(cls, \"__description__\", \"\") or \"\"\n\n    # Create a fresh async wrapper function for this agent class\n    # Each class needs its own function object for the @tool decorator\n    @wraps(cls.__call__)\n    async def _invoke(self, *args, **kwargs):\n        return await cls.__call__(self, *args, **kwargs)\n\n    # Apply @tool decorator to extract parameter info and create definition\n    td = tool(desc)(_invoke).__tool_def__\n    td.name = name\n    return td\n</code></pre>"},{"location":"reference/modules/#agentextension","title":"AgentExtension","text":"<p>Base class for creating reusable agent mixins that add tools, state, and behaviors.</p> <p>AgentExtension allows you to package common functionality (tools, state fields, linked agents) into reusable components that can be mixed into multiple agent classes. This promotes code reuse and modular agent design.</p> Example <pre><code>class LoggingMixin(AgentExtension):\n    logs: State[list[str]] = spec.State(default_factory=list)\n\n    @tool(\"Record a log message\")\n    def log(self, message: str) -&gt; str:\n        self.state.logs.append(message)\n        return f\"Logged: {message}\"\n\nclass MyAgent(BaseAgent, LoggingMixin):\n    __system_message__ = \"You are a helpful agent with logging\"\n</code></pre>"},{"location":"reference/modules/#pyagentic.AgentExtension.__annotations__","title":"<code>__annotations__: dict[str, Any] = {}</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/modules/#pyagentic.AgentExtension.__init_subclass__","title":"<code>__init_subclass__(**kwargs)</code>","text":"<p>Merges annotations from all AgentExtension bases in MRO order. Subclass annotations override parent annotations on conflicts.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional keyword arguments passed to parent init_subclass</p> <code>{}</code> Source code in <code>pyagentic/_base/_agent/_agent.py</code> <pre><code>def __init_subclass__(cls, **kwargs):\n    \"\"\"\n    Merges annotations from all AgentExtension bases in MRO order.\n    Subclass annotations override parent annotations on conflicts.\n\n    Args:\n        **kwargs: Additional keyword arguments passed to parent __init_subclass__\n    \"\"\"\n    super().__init_subclass__(**kwargs)\n\n    # Merge annotations from all AgentExtension bases (oldest first),\n    # then let the subclass' own annotations win on key conflicts.\n    merged: dict[str, Any] = {}\n    for base in reversed(cls.__mro__[1:]):  # Skip cls itself, walk up towards object\n        if issubclass(base, AgentExtension):\n            ann = getattr(base, \"__annotations__\", None)\n            if ann:\n                merged.update(ann)\n\n    merged.update(getattr(cls, \"__annotations__\", {}))\n    # Assign a fresh dict so we don't mutate a base class' annotations\n    cls.__annotations__ = dict(merged)\n</code></pre>"},{"location":"reference/modules/#decorators","title":"Decorators","text":""},{"location":"reference/modules/#tool","title":"@tool","text":"<p>Decorator to mark an agent method as a tool that the LLM can call.</p> <p>Tools are functions the LLM can invoke to perform actions or retrieve information. The tool description helps the LLM understand when and how to use the tool. All tool methods must return an object that can be casted as a string (to show the LLM).</p> <p>Parameters:</p> Name Type Description Default <code>description</code> <code>str</code> <p>Clear description of what the tool does. The LLM uses this to decide when to call the tool. Be specific and action-oriented.</p> required <code>condition</code> <code>Callable[[Any], bool]</code> <p>Function that returns True/False to conditionally enable/disable the tool. Receives the agent instance (self).</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Callable</code> <p>Decorated method that can be called by the LLM</p> <p>Raises:</p> Type Description <code>InvalidToolDefinition</code> <p>If the method does not have a return type annotation of <code>str</code></p> Example <pre><code>class FileAgent(BaseAgent):\n    __system_message__ = \"You help manage files\"\n\n    @tool(\"Read the contents of a file given its path\")\n    def read_file(self, path: str) -&gt; str:\n        with open(path, 'r') as f:\n            return f.read()\n\n    @tool(\"Write content to a file\", condition=lambda self: self.state.write_enabled)\n    def write_file(self, path: str, content: str) -&gt; str:\n        with open(path, 'w') as f:\n            f.write(content)\n        return f\"Wrote {len(content)} characters to {path}\"\n</code></pre> Source code in <code>pyagentic/_base/_tool.py</code> <pre><code>def tool(description: str, condition: Callable[[Any], bool] = None, phases: list[str] = None):\n    \"\"\"\n    Decorator to mark an agent method as a tool that the LLM can call.\n\n    Tools are functions the LLM can invoke to perform actions or retrieve information.\n    The tool description helps the LLM understand when and how to use the tool.\n    All tool methods must return an object that can be casted as a string (to show the LLM).\n\n    Args:\n        description (str): Clear description of what the tool does. The LLM uses this\n            to decide when to call the tool. Be specific and action-oriented.\n        condition (Callable[[Any], bool], optional): Function that returns True/False to\n            conditionally enable/disable the tool. Receives the agent instance (self).\n\n    Returns:\n        Callable: Decorated method that can be called by the LLM\n\n    Raises:\n        InvalidToolDefinition: If the method does not have a return type annotation of `str`\n\n    Example:\n        ```python\n        class FileAgent(BaseAgent):\n            __system_message__ = \"You help manage files\"\n\n            @tool(\"Read the contents of a file given its path\")\n            def read_file(self, path: str) -&gt; str:\n                with open(path, 'r') as f:\n                    return f.read()\n\n            @tool(\"Write content to a file\", condition=lambda self: self.state.write_enabled)\n            def write_file(self, path: str, content: str) -&gt; str:\n                with open(path, 'w') as f:\n                    f.write(content)\n                return f\"Wrote {len(content)} characters to {path}\"\n        ```\n    \"\"\"\n\n    def decorator(fn: Callable):\n        # Check return type\n        types = get_type_hints(fn)\n        return_type = types.pop(\"return\", None)\n\n        # 2) grab default values\n        sig = inspect.signature(fn)\n        defaults = {\n            param_name: param.default\n            for param_name, param in sig.parameters.items()\n            if param.default is not inspect._empty\n        }\n\n        params = {}\n\n        for name, type_ in types.items():\n            default = defaults.get(name, None)\n            if isinstance(default, ParamInfo):\n                params[name] = (type_, default)\n            elif default is not None:\n                params[name] = (type_, ParamInfo(default=default))\n            else:\n                params[name] = (type_, ParamInfo(required=True))\n\n        fn.__tool_def__ = _ToolDefinition(\n            name=fn.__name__,\n            description=description or fn.__doc__ or \"\",\n            parameters=params,\n            condition=condition,\n            return_type=return_type,\n            phases=phases,\n        )\n        return fn\n\n    return decorator\n</code></pre>"},{"location":"reference/modules/#type-annotations","title":"Type Annotations","text":""},{"location":"reference/modules/#state","title":"State","text":"<p>               Bases: <code>Generic[T]</code></p> <p>Type annotation for defining persistent state fields in agents.</p> <p>State fields hold data that persists across tool calls and LLM interactions. Use Pydantic models as the state type to ensure type safety and validation.</p> <p>Parameters:</p> Name Type Description Default <code>T</code> <p>A Pydantic BaseModel class defining the structure of the state</p> required Example <pre><code>from pydantic import BaseModel\n\nclass ConversationState(BaseModel):\n    user_name: str\n    message_count: int = 0\n\nclass ChatAgent(BaseAgent):\n    __system_message__ = \"You are a chatbot\"\n\n    # Simple state field\n    conversation: State[ConversationState]\n\n    # State field with default value\n    logs: State[list] = spec.State(default_factory=list)\n</code></pre>"},{"location":"reference/modules/#pyagentic.State.__class_getitem__","title":"<code>__class_getitem__(item)</code>","text":"<p>Creates a generic State type for a given model class.</p> <p>Parameters:</p> Name Type Description Default <code>item</code> <p>The model class to wrap as a state field</p> required <p>Returns:</p> Name Type Description <code>type</code> <p>Special marker type that the metaclass can detect and process</p> Source code in <code>pyagentic/_base/_state.py</code> <pre><code>def __class_getitem__(cls, item):\n    \"\"\"\n    Creates a generic State type for a given model class.\n\n    Args:\n        item: The model class to wrap as a state field\n\n    Returns:\n        type: Special marker type that the metaclass can detect and process\n    \"\"\"\n    # Return a special marker type that metaclass can detect\n    return type(\n        f\"State[{item.__name__}]\",\n        (),\n        {\"__origin__\": State, \"__args__\": (item,), \"__state_model__\": item},\n    )\n</code></pre>"},{"location":"reference/modules/#link","title":"Link","text":"<p>               Bases: <code>Generic[T]</code></p> <p>Type annotation for linking other agents as callable tools.</p> <p>Linked agents appear as tools to the parent agent, allowing complex multi-agent workflows. When the LLM calls a linked agent, that agent runs its full execution cycle and returns results to the parent.</p> <p>Parameters:</p> Name Type Description Default <code>T</code> <p>An agent class (subclass of BaseAgent) to link</p> required Example <pre><code>class ResearchAgent(BaseAgent):\n    __system_message__ = \"You research topics deeply\"\n    __description__ = \"Research agent for gathering detailed information\"\n\nclass OrchestratorAgent(BaseAgent):\n    __system_message__ = \"You coordinate research tasks\"\n\n    # Link research agent as a tool\n    researcher: Link[ResearchAgent]\n\n    # Conditional linking (agent only available when condition is true)\n    expert: Link[ExpertAgent] = spec.AgentLink(\n        condition=lambda self: self.state.needs_expert\n    )\n</code></pre>"},{"location":"reference/modules/#pyagentic.Link.__class_getitem__","title":"<code>__class_getitem__(item)</code>","text":"<p>Creates a generic Link type for a given agent class.</p> <p>Parameters:</p> Name Type Description Default <code>item</code> <p>The agent class to link</p> required <p>Returns:</p> Name Type Description <code>type</code> <p>Special marker type that the metaclass can detect and process</p> Source code in <code>pyagentic/_base/_agent/_agent_linking.py</code> <pre><code>def __class_getitem__(cls, item):\n    \"\"\"\n    Creates a generic Link type for a given agent class.\n\n    Args:\n        item: The agent class to link\n\n    Returns:\n        type: Special marker type that the metaclass can detect and process\n    \"\"\"\n    # Return a special marker type that metaclass can detect\n    return type(\n        f\"Link[{item.__name__}]\",\n        (),\n        {\"__origin__\": Link, \"__args__\": (item,), \"__linked_agent__\": item},\n    )\n</code></pre>"},{"location":"reference/modules/#configuration","title":"Configuration","text":""},{"location":"reference/modules/#spec","title":"spec","text":"<p>Factory class for creating configuration descriptors for agent fields.</p> <p>The <code>spec</code> object provides methods to configure state fields, tool parameters, and linked agents with advanced options like defaults, policies, and conditions.</p> <p>Methods:</p> Name Description <code>- spec.State</code> <p>Configure agent state fields</p> <code>- spec.Param</code> <p>Configure tool parameters with validation</p> <code>- spec.AgentLink</code> <p>Configure linked agent fields</p> Example <pre><code>from pyagentic import BaseAgent, State, spec, tool\nfrom pydantic import BaseModel\n\nclass UserProfile(BaseModel):\n    name: str\n    email: str\n\nclass MyAgent(BaseAgent):\n    __system_message__ = \"You are a helpful assistant\"\n\n    # State with default factory\n    profile: State[UserProfile] = spec.State(\n        default_factory=lambda: UserProfile(name=\"Guest\", email=\"\")\n    )\n\n    # State with policies\n    logs: State[list] = spec.State(\n        default_factory=list,\n        policies=[LoggingPolicy()]\n    )\n\n    @tool(\"Update user profile\")\n    def update_profile(\n        self,\n        name: str = spec.Param(description=\"User's full name\", required=True),\n        email: str = spec.Param(description=\"User's email address\")\n    ) -&gt; str:\n        self.state.profile.name = name\n        if email:\n            self.state.profile.email = email\n        return f\"Updated profile for {name}\"\n</code></pre>"},{"location":"reference/modules/#pyagentic.spec.State","title":"<code>State(default: Any = None, default_factory: Callable = None, policies: list[Policy] = None, access: Literal['read', 'write', 'readwrite', 'hidden'] = 'read', description: str | None = None, get_description: str | None = None, set_description: str | None = None, **kwargs) -&gt; StateInfo</code>  <code>staticmethod</code>","text":"<p>Creates a StateInfo descriptor for configuring agent state fields.</p> <p>Parameters:</p> Name Type Description Default <code>default</code> <code>Any</code> <p>The default value for the state field</p> <code>None</code> <code>default_factory</code> <code>Callable</code> <p>A factory function to generate the default value</p> <code>None</code> <code>policies</code> <code>list[Policy]</code> <p>List of policies to apply to this state field</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments passed to StateInfo</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>StateInfo</code> <code>StateInfo</code> <p>A configured StateInfo descriptor</p> Source code in <code>pyagentic/_base/_spec.py</code> <pre><code>@staticmethod\ndef State(\n    default: Any = None,\n    default_factory: Callable = None,\n    policies: list[Policy] = None,\n    access: Literal[\"read\", \"write\", \"readwrite\", \"hidden\"] = \"read\",\n    description: str | None = None,\n    get_description: str | None = None,\n    set_description: str | None = None,\n    **kwargs,\n) -&gt; StateInfo:\n    \"\"\"\n    Creates a StateInfo descriptor for configuring agent state fields.\n\n    Args:\n        default (Any, optional): The default value for the state field\n        default_factory (Callable, optional): A factory function to generate the default value\n        policies (list[Policy], optional): List of policies to apply to this state field\n        **kwargs: Additional keyword arguments passed to StateInfo\n\n    Returns:\n        StateInfo: A configured StateInfo descriptor\n    \"\"\"\n    return StateInfo(\n        default=default,\n        default_factory=default_factory,\n        policies=policies,\n        access=access,\n        description=description,\n        get_description=get_description,\n        set_description=set_description,\n        **kwargs,\n    )\n</code></pre>"},{"location":"reference/modules/#pyagentic.spec.Param","title":"<code>Param(description: str = None, required: bool = False, default: Any = None, default_factory: Callable = None, values: Any = None) -&gt; ParamInfo</code>  <code>staticmethod</code>","text":"<p>Creates a ParamInfo descriptor for configuring tool parameters.</p> <p>Parameters:</p> Name Type Description Default <code>description</code> <code>str</code> <p>A human-readable description of the parameter</p> <code>None</code> <code>required</code> <code>bool</code> <p>Whether this parameter must be provided. Defaults to False</p> <code>False</code> <code>default</code> <code>Any</code> <p>The default value for the parameter</p> <code>None</code> <code>default_factory</code> <code>Callable</code> <p>A factory function to generate the default value</p> <code>None</code> <code>values</code> <code>Any</code> <p>List of valid values to constrain the parameter</p> <code>None</code> <p>Returns:</p> Name Type Description <code>ParamInfo</code> <code>ParamInfo</code> <p>A configured ParamInfo descriptor</p> Source code in <code>pyagentic/_base/_spec.py</code> <pre><code>@staticmethod\ndef Param(\n    description: str = None,\n    required: bool = False,\n    default: Any = None,\n    default_factory: Callable = None,\n    values: Any = None,\n) -&gt; ParamInfo:\n    \"\"\"\n    Creates a ParamInfo descriptor for configuring tool parameters.\n\n    Args:\n        description (str, optional): A human-readable description of the parameter\n        required (bool): Whether this parameter must be provided. Defaults to False\n        default (Any, optional): The default value for the parameter\n        default_factory (Callable, optional): A factory function to generate the default value\n        values (Any, optional): List of valid values to constrain the parameter\n\n    Returns:\n        ParamInfo: A configured ParamInfo descriptor\n    \"\"\"\n    return ParamInfo(\n        description=description,\n        required=required,\n        default=default,\n        default_factory=default_factory,\n        values=values,\n    )\n</code></pre>"},{"location":"reference/modules/#pyagentic.spec.AgentLink","title":"<code>AgentLink(default: Any = None, default_factory: Callable = None, condition: Callable = None, phases: list[str] | None = None) -&gt; AgentInfo</code>  <code>staticmethod</code>","text":"<p>Creates an AgentInfo descriptor for configuring linked agent fields.</p> <p>Parameters:</p> Name Type Description Default <code>default</code> <code>Any</code> <p>The default agent instance</p> <code>None</code> <code>default_factory</code> <code>Callable</code> <p>A factory function to generate the default agent</p> <code>None</code> <code>condition</code> <code>Callable</code> <p>A callable determining when this agent link is active</p> <code>None</code> <code>phases</code> <code>list[str]</code> <p>A list of phases of when this agent will be available. When None, will show for all phases. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>AgentInfo</code> <code>AgentInfo</code> <p>A configured AgentInfo descriptor</p> Source code in <code>pyagentic/_base/_spec.py</code> <pre><code>@staticmethod\ndef AgentLink(\n    default: Any = None,\n    default_factory: Callable = None,\n    condition: Callable = None,\n    phases: list[str] | None = None,\n) -&gt; AgentInfo:\n    \"\"\"\n    Creates an AgentInfo descriptor for configuring linked agent fields.\n\n    Args:\n        default (Any, optional): The default agent instance\n        default_factory (Callable, optional): A factory function to generate the default agent\n        condition (Callable, optional): A callable determining when this agent link is active\n        phases (list[str], optional): A list of phases of when this agent will be available.\n            When None, will show for all phases. Defaults to None.\n\n    Returns:\n        AgentInfo: A configured AgentInfo descriptor\n    \"\"\"\n    return AgentInfo(\n        default=default, default_factory=default_factory, condition=condition, phases=phases\n    )\n</code></pre>"},{"location":"reference/modules/#state-references","title":"State References","text":""},{"location":"reference/modules/#ref","title":"ref","text":""}]}