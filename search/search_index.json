{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"PyAgentic Documentation","text":"<p>Build sophisticated AI agents with declarative Python syntax. PyAgentic provides a type-safe, extensible framework for creating LLM agents with persistent context, powerful tools, and seamless integration with multiple LLM providers including OpenAI, Anthropic, and others.</p>"},{"location":"#quick-start","title":"Quick Start","text":"<p>New to PyAgentic? Start here to build your first agent in minutes:</p> <ul> <li> <p>Getting Started Guide</p> <p>Complete tutorial building a research assistant agent from scratch. Learn core concepts through practical examples.</p> <p> Start building</p> </li> </ul>"},{"location":"#core-documentation","title":"Core Documentation","text":"<p>Dive deeper into PyAgentic's powerful features:</p> <ul> <li> <p> Agent Responses</p> <p>Understanding structured response objects with tool execution details and type safety.</p> <p> Learn about responses</p> </li> <li> <p> Structured Outputs</p> <p>Using Pydantic models to enforce structured output schemas for your agents.</p> <p> Learn about structured outputs</p> </li> <li> <p> Agent Linking</p> <p>Build complex multi-agent workflows where agents call other agents as specialized tools.</p> <p> Explore linking</p> </li> <li> <p> Inheritance &amp; Extensions</p> <p>Create agent hierarchies and add cross-cutting capabilities with extensions.</p> <p> Build hierarchies</p> </li> <li> <p>:material-search: Observability</p> <p>Observe and trace all steps and interactions of an agent.</p> <p> Trace behavior</p> </li> </ul> <ul> <li>GitHub: rmikulec/pyagentic - Source code, issues, and contributions</li> <li>Installation: <code>pip install pyagentic-core</code></li> <li>Python Support: 3.13+</li> </ul>"},{"location":"agent-linking/","title":"Agent Linking","text":"<p>Agent linking allows you to build multi-agent systems where agents can call other agents as specialized tools. This enables complex workflows where different agents handle their areas of expertise while a coordinator orchestrates the overall process.</p>"},{"location":"agent-linking/#how-agent-linking-works","title":"How Agent Linking Works","text":"<p>When you declare an agent as an attribute of another agent class, PyAgentic automatically makes it available as a tool. The linked agent appears in the parent's toolset with its <code>__description__</code> as the tool description. When the LLM decides to use that \"tool,\" PyAgentic seamlessly calls the linked agent and integrates its response.</p> <p>This happens at the class definition level - each agent knows about its linked agents before any instances are created, ensuring type safety and predictable behavior.</p>"},{"location":"agent-linking/#basic-linking","title":"Basic Linking","text":"<p>The simplest way to link agents is by declaring them as typed attributes in your agent class. This creates a direct relationship where the parent agent can call the child agent as needed:</p> <pre><code>class DatabaseAgent(Agent):\n    __system_message__ = \"I query databases\"\n    __description__ = \"Retrieves and analyzes data from databases\"\n\nclass ReportAgent(Agent):\n    __system_message__ = \"I generate business reports\"\n    database: DatabaseAgent  # Linked agent\n\n# The report agent can now automatically call the database agent\nresponse = await report_agent(\"Create a sales report for Q4\")\n</code></pre> <p>When the report agent runs, the LLM sees the database agent as an available tool in its toolset. If the LLM determines it needs database information to complete the task, it will automatically call the database agent. PyAgentic handles all the communication, context passing, and response integration behind the scenes.</p>"},{"location":"agent-linking/#multiple-linked-agents","title":"Multiple Linked Agents","text":"<p>Real-world applications often require coordination between multiple specialized agents. You can link as many agents as needed to create sophisticated workflows where each agent contributes its expertise:</p> <pre><code>class EmailAgent(Agent):\n    __system_message__ = \"I send emails\"\n    __description__ = \"Sends and manages email communications\"\n\nclass CalendarAgent(Agent):\n    __system_message__ = \"I manage calendars\"\n    __description__ = \"Schedules meetings and manages calendar events\"\n\nclass AssistantAgent(Agent):\n    __system_message__ = \"I help with daily tasks\"\n\n    email: EmailAgent\n    calendar: CalendarAgent\n\nresponse = await assistant.run(\"Schedule a meeting with John and send him the details\")\n</code></pre> <p>With multiple linked agents, the coordinator can intelligently decide which agents to call and in what order. In this example, the assistant might first call the calendar agent to schedule the meeting, then use that information to call the email agent to send the details. The LLM automatically determines the optimal workflow based on the task requirements.</p>"},{"location":"agent-linking/#custom-agent-parameters","title":"Custom Agent Parameters","text":"<p>By default, when a linked agent is called, it receives the full user input as a single string. However, you can customize this behavior to create more sophisticated interactions by implementing custom <code>__call__</code> methods and using <code>Param</code> classes to define structured input parameters.</p>"},{"location":"agent-linking/#basic-custom-call","title":"Basic Custom call","text":"<p>Overriding the <code>__call__</code> method gives you complete control over how your linked agent processes input. This allows you to define specific parameters that the parent agent can pass:</p> <pre><code>class AnalysisAgent(Agent):\n    __system_message__ = \"I analyze data\"\n    __description__ = \"Performs statistical analysis on datasets\"\n\n    async def __call__(self, data: str, analysis_type: str = \"basic\") -&gt; str: ...\n\nclass ReportAgent(Agent):\n    __system_message__ = \"I generate reports\"\n    analyzer: AnalysisAgent\n\n# The LLM can now call the analyzer with specific parameters\nresponse = await report_agent(\"Create a detailed analysis report\")\n</code></pre> <p>With this setup, the parent agent's LLM can call the analysis agent with specific parameters like <code>analysis_type=\"advanced\"</code>, giving it precise control over the linked agent's behavior.</p>"},{"location":"agent-linking/#using-param-for-structured-input","title":"Using Param for Structured Input","text":"<p>For more complex scenarios with multiple parameters, validation, and documentation, use <code>Param</code> classes. These provide type safety and automatic schema generation:</p> <pre><code>from pyagentic import Param\n\nclass SearchParams(Param):\n    query: str\n    max_results: int = 10\n    include_metadata: bool = True\n\nclass SearchAgent(Agent):\n    __system_message__ = \"I search databases\"\n    __description__ = \"Searches databases with advanced filtering\"\n\n    async def __call__(self, params: SearchParams) -&gt; str: ...\n\nclass DataAgent(Agent):\n    __system_message__ = \"I manage data operations\"\n    searcher: SearchAgent\n\n# The LLM can now call the searcher with structured parameters\nresult = await data_agent(\"Find customer records for 'John Smith'\")\n</code></pre> <p>When using <code>Param</code> classes, PyAgentic automatically generates the proper OpenAI tool schema, complete with parameter types, defaults, and descriptions. This makes the linked agent's interface clear to the calling LLM and ensures type safety throughout the system.</p>"},{"location":"agent-linking/#best-practices","title":"Best Practices","text":""},{"location":"agent-linking/#clear-descriptions","title":"Clear Descriptions","text":"<p>Since linked agents appear as tools to the parent agent, their <code>__description__</code> attribute becomes crucial. This description is what the LLM uses to decide when and how to use the linked agent:</p> <pre><code>class DatabaseAgent(Agent):\n    __system_message__ = \"I query databases\"\n    __description__ = \"Retrieves and analyzes data from SQL databases\"\n</code></pre> <p>A well-written description should be specific enough to guide the LLM's decision-making while being concise. Think of it as the \"tool tooltip\" that helps the parent agent understand the linked agent's capabilities and appropriate use cases.</p>"},{"location":"agent-linking/#keep-agents-focused","title":"Keep Agents Focused","text":"<p>The single responsibility principle applies strongly to linked agents. Each agent should have a clear, focused purpose that makes it easy for other agents to understand when to use it:</p> <pre><code>class EmailAgent(Agent):\n    __description__ = \"Sends and manages emails\"\n\nclass CalendarAgent(Agent):\n    __description__ = \"Manages calendar events and scheduling\"\n\nclass AssistantAgent(Agent):\n    email: EmailAgent\n    calendar: CalendarAgent\n</code></pre> <p>Focused agents are easier to compose, test, and maintain. They also make the overall system behavior more predictable since each agent's role is clearly defined.</p>"},{"location":"getting-started/","title":"Getting Started with PyAgentic","text":"<p>PyAgentic is a declarative framework for building AI agents with support for multiple LLM providers including OpenAI, Anthropic, and others. This guide will walk you through building a research assistant agent step by step, introducing each core concept along the way.</p>"},{"location":"getting-started/#installation","title":"Installation","text":"<p>First, install PyAgentic:</p> <pre><code>pip install pyagentic-core\n</code></pre> <p>You'll also need an API key from your chosen LLM provider (OpenAI, Anthropic, etc.) for this tutorial.</p>"},{"location":"getting-started/#why-pyagentic","title":"Why PyAgentic?","text":"<p>Imagine you're a researcher who needs to organize papers, extract key insights, and generate summaries. You want an AI assistant that can:</p> <ul> <li>Remember what papers you've added to your collection</li> <li>Extract and summarize key findings from papers</li> <li>Answer questions about your research collection</li> <li>Maintain context across conversations</li> </ul> <p>This is exactly the kind of stateful, tool-equipped agent that PyAgentic makes easy to build.</p>"},{"location":"getting-started/#choosing-your-llm-provider","title":"Choosing Your LLM Provider","text":"<p>PyAgentic supports multiple LLM providers out of the box. You can configure your agent to use any supported provider:</p>"},{"location":"getting-started/#supported-providers","title":"Supported Providers","text":"<ul> <li>OpenAI: GPT-4, GPT-3.5, and other OpenAI models</li> <li>Anthropic: Claude models with full tool calling support</li> <li>Mock: For testing and development without API costs</li> </ul>"},{"location":"getting-started/#provider-configuration-methods","title":"Provider Configuration Methods","text":"<p>You can configure providers in two ways:</p> <p>Model String Format <pre><code>agent = MyAgent(\n    model=\"&lt;provider&gt;::&lt;model_name&gt;\",\n    api_key=\"your_api_key\"\n)\n\nopenai_agent = MyAgent(\n    model=\"openai::gpt-5\",\n    api_key=\"your_api_key\"\n)\n\nanthropic_agent = MyAgent(\n    model=\"anthropic::claude-opus-4-1-20250805\",\n    api_key=\"your_api_key\"\n)\n</code></pre></p> <p>Provider Instance <pre><code>from pyagentic.llm import OpenAIProvider, AnthropicProvider\n\n# OpenAI\nagent = MyAgent(\n    provider=OpenAIProvider(\n        model=\"gpt-5\",\n        api_key=\"your_openai_key\",\n        max_retries=10,\n        timeout=5\n    )\n)\n\n# Anthropic\nagent = MyAgent(\n    provider=AnthropicProvider(\n        model=\"claude-opus-4-1-20250805\",\n        api_key=\"your_anthropic_key\",\n        base_url=\"https://my-deployment.com/models\"\n    )\n)\n</code></pre></p> <p>The provider instance method gives you more control over client configuration, allowing you to pass additional parameters like <code>base_url</code>, <code>timeout</code>, <code>max_retries</code>, etc.</p>"},{"location":"getting-started/#step-1-your-first-agent","title":"Step 1: Your First Agent","text":"<p>Let's start by creating a simple research assistant agent:</p> <pre><code>from pyagentic import Agent\n\nclass ResearchAgent(Agent):\n    \"\"\"An AI assistant for managing and analyzing research papers.\"\"\"\n\n    __system_message__ = \"\"\"\n    You are a research assistant that helps organize and analyze academic papers.\n    You maintain a collection of research papers and can answer questions about them.\n    You are knowledgeable, precise, and helpful in academic contexts.\n    \"\"\"\n</code></pre> <p>This creates a basic conversational agent, but it can't do much beyond chat. Let's add some memory and capabilities.</p>"},{"location":"getting-started/#step-2-adding-context-with-contextitem","title":"Step 2: Adding Context with ContextItem","text":"<p>Real research assistants need to remember things! Let's add some persistent context to track the papers in our collection:</p> <pre><code>from pyagentic import Agent, ContextItem\nfrom typing import List, Dict\nfrom collections import defaultdict\n\nfrom arxiv import Result as Paper\n\nclass ResearchAgent(Agent):\n    \"\"\"An AI assistant for managing and analyzing research papers.\"\"\"\n\n    __system_message__ = \"\"\"\n    You are a research assistant that helps organize and analyze academic papers.\n    You have full access to the Arxiv\n\n    Available topics: {available_topics}\n\n    Use your tools to help users manage and analyze their research collection.\n    Feel free to use many tools at once\n    \"\"\"\n\n    __input_template__ = \"\"\"\n    Current Topic: {current_topic}\n\n    User Message: {user_message}\n    \"\"\"\n\n    papers: Dict[str, List[Paper]] = ContextItem(default_factory=lambda: defaultdict(list))\n    current_topic: str = ContextItem(default=\"General Research\")\n</code></pre> <p>Now our agent has memory! The <code>papers</code> list and <code>current_topic</code> string persist between conversations. Notice how we reference <code>{available_topics}</code> in the system message - we'll make that work next.</p>"},{"location":"getting-started/#step-3-adding-tools-for-actions","title":"Step 3: Adding Tools for Actions","text":"<p>Let's give our agent the ability to actually search and papers by adding tools:</p> <pre><code>@tool(\"Search the Arxiv for relevant papers\")\ndef search(\n    self,\n    terms: list[str] = ParamInfo(required=True, description=\"Terms you think are relevant to the user's query. Be creative\")\n) -&gt; str:\n    print(f\"Searching terms: {terms}\")\n    found = []\n    for term in terms:\n        results = search_arxiv(term)\n        found.extend(results)\n    return json.dumps(found, indent=2)\n\n@tool(\"Add a new paper to the research collection\")\ndef add_paper(\n    self,\n    paper_id: str = ParamInfo(required=True, description=\"ID of the paper from search results\"),\n    topic: str = ParamInfo(\n        required=False,\n        description=\"Research topic/area\",\n    )\n) -&gt; str:\n    print(f\"Adding {paper_id} to {topic}\")\n    paper = get_paper(paper_id)\n    self.context.papers[topic].append(paper)\n    return f\"Added paper '{paper.title}' by {paper.authors} to your collection under topic '{topic}'.\"\n</code></pre> <p>Now our agent can perform actions! The <code>@tool</code> decorator exposes methods to the AI, and <code>ParamInfo</code> helps define parameter requirements and descriptions.</p> <p>A problem may arise here, asking the LLM to generate raw paper ids may lead to hallucination...</p>"},{"location":"getting-started/#step-4-computed-context-for-dynamic-values","title":"Step 4: Computed Context for Dynamic Values","text":"<p>This can be solved by passing over values to the param, ensuring the the LLM will only pick from that list.</p> <p>To do so, we need to combine the use of a <code>computed_context</code> and a <code>ContextRef</code></p> <p><code>computed_context</code>s work a lot like python <code>property</code>s, each time it is accessed, it is recalculated. We are going to add two here:     - available_topics     - paper_ids</p> <p>Lastly, we can hook up these new context items using a <code>ContextRef</code>, ensuring that the string passed to the ref perfectly matches that of the context item name.</p> <pre><code>@computed_context\ndef available_topics(self) -&gt; List[str]:\n    \"\"\"Extract unique topics from paper summaries and titles\"\"\"\n\n    return list(self.papers.keys())\n\n@computed_context\ndef paper_ids(self) -&gt; List[str]:\n    \"\"\"Get list of all paper titles for reference\"\"\"\n    return [paper.get_short_id() for paper in self.papers[self.current_topic]]\n\n@tool(\"Add a new paper to the research collection\")\ndef add_paper(\n    self,\n    paper_id: str = ParamInfo(\n        required=True, \n        description=\"ID of the paper from search results\",\n        values=ContextRef(\"paper_ids\")\n    ),\n    topic: str = ParamInfo(\n        required=False,\n        description=\"Research topic/area\",\n        values=ContextRef(\"available_topics\")  # Dynamic options!\n    )\n) -&gt; str:\n    print(f\"Adding {paper_id} to {topic}\")\n    paper = get_paper(paper_id)\n    self.context.papers[topic].append(paper)\n    return f\"Added paper '{paper.title}' by {paper.authors} to your collection under topic '{topic}'.\"\n</code></pre> <p>This will ensure that the LLM choices specific values when calling the tool.</p>"},{"location":"getting-started/#step-5-advanced-tool-parameters-with-contextref","title":"Step 5: Advanced Tool Parameters with ContextRef","text":"<p>Let's put it all together while adding a couple more features to make it more complete, like:     - Setting the focus     - Read a paper</p> <pre><code>from pyagentic import Agent, ContextItem, tool, ParamInfo, computed_context, ContextRef\nfrom typing import List, Dict\nfrom collections import defaultdict\n\nfrom utils import read_paper, get_paper, search_arxiv\nfrom arxiv import Result as Paper\n\nclass ResearchAgent(Agent):\n    \"\"\"An AI assistant for managing and analyzing research papers.\"\"\"\n\n    __system_message__ = \"\"\"\n    You are a research assistant that helps organize and analyze academic papers.\n    You have full access to the Arxiv\n\n    Available topics: {available_topics}\n\n    Use your tools to help users manage and analyze their research collection.\n    Feel free to use many tools at once\n    \"\"\"\n\n    __input_template__ = \"\"\"\n    Current Topic: {current_topic}\n\n    User Message: {user_message}\n    \"\"\"\n\n    papers: Dict[str, List[Paper]] = ContextItem(default_factory=lambda: defaultdict(list))\n    current_topic: str = ContextItem(default=\"General Research\")\n\n\n    @computed_context\n    def available_topics(self) -&gt; List[str]:\n        \"\"\"Extract unique topics from paper summaries and titles\"\"\"\n\n        return list(self.papers.keys())\n\n    @computed_context\n    def paper_titles(self) -&gt; List[str]:\n        \"\"\"Get list of all paper titles for reference\"\"\"\n        return [paper.title for paper in self.papers[self.current_topic]]\n\n    @computed_context\n    def paper_ids(self) -&gt; List[str]:\n        \"\"\"Get list of all paper titles for reference\"\"\"\n        return [paper.get_short_id() for paper in self.papers[self.current_topic]]\n\n\n    @tool(\"Search the Arxiv for relevant papers\")\n    def search(\n        self,\n        terms: list[str] = ParamInfo(required=True, description=\"Terms you think are relevant to the user's query. Be creative\")\n    ) -&gt; str:\n        print(f\"Searching terms: {terms}\")\n        found = []\n        for term in terms:\n            results = search_arxiv(term)\n            found.extend(results)\n        return json.dumps(found, indent=2)\n\n    @tool(\"Add a new paper to the research collection\")\n    def add_paper(\n        self,\n        paper_id: str = ParamInfo(\n            required=True, \n            description=\"ID of the paper from search results\",\n            values=ContextRef(\"paper_ids\")\n        ),\n        topic: str = ParamInfo(\n            required=False,\n            description=\"Research topic/area\",\n            values=ContextRef(\"available_topics\")  # Dynamic options!\n        )\n    ) -&gt; str:\n        print(f\"Adding {paper_id} to {topic}\")\n        paper = get_paper(paper_id)\n        self.context.papers[topic].append(paper)\n        return f\"Added paper '{paper.title}' by {paper.authors} to your collection under topic '{topic}'.\"\n\n    @tool(\"Read the entire content of a paper\")\n    def read_paper(\n        self,\n        title: str = ParamInfo(\n            required=True,\n            description=\"Exact title of the paper to get details for\",\n            values=ContextRef(\"paper_titles\")  # Only allow existing paper titles!\n        )\n    ) -&gt; str:\n        print(f\"Reading {title}\")\n        current_topic = self.context.current_topic\n        for paper in self.context.papers[current_topic]:\n            if title in paper.title:\n                return read_paper(paper)\n        return f\"Paper '{title}' not found in collection.\"\n\n    @tool(\"Update research focus topic, call this whenever you feel the subject has changed. Always call this before other tools if the subject has changed\")\n    def set_focus_topic(\n        self,\n        topic: str = ParamInfo(\n            required=True,\n            description=\"New research focus topic\",\n        )\n    ) -&gt; str:\n        print(f\"New focus: {topic}\")\n        self.context.current_topic = topic\n        return f\"Research focus updated to: {topic}\"\n</code></pre> <p>Now our tools are much smarter! The <code>ContextRef</code> creates dynamic constraints: - When adding papers, the <code>topic</code> parameter will only suggest topics that already exist in our collection - When getting paper details, the agent can only choose from actual paper titles - The available options update automatically as we add more papers</p>"},{"location":"getting-started/#step-6-lets-run-it","title":"Step 6: Let's run it!","text":"<p>First, we have to create our agent.</p> <pre><code># Option 1: Using model string format\nagent = ResearchAgent(\n    model=\"openai::gpt-4o\",\n    api_key=API_KEY\n)\n\n# Option 2: Using a provider instance\nfrom pyagentic.llm import OpenAIProvider\n\nagent = ResearchAgent(\n    provider=OpenAIProvider(\n        model=\"gpt-4o\",\n        api_key=API_KEY\n    )\n)\n</code></pre> <p>Now lets run a couple messages through to see if it is working?</p> Set FocusFind PapersAdd PapersAnalyze <pre><code>await agent('''\nIm trying to find a link between ai usage and climate change\n''')\n</code></pre> <pre><code>New focus: AI and Climate Change\n</code></pre> <p>Let's explore research papers linking AI usage and climate change. I'll look for recent studies on this topic. Please hold on for a moment.Here are some research areas and findings regarding the connection between AI usage and climate change:</p> <ol> <li> <p>AI in Climate Modeling: AI helps improve climate models by enhancing predictions of weather patterns, temperature changes, and extreme events like hurricanes. Machine learning algorithms can analyze vast datasets to improve climate forecasts.</p> </li> <li> <p>Monitoring and Reducing Emissions: AI aids in monitoring industrial emissions and optimizing energy consumption in various sectors, potentially reducing overall carbon footprints. Smart grids and AI-enhanced energy management systems help in efficient resource usage.</p> </li> <li> <p>Environmental Data Analysis:</p> </li> <li> <p>AI processes environmental data from satellites and sensors to monitor deforestation, glacial melting, and other climate-related changes. This helps in providing timely insights for environmental protection efforts.</p> </li> <li> <p>Sustainable Practices: Machine learning supports the development of sustainable agricultural practices by analyzing crop yield data and predicting suitable planting strategies, reducing waste and resource usage.</p> </li> <li> <p>AI's Carbon Footprint: Training AI models is energy-intensive, contributing to carbon emissions. Research is exploring more efficient algorithms and hardware to mitigate these effects.</p> </li> </ol> <p>Would you like to dive deeper into any specific area or look for more detailed research papers?</p> <pre><code>response = await agent('''\nYa! Find some papers around AI's Carbon Footprint\n''')\n</code></pre> <pre><code>Searching terms: ['AI carbon footprint', 'energy consumption AI', 'AI environmental impact']\n</code></pre> <p>Here are some papers related to AI's carbon footprint:</p> <ol> <li> <p>Integrating AI's Carbon Footprint into Risk Management Frameworks: Strategies and Tools for Sustainable Compliance in Banking Sector Author: Nataliya Tkachenko This paper explores integrating AI\u2019s carbon footprint into risk management in the banking sector, highlighting advancements like energy-efficient models and green cloud computing. Read more</p> </li> <li> <p>Carbon-Aware End-to-End Data Movement Authors: Jacob Goldverg, Hasibul Jamil, Elvis Rodriguez, Tevfik Kosar Investigates carbon emissions from data movement in cloud computing and proposes optimization strategies for reducing energy consumption. Read more</p> </li> <li> <p>Making AI Less \"Thirsty\": Uncovering and Addressing the Secret Water Footprint of AI Models Authors: Pengfei Li, Jianyi Yang, Mohammad A. Islam, Shaolei Ren Tackles AI's overlooked water consumption, highlighting the necessity to address both water and carbon footprints for sustainable AI. Read more</p> </li> <li> <p>Towards Environmentally Equitable AI via Geographical Load Balancing Authors: Pengfei Li, Jianyi Yang, Adam Wierman, Shaolei Ren Proposes equity-aware geographical load balancing to address regional disparities in AI's environmental impact. Read more</p> </li> <li> <p>CAFE: Carbon-Aware Federated Learning in Geographically Distributed Data Centers Authors: Jieming Bian, Lei Wang, Shaolei Ren, Jie Xu Introduces a framework for carbon-aware federated learning to optimize training across distributed data centers while considering carbon intensity. Read more</p> </li> </ol> <p>If you want to explore any specific paper in detail, let me know!</p> <pre><code>response = await agent('''\nAdd the papers that you think are the most relevant to linking AI and carbon\n''')\n</code></pre> <pre><code>Adding 2410.01818v1 to AI and Climate Change\nAdding 2406.09650v1 to AI and Climate Change\nAdding 2304.03271v5 to AI and Climate Change\nAdding 2407.05176v1 to AI and Climate Change\n</code></pre> <p>I've added the most relevant papers connecting AI and carbon emissions to your collection. If you need further assistance or wish to explore more papers, feel free to ask!</p> <pre><code>response = await agent('''\nAnalyze these papers and tell me what you learned with citiations\n''')\n</code></pre> <pre><code>Reading Integrating AI's Carbon Footprint into Risk Management Frameworks: Strategies and Tools for Sustainable Compliance in Banking Sector\nReading Carbon-Aware End-to-End Data Movement\nReading Making AI Less \"Thirsty\": Uncovering and Addressing the Secret Water Footprint of AI Models\nReading Towards Socially and Environmentally Responsible AI\n</code></pre> <p>Here's a summary and analysis of the selected papers linking AI and carbon:</p> <ol> <li>Integrating AI's Carbon Footprint into Risk Management Frameworks (Tkachenko, 2024)</li> </ol> <p>Overview: This paper discusses how AI's carbon footprint can be integrated into the banking sector's risk management frameworks (RMFs). It highlights the regulatory requirements driving financial institutions to consider environmental impacts within AI governance. Key Insights: AI models in banking require significant energy, contributing to carbon emissions. Efficient AI models and green cloud computing practices are recommended strategies to mitigate these impacts. Importance: Integrating AI's carbon footprint into RMFs can help banks comply with sustainability regulations and demonstrate environmental responsibility.</p> <ol> <li>Carbon-Aware End-to-End Data Movement (Goldverg et al., 2024)</li> </ol> <p>Overview: This study focuses on measuring and optimizing the carbon footprint of data movement across networks, a significant contributor to AI-related carbon emissions. Key Insights: The paper introduces carbon-aware scheduling strategies that optimize data transfer times and routes to reduce carbon emissions. It highlights the need for detailed monitoring of network paths and end systems. Importance: Addressing the carbon footprint in data movement is crucial for reducing the total carbon emissions associated with AI workloads.</p> <ol> <li>Making AI Less \"Thirsty\" (Li et al., 2025)</li> </ol> <p>Overview: This paper uncovers the water footprint of AI models, emphasizing that AI's environmental impact extends beyond carbon emissions to significant water consumption, particularly in data center cooling. Key Insights: The water consumption associated with AI could become a major ecological challenge. The study presents methodologies to estimate and reduce AI's water footprint. Importance: Highlighting AI's water usage as a crucial aspect of its environmental footprint encourages more holistic sustainability strategies.</p> <ol> <li>Towards Socially and Environmentally Responsible AI (Li et al., 2024)</li> </ol> <p>Overview: The paper proposes equitable geographical load balancing (GLB) to address AI's social and environmental inequalities, ensuring fair distribution of AI's benefits and burdens across regions. Key Insights: The disparities in AI's resource allocation can lead to environmental and social inequity. Implementing equity-aware GLB can balance AI's negative impacts more fairly across regions. Importance: By promoting social and environmental equity, this approach aims to foster responsible AI deployment.</p> <p>If you want further analysis or details on specific papers, feel free to let me know!</p>"},{"location":"getting-started/#conclusion","title":"Conclusion","text":"<p>The research underscores the multifaceted environmental impacts of AI, including carbon and water footprints, and stresses the importance of equitable resource distribution. The integration of these concerns into frameworks such as RMFs in banking and carbon-aware scheduling in data movement are vital steps towards sustainable AI practices.</p>"},{"location":"getting-started/#what-makes-this-powerful","title":"What Makes This Powerful","text":"<p>Our research assistant demonstrates all of PyAgentic's key strengths:</p> <ol> <li>Declarative Design: We define what the agent should do, not how</li> <li>Persistent Context: The agent remembers papers across conversations</li> <li>Dynamic Intelligence: Tools adapt their constraints based on current data  </li> <li>Type Safety: All parameters are properly typed and validated</li> <li>Natural Evolution: Easy to add new capabilities without breaking existing functionality</li> </ol>"},{"location":"getting-started/#controlling-tool-usage-with-max_call_depth","title":"Controlling Tool Usage with max_call_depth","text":"<p>By default, PyAgentic agents can only call tools once per conversation turn, then must provide a final response. This prevents endless tool-calling loops but might limit complex workflows. You can control this behavior with the <code>max_call_depth</code> parameter:</p> <pre><code># Allow multiple rounds of tool calling\nagent = ResearchAgent(\n    model=\"openai::gpt-4o\",\n    api_key=API_KEY,\n    max_call_depth=3  # Allow up to 3 rounds of tool calls\n)\n</code></pre>"},{"location":"getting-started/#how-max_call_depth-works","title":"How max_call_depth Works","text":"<ul> <li>Depth 0: Agent can call tools, then must respond</li> <li>Depth 1 (default): After tools execute, agent can call more tools or respond  </li> <li>Depth 2+: Agent can continue calling tools in multiple rounds</li> </ul> <p>Each \"depth\" represents a full round of tool calling. Within each round, the agent can make multiple parallel tool calls, but after each round completes, it decides whether to call more tools or give a final answer.</p>"},{"location":"getting-started/#when-to-increase-max_call_depth","title":"When to Increase max_call_depth","text":"<p>Use higher depths (2-4) when your agent needs to: - Search for information, then analyze what it found - Read multiple files and synthesize information - Perform multi-step research or analysis - Chain tool outputs together</p> <p>Keep default (1) when your agent: - Has simple, single-purpose tools - Should respond quickly without complex workflows - Might get stuck in tool-calling loops</p>"},{"location":"getting-started/#example-research-agent-with-multiple-depths","title":"Example: Research Agent with Multiple Depths","text":"<pre><code>With max_call_depth=1 (default):\nUser: \"Research AI and climate change\" \n  \u2192 Agent calls search() \u2192 Responds with results\n\nWith max_call_depth=3:\nUser: \"Research AI and climate change\"\n  \u2192 Depth 0: Agent calls search()  \n  \u2192 Depth 1: Agent calls add_paper() for multiple papers\n  \u2192 Depth 2: Agent calls read_paper() to analyze content\n  \u2192 Final response with comprehensive analysis\n</code></pre> <p>This allows your agent to perform sophisticated multi-step workflows while preventing infinite loops.</p>"},{"location":"getting-started/#key-concepts-summary","title":"Key Concepts Summary","text":"<ul> <li><code>Agent</code>: Base class that handles LLM provider integration and orchestration</li> <li><code>ContextItem</code>: Persistent state that survives between conversations</li> <li><code>@tool</code>: Decorator that exposes methods as callable functions to the AI</li> <li><code>ParamInfo</code>: Metadata for tool parameters (descriptions, requirements, defaults)  </li> <li><code>@computed_context</code>: Dynamic properties that recalculate on each access</li> <li><code>ContextRef</code>: Links tool parameters to live context data for smart constraints</li> <li><code>max_call_depth</code>: Controls how many rounds of tool calling are allowed per turn</li> </ul>"},{"location":"getting-started/#next-steps","title":"Next Steps","text":"<p>Now you're ready to build sophisticated AI agents! Try:</p> <ul> <li>Adding more complex tools (file I/O, API calls, data analysis)</li> <li>Creating multi-agent systems that collaborate</li> <li>Building domain-specific agents for your use cases</li> <li>Exploring advanced context patterns and validation</li> </ul> <p>The declarative nature of PyAgentic makes it easy to iterate and extend your agents as your needs grow.</p>"},{"location":"inheritance/","title":"Agent Inheritance","text":"<p>PyAgentic supports standard Python inheritance, allowing you to build agent hierarchies that share tools, context, and functionality. You can also use extensions to add cross-cutting capabilities to multiple agents without deep inheritance chains.</p>"},{"location":"inheritance/#how-inheritance-works","title":"How Inheritance Works","text":"<p>Agent inheritance follows Python's standard rules with some PyAgentic-specific behaviors. When you inherit from an agent, you get all its tools, context items, and linked agents. However, each agent must define its own system message to maintain clear identity and purpose.</p> <p>PyAgentic builds the complete agent schema at class definition time, combining inherited elements with new ones to create a fully-typed, predictable agent interface.</p>"},{"location":"inheritance/#inheritance-rules","title":"Inheritance Rules","text":"<p>PyAgentic follows specific rules about what gets inherited and what must be redefined:</p>"},{"location":"inheritance/#what-gets-inherited","title":"What Gets Inherited \u2705","text":"<ul> <li>Tools - All <code>@tool</code> methods are inherited and can be overridden</li> <li>Context Items - <code>ContextItem</code> fields inherit with their defaults and types</li> <li>Linked Agents - Agent references are inherited, child classes can add more</li> <li>Computed Context - Dynamic context methods are inherited and overridable</li> </ul>"},{"location":"inheritance/#what-must-be-redefined","title":"What Must Be Redefined \u274c","text":"<ul> <li>System Messages - Each agent must define its own <code>__system_message__</code> to maintain clear identity</li> <li>Input Templates - <code>__input_template__</code> is not inherited, allowing agent-specific formatting</li> </ul> <p>This design ensures that while agents can share functionality, each maintains its own distinct purpose and behavior.</p>"},{"location":"inheritance/#basic-inheritance","title":"Basic Inheritance","text":"<p>Extend agents using normal Python inheritance to build specialized capabilities on top of base functionality:</p> <pre><code>class BaseAssistantAgent(Agent):\n    __system_message__ = \"I am a helpful AI assistant\"\n\n    user_name: str = ContextItem(default=\"User\")\n    session_id: str = ContextItem(default=\"\")\n    conversation_context: str = ContextItem(default=\"\")\n\n    @tool(\"Get current timestamp\")\n    def get_timestamp(self) -&gt; str: ...\n\n    @tool(\"Read a file in the current directory\")\n    def count_words(self, file_name: str) -&gt; int: ...\n\n    @tool(\"Update conversation context\")\n    def update_context(self, new_context: str) -&gt; str: ...\n\nclass CodeAssistantAgent(BaseAssistantAgent):\n    __system_message__ = \"I help with programming tasks and code review\"\n\n    # Inherit user_name, session_id, conversation_context, and basic tools\n    # Add coding-specific context\n    preferred_language: str = ContextItem(default=\"python\")\n    current_project: str = ContextItem(default=\"\")\n    debug_mode: bool = ContextItem(default=False)\n\n    @tool(\"Format code snippet\")\n    def format_code(self, code: str, language: str = None) -&gt; str: ...\n\n    @tool(\"Generate code documentation\")\n    def document_code(self, code: str) -&gt; str: ...\n</code></pre> <p>The <code>CodeAssistantAgent</code> inherits all the basic functionality from <code>BaseAssistantAgent</code> (user tracking, session management, conversation context) while adding its own specialized tools for code formatting and documentation. This creates a clean hierarchy where common assistant behaviors are shared but specific domains add their own capabilities.</p> <p>Inheritance also works with tool overriding to enhance parent functionality:</p> <pre><code>class AdvancedCodeAssistantAgent(CodeAssistantAgent):\n    __system_message__ = \"I provide advanced programming assistance with security analysis\"\n\n    # Override parent tool with enhanced functionality\n    @tool(\"Format and validate code snippet\")\n    def format_code(self, code: str, language: str = None, formatting_style: str = None) -&gt; str: ...\n</code></pre>"},{"location":"inheritance/#agent-extensions","title":"Agent Extensions","text":"<p>Extensions allow you to add cross-cutting functionality to multiple agents without creating deep inheritance hierarchies. They're perfect for capabilities like logging, authentication, or caching that many different agents might need.</p>"},{"location":"inheritance/#creating-extensions","title":"Creating Extensions","text":"<p>Extensions inherit from <code>AgentExtension</code> and can include tools, context items, and computed context:</p> <pre><code>class FileOperationsExtension(AgentExtension):\n    base_directory: str = ContextItem(default=\"./workspace\")\n\n    @tool(\"Read file contents\")\n    def read_file(self, filename: str) -&gt; str: ...\n\n    @tool(\"Write content to file\")\n    def write_file(self, filename: str, content: str) -&gt; str: ...\n\nclass WebSearchExtension(AgentExtension):\n    max_results: int = ContextItem(default=5)\n\n    @tool(\"Search the web for information\")\n    def web_search(self, query: str) -&gt; str: ...\n\n    @tool(\"Get webpage content\")\n    def get_webpage(self, url: str) -&gt; str: ...\n</code></pre>"},{"location":"inheritance/#using-extensions","title":"Using Extensions","text":"<p>Simply include extensions in your agent's inheritance list:</p> <pre><code>class ResearchAgent(Agent, FileOperationsExtension, WebSearchExtension):\n    __system_message__ = \"I help with research by searching the web and managing files\"\n\n    research_topic: str = ContextItem(default=\"\")\n\n    @tool(\"Conduct comprehensive research\")\n    def research_topic(self, topic: str) -&gt; str: ...\n</code></pre> <p>The agent automatically gets all tools and context from both extensions, creating a powerful composition pattern.</p>"},{"location":"inheritance/#method-resolution-order-mro","title":"Method Resolution Order (MRO)","text":"<p>When using multiple extensions or inheritance, Python's Method Resolution Order (MRO) determines which implementation is used when there are conflicts. PyAgentic follows Python's C3 linearization:</p> <pre><code>class MemoryExtension(AgentExtension):\n    @tool(\"Remember information\")\n    def remember(self, info: str) -&gt; str: ...\n\nclass ConversationExtension(AgentExtension):\n    @tool(\"Remember information\")\n    def remember(self, info: str) -&gt; str: ...\n\nclass ChatbotAgent(Agent, MemoryExtension, ConversationExtension):\n    __system_message__ = \"I am a conversational AI\"\n\n# MRO: ChatbotAgent -&gt; MemoryExtension -&gt; ConversationExtension -&gt; Agent\n# The MemoryExtension.remember() method will be used\n</code></pre> <p>You can check the MRO with <code>ChatbotAgent.__mro__</code> to understand the resolution order. Extensions listed first in the inheritance list take precedence.</p>"},{"location":"observability/","title":"Observability","text":"<p>PyAgentic provides built-in observability through tracing, allowing you to monitor and understand how your agents work. This guide covers the basics of tracing and how to set up different tracers.</p>"},{"location":"observability/#what-are-traces","title":"What are Traces?","text":"<p>Traces help you observe the execution flow of your agents by recording what happens during agent runs. A trace represents a complete execution path, made up of individual spans that capture specific operations.</p> <p>Think of a trace like a detailed log of everything your agent does: - When it starts thinking about a problem - When it calls tools or external services - When it makes inference calls to language models - When it finishes a task</p>"},{"location":"observability/#span-types","title":"Span Types","text":"<p>PyAgentic supports four types of spans to categorize different operations:</p> <ul> <li>Agent spans (<code>SpanKind.AGENT</code>): Track high-level agent operations and workflows</li> <li>Tool spans (<code>SpanKind.TOOL</code>): Monitor tool executions and external API calls</li> <li>Inference spans (<code>SpanKind.INFERENCE</code>): Capture language model interactions and generations</li> <li>Step spans (<code>SpanKind.STEP</code>): Record individual steps within larger operations</li> </ul> <p>Each span captures timing information, attributes, and can include events for detailed logging.</p>"},{"location":"observability/#available-tracers","title":"Available Tracers","text":"<p>PyAgentic includes two built-in tracers:</p>"},{"location":"observability/#basictracer","title":"BasicTracer","text":"<p>An in-memory tracer that stores traces locally in Python dictionaries. Perfect for development, testing, and simple use cases.</p> <p>The BasicTracer is the simplest way to get started with tracing. It stores all trace data in memory and provides export functionality.</p> <pre><code>from your_agent_module import YourAgent\n\n\n# Create an agent - The BasicTracer is the default tracer of any declared agent\nagent = YourAgent(\n    model=\"openai::gpt-4o\",\n    api_key=MY_API_KEY,\n)\n\n\n# Run your agent\nresult = await agent(\"Your task here\")\n</code></pre>"},{"location":"observability/#basictracer-features","title":"BasicTracer Features","text":"<ul> <li>In-memory storage: All data stored locally, no external dependencies</li> <li>Export functionality: Get trace data as JSON for analysis or debugging</li> <li>Thread-safe: Safe to use with concurrent operations</li> <li>Reset option: Clear traces after export to manage memory usage</li> </ul> <pre><code># Export a specific trace and clear it from memory\ntrace_data = tracer.export_trace(trace_id, reset=True)\n\n# Clear all stored traces\ntracer.clear()\n</code></pre>"},{"location":"observability/#langfusetracer","title":"LangfuseTracer","text":"<p>Integrates with Langfuse for production-grade observability with advanced analytics, dashboards, and collaboration features.</p> <p>The LangfuseTracer provides enterprise-grade observability by forwarding traces to Langfuse.</p>"},{"location":"observability/#setup","title":"Setup","text":"<p>First, install the Langfuse SDK:</p> <pre><code>pip install langfuse\n</code></pre> <p>Configure your Langfuse connection using environment variables:</p> <pre><code>export LANGFUSE_SECRET_KEY=\"your-secret-key\"\nexport LANGFUSE_PUBLIC_KEY=\"your-public-key\"\nexport LANGFUSE_HOST=\"https://cloud.langfuse.com\"  # or your self-hosted instance\n</code></pre>"},{"location":"observability/#usage","title":"Usage","text":"<pre><code>from pyagentic.tracing import LangfuseTracer\nfrom your_agent_module import YourAgent\n\n# Create an agent with the tracer\nagent = YourAgent(\n    model=\"openai::gpt-4o\",\n    api_key=MY_API_KEY,\n    tracer=LangfuseTracer()\n)\n\n# Run your agent - traces will be sent to Langfuse\nresult = await agent(\"Your task here\")\n</code></pre>"},{"location":"observability/#langfusetracer-features","title":"LangfuseTracer Features","text":"<ul> <li>Real-time streaming: Traces sent to Langfuse as they happen</li> <li>Rich UI: View traces in the Langfuse dashboard with advanced filtering and analytics</li> <li>Cost tracking: Automatic LLM usage and cost monitoring</li> <li>Collaboration: Share traces with team members</li> <li>Production-ready: Built for high-volume production workloads</li> </ul>"},{"location":"observability/#choosing-a-tracer","title":"Choosing a Tracer","text":"<p>Use BasicTracer when: - Developing and testing agents locally - Simple debugging scenarios - No external dependencies desired - Working with sensitive data that must stay local</p> <p>Use LangfuseTracer when: - Running agents in production - Need advanced analytics and monitoring - Want to share traces with team members - Require cost tracking and optimization insights - Building user-facing applications</p>"},{"location":"responses/","title":"Agent Responses","text":"<p>PyAgentic agents return structured response objects that contain both the natural language output and detailed information about what happened during execution. This makes it easy to build applications that need both human-readable responses and programmatic access to execution details.</p>"},{"location":"responses/#response-structure","title":"Response Structure","text":"<p>Every agent response is a Pydantic model with a predictable structure:</p> <ul> <li><code>final_output: str</code> - The natural language response from the LLM</li> <li><code>tool_responses: List[ToolResponse]</code> - Details of any tools called (if agent has tools)</li> <li><code>agent_responses: List[AgentResponse]</code> - Responses from linked agents (if agent has linked agents)</li> </ul> <p>The response model is predetermined when the agent class is defined. Each agent automatically gets its own response class that knows exactly what tools and linked agents it can use. This means you get full type safety and IDE autocompletion before you ever run the agent.</p>"},{"location":"responses/#basic-response","title":"Basic Response","text":"<p>Every agent response includes a <code>final_output</code> field containing the LLM's natural language response:</p> <pre><code>response = await agent(\"Hello\")\nresponse.final_output  # \"Hi there! How can I help?\"\n</code></pre> <p>Since responses are Pydantic models, you can serialize them to JSON, validate them, and integrate them seamlessly with FastAPI or other frameworks.</p>"},{"location":"responses/#tool-responses","title":"Tool Responses","text":"<p>When agents use tools, the response automatically includes structured information about each tool call. All tool parameters become accessible as typed fields on the response:</p> <pre><code>class EmailAgent(Agent):\n    @tool(\"Send email\")\n    def send_email(self, to: str, urgent: bool = False) -&gt; str: ...\n\nresponse = await agent(\"Send urgent email to john about moving to our next apartment\")\n</code></pre> <pre><code>{\n  \"final_output\": \"I've sent the email to John. Let me know if there's anything else you need!\",\n  \"tool_responses\": [\n    {\n      \"raw_kwargs\": \"{\\\"to\\\":\\\"john@example.com\\\",\\\"message\\\":\\\"Subject: Moving Forward with the Next Apartment\\\\n\\\\nHi John,\\\\n\\\\nI hope this message finds you well. I wanted to discuss our plans for moving to the next apartment. Please let me know when would be a good time for us to chat or meet to go over the specifics.\\\\n\\\\nLooking forward to hearing from you soon.\\\\n\\\\nBest,\\\\n[Your Name]\\\",\\\"urgent\\\":false}\",\n      \"call_depth\": 0,\n      \"output\": \"Email sent\",\n      \"to\": \"john@example.com\",\n      \"message\": \"Subject: Moving Forward with the Next Apartment\\n\\nHi John,\\n\\nI hope this message finds you well. I wanted to discuss our plans for moving to the next apartment. Please let me know when would be a good time for us to chat or meet to go over the specifics.\\n\\nLooking forward to hearing from you soon.\\n\\nBest,\\n[Your Name]\",\n      \"urgent\": false\n    }\n  ]\n}\n</code></pre> <p>This gives you both the conversational response and programmatic access to exactly what the agent did.</p>"},{"location":"responses/#multiple-tools","title":"Multiple Tools","text":"<p>PyAgentic automatically generates response schemas that can handle any combination of tools your agent might use. The response type is created at class definition time and includes proper typing for all possible tool combinations:</p> <pre><code>class CustomerAgent(Agent):\n    @tool(\"Get customer\")\n    def get_customer(self, email: str): ...\n\n    @tool(\"Update status\") \n    def update_status(self, id: int, status: str): ...\n\n# Response automatically includes fields for whichever tools were called\n</code></pre> <p>You can access any tool's parameters through the <code>tool_responses</code> list, with full type safety and IDE autocompletion.</p>"},{"location":"responses/#linked-agents","title":"Linked Agents","text":"<p>When agents call other agents, their complete responses are nested within the parent response. This creates a tree structure that captures the full execution flow:</p> <pre><code>class ReportAgent(Agent):\n    database: DatabaseAgent = AgentLink()\n\n    @tool(\"Create chart\")\n    def make_chart(self, type: str): ...\n\nresponse = await agent(\"Create sales chart\")\nresponse.final_output                    # Main agent response\nresponse.tool_responses[0].type          # \"sales\"\nresponse.agent_responses[0].final_output # Database agent response\n</code></pre> <p>This nested structure lets you trace exactly what each agent did and access the results of any sub-agent calls. The parent agent's response includes both its own tool calls and the complete responses from any linked agents it used.</p>"},{"location":"structured-output/","title":"Structured Outputs","text":"<p>PyAgentic can automatically structure the final output of an agent into a Pydantic model. This is useful when you need the agent's response to follow a specific schema, making it easy to validate and use in downstream applications.</p>"},{"location":"structured-output/#defining-a-response-model","title":"Defining a Response Model","text":"<p>To specify a structured output, define a Pydantic model and assign it to the <code>__response_format__</code> attribute of your agent.</p> <pre><code>from pyagentic import Agent, tool\nfrom pydantic import BaseModel\n\nclass UserInfo(BaseModel):\n    name: str\n    age: int\n    desc: str\n    city: str\n    state: str\n\nclass UserParsingAgent(Agent):\n    __system_message__ = \"You are an AI that is an expert at parsing user information from any text\"\n    __response_format__ = UserInfo\n\n    @tool(\"Returns the city and state of a given zipcode\")\n    def zipcode_lookup(self, zipcode: str) -&gt; str:\n        ...\n</code></pre> <p>When you run this agent, the <code>final_output</code> of the response will be an instance of the <code>UserInfo</code> model, rather than a string.</p> <pre><code>await agent(\"Im John, im 28 and my postal code is 10012\")\n</code></pre> <pre><code>{\n  \"final_output\": {\n    \"name\": \"John\",\n    \"age\": 28,\n    \"desc\": \"User is John, aged 28, from NYC.\",\n    \"city\": \"NYC\",\n    \"state\": \"New York\"\n  },\n  \"tool_responses\": [\n    {\n      \"raw_kwargs\": \"{\\\"zipcode\\\":\\\"10012\\\"}\",\n      \"call_depth\": 0,\n      \"output\": \"NYC, New York\",\n      \"zipcode\": \"10012\"\n    }\n  ]\n}\n</code></pre>"},{"location":"structured-output/#how-it-works","title":"How it Works","text":"<p>Under the hood, PyAgentic uses the <code>parse</code> capability with a given <code>__response_format__</code>, this takes advantage of the LLMs structured output feature (if supported). Pyagentic also automatically updates its own <code>__response_model__</code> to ensure that the agent's output is always expected.</p> <pre><code>{\n    \"$defs\": {\n        \"ToolResponse_get_user_\": {\n            \"properties\": {\n                \"raw_kwargs\": {\n                    \"title\": \"Raw Kwargs\",\n                    \"type\": \"string\"\n                },\n                \"call_depth\": {\n                    \"title\": \"Call Depth\",\n                    \"type\": \"integer\"\n                },\n                \"output\": {\n                    \"title\": \"Output\"\n                },\n                \"user_id\": {\n                    \"default\": null,\n                    \"title\": \"User Id\",\n                    \"type\": \"string\"\n                }\n            },\n            \"required\": [\n                \"raw_kwargs\",\n                \"call_depth\",\n                \"output\"\n            ],\n            \"title\": \"ToolResponse[get_user]\",\n            \"type\": \"object\"\n        },\n        \"UserInfo\": {\n            \"properties\": {\n                \"name\": {\n                    \"title\": \"Name\",\n                    \"type\": \"string\"\n                },\n                \"age\": {\n                    \"title\": \"Age\",\n                    \"type\": \"integer\"\n                },\n                \"desc\": {\n                    \"title\": \"Desc\",\n                    \"type\": \"string\"\n                }\n            },\n            \"required\": [\n                \"name\",\n                \"age\",\n                \"desc\"\n            ],\n            \"title\": \"UserInfo\",\n            \"type\": \"object\"\n        }\n    },\n    \"properties\": {\n        \"final_output\": {\n            \"$ref\": \"#/$defs/UserInfo\"\n        },\n        \"tool_responses\": {\n            \"items\": {\n                \"$ref\": \"#/$defs/ToolResponse_get_user_\"\n            },\n            \"title\": \"Tool Responses\",\n            \"type\": \"array\"\n        }\n    },\n    \"required\": [\n        \"final_output\",\n        \"tool_responses\"\n    ],\n    \"title\": \"UserParsingAgentResponse\",\n    \"type\": \"object\"\n}\n</code></pre> <p>This ensures that the agent's output is a valid JSON object that conforms to the specified Pydantic model, providing type safety and structured data you can rely on.</p>"},{"location":"reference/modules/","title":"Module Reference","text":""},{"location":"reference/modules/#pyagentic.__all__","title":"<code>__all__ = ['Agent', 'AgentExtension', 'Param', 'ParamInfo', 'tool', 'computed_context', 'ContextRef', 'ContextItem']</code>  <code>module-attribute</code>","text":""},{"location":"reference/modules/#pyagentic.Agent","title":"<code>Agent</code>","text":""},{"location":"reference/modules/#pyagentic.Agent._get_tool_defs","title":"<code>_get_tool_defs() -&gt; list[_ToolDefinition]</code>  <code>async</code>","text":"<p>Creates a list of tool definitions from any methods decorated with \"@tool\" and any agents     linked to the parent agent</p> Source code in <code>pyagentic/_base/_agent.py</code> <pre><code>async def _get_tool_defs(self) -&gt; list[_ToolDefinition]:\n    \"\"\"\n    Creates a list of tool definitions from any methods decorated with \"@tool\" and any agents\n        linked to the parent agent\n    \"\"\"\n    tool_defs = []\n    # iterate through registered tools\n    for tool_def in self.__tool_defs__.values():\n        # Check if any of the tool params use a ContextRef\n        # convert to openai schema\n        tool_defs.append(tool_def)\n    for name, agent in self.__linked_agents__.items():\n        tool_def = agent.get_tool_definition(name)\n        tool_defs.append(tool_def)\n    return tool_defs\n</code></pre>"},{"location":"reference/modules/#pyagentic.Agent._process_agent_call","title":"<code>_process_agent_call(tool_call: ToolCall) -&gt; AgentResponse</code>  <code>async</code>","text":"<p>Processes linked agents by adding appropriate messages to the context, calling the agent,     handling errors, and creating an agent response.</p> Source code in <code>pyagentic/_base/_agent.py</code> <pre><code>@traced(SpanKind.AGENT)\nasync def _process_agent_call(self, tool_call: ToolCall) -&gt; AgentResponse:\n    \"\"\"\n    Processes linked agents by adding appropriate messages to the context, calling the agent,\n        handling errors, and creating an agent response.\n    \"\"\"\n    self.tracer.set_attributes(\n        agent=tool_call.name,\n    )\n    logger.info(f\"Calling {tool_call.name} with kwargs: {tool_call.arguments}\")\n    self.context._messages.append(self.provider.to_tool_call_message(tool_call))\n    agent = getattr(self, tool_call.name)\n    agent.tracer = self.tracer\n    try:\n        kwargs = json.loads(tool_call.arguments)\n        self.tracer.set_attributes(**kwargs)\n        response = await agent(**kwargs)\n        result = f\"Agent {tool_call.name}: {response.final_output}\"\n        self.tracer.set_attributes(result=response.model_dump())\n    except Exception as e:\n        self.tracer.record_exception(str(e))\n        result = f\"Agent `{tool_call.name}` failed: {e}. Please kindly state to the user that is failed, provide context, and ask if they want to try again.\"  # noqa E501\n        response = AgentResponse(final_output=result, provider_info=agent.provider._info)\n    self.context._messages.append(\n        self.provider.to_tool_call_result_message(result=result, id_=tool_call.id)\n    )\n    return response\n</code></pre>"},{"location":"reference/modules/#pyagentic.Agent._process_tool_call","title":"<code>_process_tool_call(tool_call: ToolCall, call_depth: int) -&gt; ToolResponse</code>  <code>async</code>","text":"<p>Processes a tool call by adding appropriate messages to the context, calling the tool,     handling errors, and creating the tool response</p> Source code in <code>pyagentic/_base/_agent.py</code> <pre><code>@traced(SpanKind.TOOL)\nasync def _process_tool_call(self, tool_call: ToolCall, call_depth: int) -&gt; ToolResponse:\n    \"\"\"\n    Processes a tool call by adding appropriate messages to the context, calling the tool,\n        handling errors, and creating the tool response\n    \"\"\"\n    self.tracer.set_attributes(**tool_call.__dict__)\n    self.context._messages.append(self.provider.to_tool_call_message(tool_call))\n    logger.info(f\"Calling {tool_call.name} with kwargs: {tool_call.arguments}\")\n    # Lookup the bound method\n    try:\n        tool_def = self.__tool_defs__[tool_call.name]\n        handler = getattr(self, tool_call.name)\n    except KeyError:\n        return f\"Tool {tool_call.name} not found\"\n    kwargs = json.loads(tool_call.arguments)\n\n    # Run the tool, emitting updates\n    try:\n        if self.emitter:\n            await _safe_run(\n                self.emitter,\n                ToolUpdate(\n                    status=Status.PROCESSING, tool_call=tool_call.name, tool_args=kwargs\n                ),\n            )\n\n        compiled_args = tool_def.compile_args(**kwargs)\n        result = await _safe_run(handler, **compiled_args)\n        self.tracer.set_attributes(result=result)\n    except Exception as e:\n        self.tracer.record_exception(str(e))\n        logger.exception(e)\n        result = f\"Tool `{tool_call.name}` failed: {e}. Please kindly state to the user that is failed, provide context, and ask if they want to try again.\"  # noqa E501\n        if self.emitter:\n            await _safe_run(\n                self.emitter,\n                ToolUpdate(status=Status.ERROR, tool_call=tool_call.name, tool_args=kwargs),\n            )\n\n    # Record output for LLM\n    self.context._messages.append(\n        self.provider.to_tool_call_result_message(result=result, id_=tool_call.id)\n    )\n    ToolResponseModel = self.__tool_response_models__[tool_call.name]\n    return ToolResponseModel(\n        raw_kwargs=tool_call.arguments, call_depth=call_depth, output=result, **compiled_args\n    )\n</code></pre>"},{"location":"reference/modules/#pyagentic.Agent.get_tool_definition","title":"<code>get_tool_definition(name: str) -&gt; _ToolDefinition</code>  <code>classmethod</code>","text":"<p>Creates and returns a tool definition for the agent.</p> <p>This is used for linked agents, allowing each agent to be linked to another by using it     as a tools</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the linked agent</p> required <p>Returns:</p> Name Type Description <code>_ToolDefinition</code> <code>_ToolDefinition</code> <p>A pyagentic tool defintion to be injected into a generate call</p> Source code in <code>pyagentic/_base/_agent.py</code> <pre><code>@classmethod\ndef get_tool_definition(cls, name: str) -&gt; _ToolDefinition:\n    \"\"\"\n    Creates and returns a tool definition for the agent.\n\n    This is used for linked agents, allowing each agent to be linked to another by using it\n        as a tools\n\n    Args:\n        name (str): The name of the linked agent\n\n    Returns:\n        _ToolDefinition: A pyagentic tool defintion to be injected into a generate call\n    \"\"\"\n    desc = getattr(cls, \"__description__\", \"\") or \"\"\n\n    # fresh async wrapper so each class gets its own function object\n    @wraps(cls.__call__)\n    async def _invoke(self, *args, **kwargs):\n        return await cls.__call__(self, *args, **kwargs)\n\n    td = tool(desc)(_invoke).__tool_def__  # decorator attaches metadata to the wrapper\n    td.name = name\n    return td\n</code></pre>"},{"location":"reference/modules/#pyagentic.AgentExtension","title":"<code>AgentExtension</code>","text":"<p>Inherit this in any mixin that contributes fields to the Agent init.</p>"},{"location":"reference/modules/#pyagentic.ContextItem","title":"<code>ContextItem(default: Any = None, default_factory: Callable = None)</code>  <code>dataclass</code>","text":"<p>A <code>ContextItem</code> is used to signal that a class attribute can be used in the context of an agent. Any of these values can be referenced in:     - the agent's <code>instructions</code>     - the agent's <code>input_template</code>     - any <code>ContextRef</code> used in the Agent (e.g., in a <code>ParamInfo</code>)     - the constructor of the Agent itself</p> <p>Parameters:</p> Name Type Description Default <code>default</code> <code>Any</code> <p>The default value for this context item if no explicit value is provided. Defaults to <code>None</code>.</p> <code>None</code> <code>default_factory</code> <code>Callable[[], Any]</code> <p>A zero-argument factory function that produces a default value. If provided, its return value takes precedence over <code>default</code>. Defaults to <code>None</code>.</p> <code>None</code>"},{"location":"reference/modules/#pyagentic.ContextRef","title":"<code>ContextRef(path: str)</code>","text":"<p>A placeholder pointing at some attribute or method on the agent\u2019s context, to be resolved at schema-build time.</p> Source code in <code>pyagentic/_base/_context.py</code> <pre><code>def __init__(self, path: str):\n    self.path = path  # dot-notation into agent.context\n</code></pre>"},{"location":"reference/modules/#pyagentic.Param","title":"<code>Param(**kwargs)</code>","text":"<p>Base class for defining structured parameters that can be converted into OpenAI-compatible JSON schema entries.</p> <p>Subclasses should declare class attributes with type annotations, optionally assigning a ParamInfo instance or a raw default value.</p> <p>On subclass creation, attributes is populated mapping field names to (type, ParamInfo) pairs. Instances perform simple type-checked assignment and reject unknown fields.</p> <p>Instantiate a Param subclass by validating and assigning each annotated field, falling back to class-level defaults if absent.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>if a provided value does not match the annotated type,        or if unexpected fields are passed.</p> Source code in <code>pyagentic/_base/_params.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"\n    Instantiate a Param subclass by validating and assigning each\n    annotated field, falling back to class-level defaults if absent.\n\n    Raises:\n        TypeError: if a provided value does not match the annotated type,\n                   or if unexpected fields are passed.\n    \"\"\"\n    for field_name, (field_type, field_info) in self.__attributes__.items():\n        type_info = analyze_type(field_type, self.__class__.__bases__[0])\n        value = kwargs.get(field_name, field_info.default)\n\n        try:\n            if not type_info.is_subclass:\n                check_type(value, field_type)\n        except TypeCheckError:\n            raise TypeError(f\"Field '{field_name}' expected {field_type}, got {type(value)}\")\n\n        match type_info.category:\n\n            case TypeCategory.PRIMITIVE:\n                setattr(self, field_name, value)\n            case TypeCategory.LIST_PRIMITIVE:\n                setattr(self, field_name, value)\n            case TypeCategory.SUBCLASS:\n                value = field_type(**value) if type(value) is dict else value\n                setattr(self, field_name, value)\n            case TypeCategory.LIST_SUBCLASS:\n                listed_value = (\n                    [type_info.inner_type(**param_kwargs) for param_kwargs in value]\n                    if isinstance(value, list) and all(isinstance(v, dict) for v in value)\n                    else value\n                )\n                setattr(self, field_name, listed_value)\n\n    unexpected_args = [kwarg for kwarg in kwargs if kwarg not in self.__attributes__]\n    if unexpected_args:\n        unexpected = \", \".join(unexpected_args)\n        raise TypeError(f\"Unexpected fields for {self.__class__.__name__}: {unexpected}\")\n</code></pre>"},{"location":"reference/modules/#pyagentic.Param.to_json_schema","title":"<code>to_json_schema(context: _AgentContext) -&gt; List[Dict[str, Any]]</code>  <code>classmethod</code>","text":"<p>Generate a JSON-schema-style dictionary suitable for OpenAI function parameter definitions.</p> <p>Returns:</p> Type Description <code>List[Dict[str, Any]]</code> <p>Dict[str, Any]: A schema object with keys: - \"type\": always \"object\" - \"properties\": mapping from field names to their OpenAI types - \"required\": list of names marked as required</p> Source code in <code>pyagentic/_base/_params.py</code> <pre><code>@classmethod\ndef to_json_schema(cls, context: _AgentContext) -&gt; List[Dict[str, Any]]:\n    \"\"\"\n    Generate a JSON-schema-style dictionary suitable for OpenAI function\n    parameter definitions.\n\n    Returns:\n        Dict[str, Any]: A schema object with keys:\n          - \"type\": always \"object\"\n          - \"properties\": mapping from field names to their OpenAI types\n          - \"required\": list of names marked as required\n    \"\"\"\n    properties: Dict[str, dict] = defaultdict(dict)\n    required = []\n\n    for name, (type_, info) in cls.__attributes__.items():\n        resolved_info = info.resolve(context)\n        properties[name][\"type\"] = _TYPE_MAP.get(type_, \"string\")\n        if resolved_info.description:\n            properties[name][\"description\"] = resolved_info.description\n        if resolved_info.values:\n            properties[name][\"enum\"] = resolved_info.values\n\n        if resolved_info.required:\n            required.append(name)\n\n    return {\"type\": \"object\", \"properties\": dict(properties), \"required\": required}\n</code></pre>"},{"location":"reference/modules/#pyagentic.ParamInfo","title":"<code>ParamInfo(description: MaybeContext[str] = None, required: bool = False, default: MaybeContext[Any] = None, values: MaybeContext[list[str]] = None)</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ContextualMixin</code></p> <p>Declare metadata for parameters in tool declarations and/or Parameter declarations.</p> <p>Attributes:</p> Name Type Description <code>description</code> <code>str | None</code> <p>A human-readable description of the parameter.</p> <code>required</code> <code>bool</code> <p>Whether this parameter must be provided by the user.</p> <code>default</code> <code>Any</code> <p>The default value to use if none is provided.</p> <code>values</code> <code>list[str]</code> <p>values to limit the input of this parameter. If used, the agent is forced to use on the the values in the list.</p> Context-Ready Attributes <p>These attributes can be given a <code>ContextRef</code> to link them to any context items in the agent.</p> <ul> <li>description</li> <li>default</li> <li>values</li> </ul>"},{"location":"reference/modules/#pyagentic.computed_context","title":"<code>computed_context(fget)</code>","text":"<p>Descriptor used to mark a method in an Agent as a computed context.</p> <p>Computed contexts work very similarly to Python's <code>@property</code> descriptor: they are re-computed each time they're accessed. When a computed context appears in:</p> <ul> <li>the agent's <code>instructions</code>, its value will be refreshed on every call to the agent,     updating the system message with the latest value.</li> <li>the agent's <code>input_template</code>, its value will be refreshed each time a new user message is     added, updating the prompt accordingly.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>Callable[[Agent], Any]</code> <p>The method on the Agent class that computes and returns the context value. It will be called with the agent instance each time the context is accessed.</p> required Source code in <code>pyagentic/_base/_context.py</code> <pre><code>def __init__(self, fget):\n    functools.update_wrapper(self, fget)\n    self.fget = fget\n    self._is_context = True\n</code></pre>"},{"location":"reference/modules/#pyagentic.tool","title":"<code>tool(description: str, condition: Callable[[Any], bool] = None)</code>","text":"<p>Decorator to mark a method as a callable tool. All methods marked with this descriptor must return a string</p> <p>Parameters:</p> Name Type Description Default <code>description(str)</code> <p>Description of the tool that will be read by the LLM</p> required <code>condition(Callable)</code> <p>A callable that returns a boolean, determining when the tool will be included in the LLM inference call</p> required Source code in <code>pyagentic/_base/_tool.py</code> <pre><code>def tool(\n    description: str,\n    condition: Callable[[Any], bool] = None,\n):\n    \"\"\"\n    Decorator to mark a method as a callable tool.\n    All methods marked with this descriptor **must** return a string\n\n    Args:\n        description(str): Description of the tool that will be read by the LLM\n        condition(Callable): A callable that returns a boolean, determining when the tool\n            will be included in the LLM inference call\n    \"\"\"\n\n    def decorator(fn: Callable):\n        # Check return type\n        types = get_type_hints(fn)\n        return_type = types.pop(\"return\", None)\n        if return_type != str and fn.__name__ != \"__call__\":\n            raise ToolDeclarationFailed(\n                tool_name=fn.__name__, message=\"Method must have a return type of `str`\"\n            )\n\n        # 2) grab default values\n        sig = inspect.signature(fn)\n        defaults = {\n            param_name: param.default\n            for param_name, param in sig.parameters.items()\n            if param.default is not inspect._empty\n        }\n\n        params = {}\n\n        for name, type_ in types.items():\n            default = defaults.get(name, None)\n            if isinstance(default, ParamInfo):\n                params[name] = (type_, default)\n            elif default is not None:\n                params[name] = (type_, ParamInfo(default=default))\n            else:\n                params[name] = (type_, ParamInfo())\n\n        fn.__tool_def__ = _ToolDefinition(\n            name=fn.__name__,\n            description=description or fn.__doc__ or \"\",\n            parameters=params,\n            condition=condition,\n        )\n        return fn\n\n    return decorator\n</code></pre>"}]}